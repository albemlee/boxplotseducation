{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, Imputer, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from tpot import TPOTClassifier\n",
    "import dill\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load testing data\n",
    "data_test = pd.read_csv('data/TestData.csv', index_col=0)\n",
    "\n",
    "# Load training data\n",
    "data = pd.read_csv('data/TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List features and labels\n",
    "\n",
    "features = ['FTE', \n",
    "            'Facility_or_Department', \n",
    "            'Function_Description', \n",
    "            'Fund_Description', \n",
    "            'Job_Title_Description', \n",
    "            'Location_Description', \n",
    "            'Object_Description', \n",
    "            'Position_Extra', \n",
    "            'Program_Description', \n",
    "            'SubFund_Description', \n",
    "            'Sub_Object_Description', \n",
    "            'Text_1', \n",
    "            'Text_2', \n",
    "            'Text_3', \n",
    "            'Text_4', \n",
    "            'Total']\n",
    "\n",
    "labels = ['Function', \n",
    "          'Object_Type', \n",
    "          'Operating_Status', \n",
    "          'Position_Type', \n",
    "          'Pre_K', \n",
    "          'Reporting', \n",
    "          'Sharing', \n",
    "          'Student_Type', \n",
    "          'Use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels into category data type\n",
    "data[labels] = data[labels].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and one-hot encode labels\n",
    "encoded_labels = pd.get_dummies(data[labels], prefix_sep='__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "data_features = data[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose 50064 records as the size of the development set to match the size of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric feature preprocessing\n",
    "select_numeric_features = FunctionTransformer(lambda x: x[['FTE', 'Total']], validate=False)\n",
    "numeric_preprocess_pipeline = Pipeline([\n",
    "    ('selector', select_numeric_features),\n",
    "    ('handle_missing_values', Imputer())\n",
    "])\n",
    "\n",
    "# Text feature preprocessing\n",
    "def combine_text_columns(df_train):\n",
    "    return df_train.drop(columns=['FTE', 'Total']).fillna(\"\").apply(lambda x: \" \".join(x), axis=1)\n",
    "    \n",
    "prepare_text_features = FunctionTransformer(lambda x: combine_text_columns(x), validate=False)\n",
    "text_preprocess_pipeline = Pipeline([\n",
    "    ('combine_text', prepare_text_features),\n",
    "    ('vectorize', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                    non_negative=True,\n",
    "                                    norm=None,\n",
    "                                    binary=False, \n",
    "                                    ngram_range=(1, 2))),\n",
    "    ('dim_red', SelectKBest(chi2, 100))\n",
    "])\n",
    "\n",
    "# Combine numeric and text feature preprocessing\n",
    "preprocess_pipeline = FeatureUnion(transformer_list = [\n",
    "    ('numeric_preprocess', numeric_preprocess_pipeline),\n",
    "    ('text_preprocess', text_preprocess_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric_preprocess', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x1a2a16a510>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "          validate=False)), ('handle_...', tokenizer=None)), ('dim_red', SelectKBest(k=100, score_func=<function chi2 at 0x1a1fbc9950>))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Preprocessing Model\n",
    "preprocess_pipeline.fit(data_features, encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "encoded_data_features = preprocess_pipeline.transform(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and development sets\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(encoded_data_features, encoded_labels, test_size=50064, random_state=93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Function__Aides Compensation',\n",
       "       'Function__Career & Academic Counseling', 'Function__Communications',\n",
       "       'Function__Curriculum Development',\n",
       "       'Function__Data Processing & Information Services',\n",
       "       'Function__Development & Fundraising', 'Function__Enrichment',\n",
       "       'Function__Extended Time & Tutoring',\n",
       "       'Function__Facilities & Maintenance', 'Function__Facilities Planning',\n",
       "       ...\n",
       "       'Student_Type__Special Education', 'Student_Type__Unspecified',\n",
       "       'Use__Business Services', 'Use__ISPD', 'Use__Instruction',\n",
       "       'Use__Leadership', 'Use__NO_LABEL', 'Use__O&M',\n",
       "       'Use__Pupil Services & Enrichment', 'Use__Untracked Budget Set-Aside'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in y_dev.columns:\n",
    "    y_train_single = y_train[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9600311601150527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'Function__Aides Compensation'\n",
    "\n",
    "y_train_single = y_train[label].values\n",
    "y_dev_single = y_dev[label].values\n",
    "clf = LogisticRegression()\n",
    "# clf = TPOTClassifier(scoring='neg_log_loss', random_state=82, config_dict='TPOT sparse', early_stop=10, verbosity=3, periodic_checkpoint_folder='models/automl_pipelines')\n",
    "clf.fit(X_train, y_train_single)\n",
    "clf.score(X_dev, y_dev_single)\n",
    "# clf.export('models/automl_pipelines/final_'+label+'.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
