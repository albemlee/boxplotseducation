{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Requirements\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from scipy import sparse\n",
    "\n",
    "import zipfile\n",
    "import re, nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, concatenate, Input, Dropout, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape: (400277, 25)\n",
      "data_test shape: (50064, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data_train, data_test = load_data()\n",
    "print('data_train shape:', data_train.shape)\n",
    "print('data_test shape:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_features shape: (450341, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load Features\n",
    "data_features = load_features(data_train, data_test)\n",
    "print('data_features shape:', data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(phrase):\n",
    "    \"\"\"\n",
    "    Return list processed_phrase: phrase tokens after processing has been completed\n",
    "    \n",
    "    param string phrase: phrase to be processed\n",
    "    \n",
    "    Required Libraries: re, nltk\n",
    "    \"\"\"\n",
    "    \n",
    "    # Case Normalization\n",
    "    processed_phrase = phrase.lower()\n",
    "    \n",
    "    # Remove Punctuations\n",
    "    processed_phrase = re.sub(r\"[^a-z0-9-]\", \" \", processed_phrase)\n",
    "    \n",
    "    # Tokenize Phrase\n",
    "    processed_phrase = processed_phrase.split()\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    processed_phrase = [word for word in processed_phrase if word not in stopwords.words(\"english\")]\n",
    "    processed_phrase = [word for word in processed_phrase if word != '-']\n",
    "    \n",
    "    # Lemmatization\n",
    "    processed_phrase = [WordNetLemmatizer().lemmatize(word) for word in processed_phrase]\n",
    "    \n",
    "    # Recombine list into phrase\n",
    "    processed_phrase = ' '.join(processed_phrase)\n",
    "    \n",
    "    return processed_phrase\n",
    "\n",
    "def init_prep(data_train, data_test, data_features, label=None):\n",
    "    \"\"\"\n",
    "    Return numpy array X: feature matrix for classification model fitting\n",
    "    Return numpy array y: labels matrix for classification model fitting\n",
    "    Return numpy array X_test: feature matrix of test set\n",
    "    \n",
    "    Param pandas dataframe data_train: training data (features + labels)\n",
    "    Param pandas dataframe data_test: test data (features)\n",
    "    Param pandas dataframe data_features: data in feature columns of data_train and data_test\n",
    "    \n",
    "    Required Libraries: pandas, numpy, keras\n",
    "    Required helper functions: text_processing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combined and preprocess text columns\n",
    "    data_train['combined_text'] = (data_train[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                  )\n",
    "    data_test['combined_text'] = (data_test[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                 )\n",
    "    data_features['combined_text'] = (data_features\n",
    "                                          .drop(columns=['FTE', 'Total'])\n",
    "                                          .fillna(\"\")\n",
    "                                          .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                          .apply(lambda x: text_processing(x))\n",
    "                                     )\n",
    "    \n",
    "    # Vectorizer text columns in training data\n",
    "    tokenize = Tokenizer()\n",
    "    tokenize.fit_on_texts(data_features['combined_text'])\n",
    "    \n",
    "    X_text = tokenize.texts_to_sequences(data_train['combined_text'])\n",
    "    X_text_test = tokenize.texts_to_sequences(data_test['combined_text'])\n",
    "    \n",
    "    X_text = pad_sequences(X_text, padding='post', maxlen=50, truncating='post')\n",
    "    X_text_test = pad_sequences(X_text_test, padding='post', maxlen=50, truncating='post')\n",
    "    \n",
    "    # Impute missing numerical data\n",
    "    imp_total = Imputer(strategy='median')\n",
    "    imp_total.fit(data_features['Total'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    total_not_missing = pd.isnull(data_train['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing = pd.isnull(data_train['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total = imp_total.transform(data_train['Total'].values.reshape(-1, 1))\n",
    "    fte = data_train['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "\n",
    "    total_not_missing_test = pd.isnull(data_test['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing_test = pd.isnull(data_test['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total_test = imp_total.transform(data_test['Total'].values.reshape(-1, 1))\n",
    "    fte_test = data_test['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X_numeric = np.concatenate([total, total_not_missing, fte, fte_not_missing], axis=1)\n",
    "    X_numeric_test = np.concatenate([total_test, total_not_missing_test, fte_test, fte_not_missing_test], axis=1)\n",
    "    \n",
    "    # Create labels matrix\n",
    "    if label:\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    else:\n",
    "        label = ['Function',\n",
    "                 'Object_Type',\n",
    "                 'Operating_Status',\n",
    "                 'Position_Type',\n",
    "                 'Pre_K',\n",
    "                 'Reporting',\n",
    "                 'Sharing',\n",
    "                 'Student_Type',\n",
    "                 'Use']\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    \n",
    "    return X_numeric, X_text, X_numeric_test, X_text_test, y, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_numeric shape: (400277, 4)\n",
      "X_numeric_test shape: (50064, 4)\n",
      "X_text shape: (400277, 50)\n",
      "X_text_test shape: (50064, 50)\n",
      "y shape: (400277, 104)\n"
     ]
    }
   ],
   "source": [
    "X_numeric, X_text, X_numeric_test, X_text_test, y, tokenize = init_prep(data_train, data_test, data_features, label=None)\n",
    "print('X_numeric shape:', X_numeric.shape)\n",
    "print('X_numeric_test shape:', X_numeric_test.shape)\n",
    "print('X_text shape:', X_text.shape)\n",
    "print('X_text_test shape:', X_text_test.shape)\n",
    "print('y shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': 1, 'fund': 2, 'teacher': 3, 'regular': 4, 'service': 5, 'school': 6, 'employee': 7, 'instruction': 8, 'instructional': 9, 'salary': 10, 'education': 11, 'benefit': 12, 'professional': 13, 'title': 14, 'special': 15, 'support': 16, 'non': 17, 'project': 18, 'staff': 19, 'elementary': 20, 'part': 21, 'wage': 22, 'pay': 23, 'sub': 24, 'operation': 25, 'program': 26, 'food': 27, 'basic': 28, 'supply': 29, 'undesignated': 30, 'extra': 31, 'substitute': 32, 'duty': 33, 'transportation': 34, 'ed': 35, 'personnel': 36, 'undistributed': 37, 'time': 38, 'operating': 39, 'high': 40, 'personal': 41, 'term': 42, 'child': 43, 'training': 44, 'educational': 45, 'disadvantaged': 46, 'retirement': 47, 'k': 48, 'curriculum': 49, 'federal': 50, 'district': 51, 'overtime': 52, 'professi': 53, 'campus': 54, 'activity': 55, 'community': 56, 'student': 57, 'state': 58, 'short': 59, 'middle': 60, 'bus': 61, 'maintenance': 62, 'targeted': 63, 'assistance': 64, 'purpose': 65, 'secondary': 66, '12': 67, 'arra': 68, 'contra': 69, 'driver': 70, 'payroll': 71, 'additional': 72, 'day': 73, 'gdpg': 74, 'budget': 75, 'nutrition': 76, 'office': 77, 'stip': 78, 'plant': 79, 'grade': 80, 'miscellaneous': 81, 'unalloc': 82, 'ii': 83, 'admin': 84, 'extended': 85, 'certificated': 86, 'blank': 87, 'grant': 88, 'asst': 89, 'local': 90, 'trade': 91, 'misc': 92, 'schoolwide': 93, 'services': 94, 'craft': 95, 'fy': 96, 'material': 97, 'paraprofessional': 98, 'early': 99, 'fefp': 100, 'improving': 101, 'development': 102, 'contrib': 103, 'administration': 104, 'facility': 105, 'related': 106, 'improvement': 107, 'department': 108, 'b': 109, 'maint': 110, 'leadership': 111, 'sch': 112, 'bachelor': 113, 'comp': 114, 'medium': 115, 'certified': 116, '8': 117, 'primary': 118, 'other': 119, 'ela': 120, 'learning': 121, 'principal': 122, 'summer': 123, 'idea': 124, 'purchased': 125, 'custodian': 126, 'revenue': 127, 'childhood': 128, 'e': 129, 'pupil': 130, 'spec': 131, 'travel': 132, 'custodial': 133, 'resource': 134, 'worker': 135, 'teaching': 136, 'center': 137, 'objective': 138, 'disability': 139, 'levy': 140, 'employer': 141, 'svcs': 142, 'assistant': 143, 'elem': 144, 'bilingual': 145, 'pd': 146, 'equipment': 147, 'stimulus': 148, 'capital': 149, 'aide': 150, 'retrd': 151, 'shrt': 152, 'classroom': 153, 'athletics': 154, 'med': 155, 'contribution': 156, 'care': 157, 'youth': 158, 'paid': 159, 'security': 160, 'turnaround': 161, 'pool': 162, 'administrative': 163, 'central': 164, 'preschool': 165, 'eng': 166, 'iii': 167, 'junior': 168, 'math': 169, 'management': 170, 'science': 171, 'prog': 172, 'charter': 173, 'pre': 174, 'need': 175, 'alternative': 176, 'art': 177, 'based': 178, 'specialist': 179, 'tech': 180, 'upkeep': 181, 'serv': 182, 'language': 183, 'public': 184, 'bldg': 185, 'bonus': 186, 'supplement': 187, 'preparation': 188, 'wide': 189, 'a': 190, 'trust': 191, 'building': 192, 'sheltered': 193, 'reading': 194, 'super': 195, 'inst': 196, 'instr': 197, 'para': 198, 'dev': 199, 'unallocated': 200, 'mill': 201, 'kindergarten': 202, 'lunch': 203, 'social': 204, 'technical': 205, 'severe': 206, 'serving': 207, 'secretary': 208, 'breakfast': 209, 't': 210, 'career': 211, 'schools': 212, 'master': 213, 'vocational': 214, 'fee': 215, 'textbook': 216, 'opportunity': 217, 'tuition': 218, 'reg': 219, '9': 220, 'adult': 221, 'sped': 222, 'esea': 223, 'guidance': 224, 'i': 225, 'sport': 226, 'tchr': 227, 'moderate': 228, 'elpa': 229, 'manager': 230, 'mild': 231, 'extracurricular': 232, 'ext': 233, 'book': 234, 'gifted': 235, 'card': 236, 'fed': 237, 'degreed': 238, 'conversion': 239, 'afterschool': 240, 'year': 241, 'contracted': 242, 'thru': 243, 'intervention': 244, 'technology': 245, 'coach': 246, 'tcher': 247, '6': 248, 'administrator': 249, 'national': 250, 'cocurricular': 251, 'exceptional': 252, 'vi': 253, 'accelerated': 254, 'periodical': 255, 'clerical': 256, 'allotment': 257, 'assessment': 258, 'officer': 259, 'cash': 260, 'library': 261, 'purchase': 262, 'act': 263, 'advance': 264, 'speech': 265, 'counselor': 266, 'itemgd': 267, 'cost': 268, 'category': 269, 'incentive': 270, 'esl': 271, 'addl': 272, 'english': 273, 'el': 274, 'talented': 275, 'facilitator': 276, 'compensation': 277, 'temporary': 278, 'repair': 279, 'sp': 280, 'workshop': 281, 'parent': 282, 'participant': 283, 'l': 284, 'humanity': 285, 'override': 286, 'evaluation': 287, 'nurse': 288, 'voc': 289, 'lead': 290, 'human': 291, 'allowance': 292, 'certifiedaddl': 293, 'operations': 294, 'health': 295, 'critical': 296, 'itemgb': 297, 'qualit': 298, 'formula': 299, 'leave': 300, 'work': 301, 'compute': 302, 'item': 303, 'assignment': 304, 'curricular': 305, 'yr': 306, 'expense': 307, 'second': 308, 'top': 309, 'signing': 310, 'person': 311, 'schl': 312, 'supplemental': 313, 'spanish': 314, 'academic': 315, 'oth': 316, 'acq': 317, 'computer': 318, 'race': 319, 'counseling': 320, 'cafeteria': 321, 'ladder': 322, 'writing': 323, 'smoothed': 324, 'not': 325, 'prof': 326, 'run': 327, 'research': 328, 'team': 329, 'core': 330, 'system': 331, 'head': 332, 'safety': 333, 'utility': 334, 'h': 335, 'athletic': 336, 'literacy': 337, 'lang': 338, 'kindergar': 339, 'prg': 340, 'initiative': 341, 'psychological': 342, 'supp': 343, 'chief': 344, 'garage': 345, 'business': 346, 'sea': 347, 'line': 348, 'job': 349, 'acquisition': 350, 'construction': 351, 'matter': 352, 'money': 353, 'en': 354, 'ece': 355, 'helper': 356, 'reserve': 357, 'main': 358, 'recognition': 359, 'communication': 360, 'pupils': 361, 'alloc': 362, 'tif': 363, 'kinder': 364, 'week': 365, 'classified': 366, 'award': 367, 'dept': 368, 'meeting': 369, 'direction': 370, 'upper': 371, 'data': 372, 'account': 373, 'cu': 374, 'music': 375, 'expenditure': 376, 'm': 377, 'rental': 378, 'bond': 379, 'psychologist': 380, 'individual': 381, 'prize': 382, 'nat': 383, 'due': 384, 'object': 385, 'librarian': 386, 'iv': 387, 'itinerant': 388, 'coaching': 389, 'dir': 390, 'lep': 391, 'sec': 392, 'gob': 393, 'therapist': 394, 'sr': 395, 'hs': 396, 'outlay': 397, 'educ': 398, 'partnership': 399, 'coordinator': 400, 'prekindergarten': 401, 'planning': 402, 'hrly': 403, 'sai': 404, 'carryover': 405, 'start': 406, 'unassigned': 407, 'pers': 408, 'leaf': 409, 'effectiveness': 410, 'success': 411, 'field': 412, 'const': 413, 'pgms': 414, 'software': 415, 'intensive': 416, 'constr': 417, 'vehicle': 418, 'new': 419, 'rollup': 420, 'unit': 421, 'coverage': 422, 'g': 423, 'information': 424, 'trip': 425, 'curr': 426, 'pathologst': 427, 'nursing': 428, 'opp': 429, 'relation': 430, 'skill': 431, 'quality': 432, 'mobile': 433, 'remediation': 434, 'speaker': 435, 'capitalized': 436, 'pi': 437, 'including': 438, 'chair': 439, 'technician': 440, 'relief': 441, 'direct': 442, 'homeless': 443, 'adm': 444, 'empac': 445, 'millage': 446, 'mileage': 447, 'bil': 448, 'itemfa': 449, 'aaps': 450, 'hourly': 451, 'medicare': 452, 'perkins': 453, 'host': 454, 'first': 455, 'sci': 456, 'size': 457, 'ese': 458, 'involvement': 459, 'area': 460, 'purchasing': 461, 'ground': 462, 'reserved': 463, 'tap': 464, 'inter': 465, 'after': 466, 'class': 467, '2nd': 468, 's': 469, 'instruct': 470, 'superintendent': 471, 'allocation': 472, 'funded': 473, 'fiscal': 474, 'p': 475, 'princ': 476, 'payment': 477, 'pt': 478, 'rtd': 479, 'warehouse': 480, 'com': 481, 'male': 482, 'monitoring': 483, 'century': 484, 'handicapped': 485, 'avid': 486, 'doe': 487, 'activiti': 488, 'ofc': 489, 'innovation': 490, 'director': 491, 'registration': 492, 'soc': 493, 'le': 494, 'phone': 495, '3rd': 496, 'liaison': 497, 'site': 498, '1st': 499, 'property': 500, 'lea': 501, 'organization': 502, 'stabilitazion': 503, 'oriented': 504, 'c': 505, 'group': 506, 'subsistence': 507, 'foundation': 508, 'cte': 509, 'ex': 510, 'college': 511, 'np': 512, 'cert': 513, 'board': 514, 'various': 515, 'instructor': 516, 'srvcs': 517, 'tutor': 518, 'nonpublic': 519, 'water': 520, 'hour': 521, 'si': 522, 'long': 523, 'recruitment': 524, 'hr': 525, 'insurance': 526, 'bgt': 527, 'external': 528, 'accounting': 529, 'police': 530, 'esol': 531, '4th': 532, 'gr': 533, 'renov': 534, 'dispensing': 535, 'interrelated': 536, 'items': 537, 'nclb': 538, 'clerk': 539, 'equip': 540, 'exp': 541, 'bookkeeper': 542, 'noncapitalized': 543, 'remod': 544, 'lottery': 545, 'se': 546, 'relatated': 547, 'co': 548, 'life': 549, 'advancement': 550, 'auxiliary': 551, 'furniture': 552, 'prep': 553, 'exec': 554, 'city': 555, 'uni': 556, 'telephone': 557, 'advanced': 558, '5th': 559, 'carl': 560, 'parapro': 561, 'aux': 562, 'pk': 563, 'slry': 564, 'da': 565, 'tutorial': 566, 'intellectually': 567, 'mechanic': 568, 'in': 569, 'f': 570, 'military': 571, 'risk': 572, 'charge': 573, 'level': 574, 'accountability': 575, 'prod': 576, 'medicaid': 577, 'third': 578, 'consultant': 579, 'studies': 580, 'retiree': 581, 'eve': 582, 'finance': 583, 'cha': 584, 'id': 585, 'description': 586, 'provided': 587, 'arts': 588, 'recovery': 589, 'game': 590, 'paraprof': 591, 'pe': 592, 'supv': 593, 'electricity': 594, 'reso': 595, 'analyst': 596, 'family': 597, 'ccoach': 598, 'tchracct': 599, 'assgnmt': 600, 'kg': 601, 'performance': 602, 'postage': 603, 'revitalization': 604, 'funding': 605, 'compensatory': 606, 'learn': 607, 'contract': 608, 'closed': 609, 'placement': 610, 'asset': 611, 'induction': 612, 'info': 613, 'advisor': 614, 'coordination': 615, 'physical': 616, 'dr': 617, 'performing': 618, 'fourth': 619, 'schls': 620, 'band': 621, 'processing': 622, 'fifth': 623, 'occupational': 624, 'terminal': 625, 'associated': 626, 'radio': 627, 'network': 628, 'none': 629, 'purch': 630, 'donation': 631, 'elc': 632, 'sick': 633, 'handicap': 634, 'transport': 635, 'lab': 636, 'ce': 637, 'full': 638, 'senior': 639, 'used': 640, 'ready': 641, 'cycle': 642, 'itemgg': 643, 'flow': 644, 'study': 645, 'gas': 646, 'waiting': 647, 'mgr': 648, 'o': 649, 'publi': 650, 'invl': 651, 'structured': 652, 'technol': 653, 'coord': 654, 'basis': 655, 'female': 656, 'activi': 657, 'involvem': 658, 'systemwide': 659, 'minor': 660, 'spo': 661, 'financial': 662, 'flowthru': 663, 'v': 664, 'access': 665, 'sw': 666, 'supervisor': 667, 'flowthrough': 668, 'qbe': 669, 'hvac': 670, 'comm': 671, 'gross': 672, 'patrol': 673, 'electronic': 674, 'county': 675, 'midd': 676, 'medical': 677, 'set': 678, 'laboratory': 679, 'cell': 680, 'electrical': 681, 'cdc': 682, 'out': 683, 'recruiting': 684, 'cntry': 685, 'schoo': 686, 'pathway': 687, 'strategic': 688, 'attendance': 689, 'vib': 690, 'lrng': 691, 'commty': 692, 'of': 693, 'copying': 694, 'reimbursement': 695, 'executive': 696, 'foodsvc': 697, 'league': 698, 'round': 699, 'newspaper': 700, 'temp': 701, 'sfpc': 702, 'scndy': 703, 'enterprise': 704, 'multilingual': 705, 'lfi': 706, 'read': 707, 'cd': 708, 'rate': 709, 'prin': 710, 'busine': 711, 'str': 712, 'lrn': 713, 'use': 714, 'interdisciplinary': 715, 'di': 716, 'inservice': 717, 'phys': 718, 'customer': 719, 'engineering': 720, 'film': 721, 'plumbing': 722, 'filmstrips': 723, 'ab': 724, 'natural': 725, 'internal': 726, 'apps': 727, '70h': 728, 'smaller': 729, 'optional': 730, 'three': 731, 'cleaning': 732, 'improvemen': 733, 'teachers': 734, 'testing': 735, 'effective': 736, 'using': 737, 'montessori': 738, 'garbage': 739, 'limited': 740, 'achieve': 741, 'home': 742, 'kin': 743, 'self': 744, 'ist': 745, 'pgm': 746, 'vpk': 747, 'clinic': 748, 'contained': 749, 'decis': 750, 'hd': 751, 'deaf': 752, 'text': 753, 'guard': 754, 'stage': 755, 'light': 756, 'refreshment': 757, 'registrar': 758, 'history': 759, 'parental': 760, 'outreach': 761, 'monitor': 762, 'man': 763, 'private': 764, 'facsimile': 765, 'enhancement': 766, 'architecture': 767, 'legal': 768, 'record': 769, 'sewer': 770, 'dell': 771, 'asd': 772, 'safe': 773, 'copier': 774, 'contractual': 775, 'interpreter': 776, 'ch': 777, 'printing': 778, 'constituency': 779, 'hc': 780, 'hearing': 781, 'pro': 782, 'cl': 783, 'north': 784, 'satellite': 785, 'ser': 786, 'america': 787, 'servicing': 788, 'pc': 789, 'hardw': 790, 'ms': 791, 'childhd': 792, 'reproduction': 793, 'accountant': 794, 'strategy': 795, 'indirect': 796, 'academy': 797, 'cleaner': 798, 'cook': 799, 'instruc': 800, 'sale': 801, 'assist': 802, 'vision': 803, 'industrial': 804, 'kdg': 805, 'graduation': 806, 'depot': 807, 'division': 808, 'behavior': 809, 'ot': 810, 'n': 811, 'case': 812, 'share': 813, 'drug': 814, 'binding': 815, 'chairperson': 816, 'dop': 817, 'subscription': 818, 'refugee': 819, 'teachersup': 820, 'ledger': 821, 'commodity': 822, 'choral': 823, 'mentor': 824, 'fuel': 825, 'multi': 826, 'require': 827, 'approval': 828, 'truck': 829, 'serve': 830, 'apprenticeship': 831, 'intern': 832, 'pathologist': 833, 'intradistrict': 834, 'encumbr': 835, 'crossing': 836, 'sys': 837, 'eett': 838, 'improv': 839, 'structural': 840, 'mixed': 841, 'carpentry': 842, 'engagement': 843, 'participatory': 844, 'license': 845, 'disciplinary': 846, 'fringe': 847, 'refrigeration': 848, 'choice': 849, 'itemga': 850, 'oper': 851, 'mainstream': 852, 'basketball': 853, 'removal': 854, 'asid': 855, 'itemabed': 856, 'tutoring': 857, 'impaired': 858, 'premium': 859, 'foreign': 860, 'specific': 861, 'budgetary': 862, 'hardware': 863, 'md': 864, 'permanent': 865, 'ta': 866, 'iaf': 867, 'lit': 868, 'aut': 869, 'small': 870, 'excellence': 871, 'usda': 872, 'abd': 873, 'donated': 874, 'homebound': 875, 'assoc': 876, 'control': 877, 'paint': 878, 'bridge': 879, 'mdta': 880, 'chance': 881, 'complex': 882, 'twenty': 883, 'proficiency': 884, 'lease': 885, 'debt': 886, 'conference': 887, 'sel': 888, 'sup': 889, 'admission': 890, 'nov': 891, 'hospitality': 892, 'cfda': 893, 'prt': 894, 'marketing': 895, 'gen': 896, 'hdc': 897, 'couns': 898, 'track': 899, 'welding': 900, 'educator': 901, 'aside': 902, 'agency': 903, 'readiness': 904, 'measure': 905, 'receiving': 906, 'childcare': 907, 'rotc': 908, 'block': 909, 'institute': 910, 'credit': 911, 'add': 912, 'consolidation': 913, 'interm': 914, 'camp': 915, 'trainer': 916, 'virtual': 917, 'mgmt': 918, 'annuity': 919, 'perf': 920, 'operator': 921, 'aligning': 922, 'admn': 923, 'sip': 924, 'tax': 925, 'found': 926, 'sheetmtl': 927, 'itemv': 928, 'mid': 929, 'eval': 930, 'south': 931, 'lunchroom': 932, 'occupation': 933, 'imprvmnt': 934, 'sewage': 935, 'differentia': 936, 'teach': 937, 'cust': 938, 'distribution': 939, 'vending': 940, 'girl': 941, 'sanitation': 942, 'itemr': 943, 'orchestra': 944, 'perishable': 945, 'daep': 946, 'contr': 947, 'outdoor': 948, 'itemp': 949, 'content': 950, 'ctr': 951, 'post': 952, 'learner': 953, 'rec': 954, 'tmd': 955, 'licensed': 956, 'motor': 957, 'independent': 958, 'pilot': 959, 'int': 960, 'giver': 961, 'ebd': 962, 'aep': 963, 'warehousing': 964, 'soccer': 965, 'transition': 966, 'renovation': 967, 're': 968, 'source': 969, 'sac': 970, 'intramural': 971, 'prevention': 972, 'intermediate': 973, 'mathematics': 974, 'machinery': 975, 'doctoral': 976, 'procurement': 977, 'wkr': 978, 'choir': 979, 'kitchen': 980, 'protech': 981, 'adjustment': 982, 'consumer': 983, 'compliance': 984, 'leader': 985, 'saturday': 986, 'fellow': 987, 'locally': 988, 'ic': 989, 'labor': 990, 'entry': 991, 'sig': 992, '70': 993, 'excelerator': 994, 'renewal': 995, 'alt': 996, 'creative': 997, 'hazmat': 998, '84': 999, '00a': 1000, 'football': 1001, 'web': 1002, 'athl': 1003, 'ell': 1004, 'impact': 1005, 'waste': 1006, 'esc': 1007, 'timecard': 1008, 'concession': 1009, 'summit': 1010, 'subcontract': 1011, 'telecommunication': 1012, 'focus': 1013, 'contractor': 1014, 'position': 1015, 'preformance': 1016, 'magnet': 1017, 'transfer': 1018, 'land': 1019, 'foreman': 1020, 'manual': 1021, 'app': 1022, 'night': 1023, 'qualified': 1024, 'imp': 1025, 'ac': 1026, 'langs': 1027, 'free': 1028, 'machine': 1029, 'bldgs': 1030, 'fl': 1031, 'cgc': 1032, 'rep': 1033, 'energy': 1034, 'audiologist': 1035, 'boy': 1036, 'deputy': 1037, 'reclassified': 1038, 'attn': 1039, 'budgeting': 1040, '9th': 1041, 'lower': 1042, 'strand': 1043, 'prj': 1044, 'aditional': 1045, 'inventory': 1046, 'inc': 1047, 'american': 1048, 'scrty': 1049, 'ops': 1050, 'migrant': 1051, 'improve': 1052, 'mi': 1053, 'instrumental': 1054, 'delinquent': 1055, 'metro': 1056, 'inheriting': 1057, 'legacy': 1058, 'freedom': 1059, 'inactive': 1060, 'managed': 1061, 'payable': 1062, 'distributed': 1063, 'starting': 1064, 'standard': 1065, 'niet': 1066, 'tip': 1067, 'cera': 1068, 'industry': 1069, 'rgn': 1070, 'proficient': 1071, 'crew': 1072, 'sum': 1073, 'remedial': 1074, 'demonstration': 1075, 'differential': 1076, 'hospital': 1077, 'xpay': 1078, 'xcurricluar': 1079, 'corp': 1080, 'enrichment': 1081, 'dispatch': 1082, 'pathology': 1083, 'reqd': 1084, 'heavy': 1085, 'duplicating': 1086, 'psp': 1087, 'path': 1088, 'function': 1089, 'rttt': 1090, 'immigrant': 1091, 'programmer': 1092, 'svc': 1093, 'fire': 1094, 'billing': 1095, 'application': 1096, 'indian': 1097, 'matls': 1098, 'avg': 1099, 'urban': 1100, 'coor': 1101, 'stem': 1102, 'gender': 1103, 'bdgt': 1104, 'neglected': 1105, 'independence': 1106, 'screening': 1107, 'disorder': 1108, 'ninth': 1109, 'wastewater': 1110, 'red': 1111, 'ldrshp': 1112, 'bell': 1113, 'certifications': 1114, 'wellness': 1115, 'rttp': 1116, 'biology': 1117, 'sunday': 1118, 'cont': 1119, 'major': 1120, 'mgt': 1121, 'periodic': 1122, 'product': 1123, 'delta': 1124, 'othr': 1125, 'sourc': 1126, 'transformation': 1127, 'kid': 1128, 'scii': 1129, 'eip': 1130, 'var': 1131, 'fam': 1132, 'common': 1133, 'volleyball': 1134, 'academically': 1135, 'w': 1136, 'shift': 1137, 'therapy': 1138, 'sundries': 1139, 'ncert': 1140, 'visual': 1141, 'correctionist': 1142, 'ei': 1143, 'itemt': 1144, 'laundry': 1145, 'supt': 1146, 'assis': 1147, 'bs': 1148, 'srv': 1149, 'spiii': 1150, 'ohsti': 1151, 'nfac': 1152, 'correction': 1153, 'pell': 1154, 'route': 1155, 'partne': 1156, 'mtce': 1157, 'itemu': 1158, 'expelled': 1159, 'attorney': 1160, 'economics': 1161, 'bk': 1162, 'univ': 1163, 'delivery': 1164, 'competition': 1165, 'magement': 1166, 'proj': 1167, 'solution': 1168, 'stud': 1169, 'membership': 1170, 'fast': 1171, 'differentiated': 1172, 'fixed': 1173, 'aug': 1174, 'electrician': 1175, 'dist': 1176, 'srvc': 1177, 'emp': 1178, 'prov': 1179, 'hst': 1180, 'dispatcher': 1181, 'copy': 1182, 'courier': 1183, 'lpn': 1184, 'jrotc': 1185, 'carpenter': 1186, 'acctblty': 1187, 'tennis': 1188, 'tanf': 1189, 'faculty': 1190, 'held': 1191, 'autism': 1192, 'turn': 1193, 'around': 1194, 'subject': 1195, 'hear': 1196, 'adaptive': 1197, 'st': 1198, 'audit': 1199, 'americorps': 1200, 'vacation': 1201, 'mentally': 1202, 'painter': 1203, 'equp': 1204, 'find': 1205, 'et': 1206, 'test': 1207, 'sat': 1208, 'ose': 1209, 'cate': 1210, 'ayp': 1211, 'cheerleader': 1212, 'disabilit': 1213, 'laborer': 1214, 'americorp': 1215, 'staffing': 1216, 'comptrolle': 1217, 'nondisciplinary': 1218, 'supervision': 1219, 'av': 1220, 'help': 1221, 'amd': 1222, 'fs': 1223, 'one': 1224, 'dance': 1225, 'mast': 1226, 'def': 1227, 'baseball': 1228, 'economic': 1229, 'advanc': 1230, 'gasoline': 1231, 'itemge': 1232, 'hygiene': 1233, 'translator': 1234, 'database': 1235, 'upgrade': 1236, 'acct': 1237, 'plumber': 1238, 'jr': 1239, 'ssig': 1240, 'printer': 1241, 'agreement': 1242, 'engineer': 1243, 'terminated': 1244, 'stipend': 1245, 'payout': 1246, 'advertising': 1247, 'pac': 1248, 'fixture': 1249, 'fundamental': 1250, 'holding': 1251, 'practical': 1252, 'ah': 1253, 'vh': 1254, 'scholar': 1255, 'exception': 1256, 'creating': 1257, 'rev': 1258, 'july': 1259, 'continuing': 1260, '720': 1261, 'connection': 1262, 'online': 1263, 'sk': 1264, 'cooperating': 1265, 'z': 1266, 'bdg': 1267, 'olympics': 1268, 'drama': 1269, 'adopted': 1270, 'expansion': 1271, 'stadium': 1272, 'innovative': 1273, 'unacceptable': 1274, 'prev': 1275, 'itemah': 1276, 'drop': 1277, 'oversight': 1278, 'working': 1279, 'cent': 1280, 'regional': 1281, 'consortium': 1282, 'cec': 1283, 'ni': 1284, 'au': 1285, 'aefla': 1286, 'lay': 1287, 'referral': 1288, 'suspension': 1289, 'cross': 1290, 'assurance': 1291, 'reporting': 1292, 'mech': 1293, 'repl': 1294, 'treatment': 1295, 'steam': 1296, 'itemai': 1297, 'sasi': 1298, 'pta': 1299, 'containd': 1300, 'headstart': 1301, 'remodeling': 1302, 'cabinet': 1303, 'disbursing': 1304, 'print': 1305, 'exempt': 1306, 'behav': 1307, 'floor': 1308, 'civics': 1309, 'reimbur': 1310, 'subsidy': 1311, 'inclus': 1312, 'scholarship': 1313, 'itemy': 1314, 'growth': 1315, 'old': 1316, 'peer': 1317, 'surgical': 1318, 'plan': 1319, 'clk': 1320, 'mo': 1321, 'inclusion': 1322, 'on': 1323, 'acctg': 1324, 'implementation': 1325, 'mail': 1326, 'iia': 1327, 'qualty': 1328, 'goal': 1329, 'mon': 1330, 'via': 1331, 'bd': 1332, 'therap': 1333, 'generalist': 1334, 'paperback': 1335, 'mag': 1336, 'dedicated': 1337, 'auditor': 1338, 'birth': 1339, 'defined': 1340, 'grouping': 1341, 'bonding': 1342, 'ad': 1343, 'footbll': 1344, 'gratuity': 1345, 'secure': 1346, 'sweeper': 1347, 'shipping': 1348, 'hqt': 1349, 'warehouseman': 1350, 'shop': 1351, 'differen': 1352, 'highly': 1353, 'end': 1354, 'buyer': 1355, 'reform': 1356, 'sc': 1357, 'treasurer': 1358, 'accnts': 1359, 'determination': 1360, 'elect': 1361, 'flexible': 1362, 'expert': 1363, 'ti': 1364, 'campbell': 1365, 'nc': 1366, 'itemag': 1367, 'alrms': 1368, 'intrcom': 1369, 'design': 1370, 'hydronic': 1371, 'sept': 1372, 'collection': 1373, 'large': 1374, 'bump': 1375, 'resolution': 1376, 'detention': 1377, 'fr': 1378, 'itemgf': 1379, 'exam': 1380, 'mesa': 1381, 'room': 1382, 'acad': 1383, 'stu': 1384, 'country': 1385, 'golf': 1386, 'chemistry': 1387, 'vendor': 1388, 'distance': 1389, 'consolidated': 1390, 'truancy': 1391, 'consulting': 1392, 'east': 1393, 'club': 1394, 'cen': 1395, 'ia': 1396, 'member': 1397, 'sheet': 1398, 'feeding': 1399, 'expendable': 1400, 'collaborative': 1401, 'cheerleading': 1402, 'atrt': 1403, 'ely': 1404, 'chi': 1405, 'reimbursable': 1406, 'softball': 1407, 'aircraft': 1408, 'wae': 1409, 'making': 1410, 'itemk': 1411, 'votec': 1412, 'sound': 1413, 'spe': 1414, 'studnt': 1415, 'french': 1416, 'plus': 1417, 'prevent': 1418, 'visually': 1419, 'playground': 1420, 'coverings': 1421, 'directo': 1422, 'report': 1423, 'banquet': 1424, 'donatio': 1425, 'ofcr': 1426, 'priority': 1427, 'dean': 1428, 'attendant': 1429, 'itemj': 1430, 'techician': 1431, 'registered': 1432, 'ldr': 1433, 'guid': 1434, 'meal': 1435, 'neighbrhd': 1436, 'mhuw': 1437, 'anlyt': 1438, 'servi': 1439, 'desk': 1440, 'passroom': 1441, 'qa': 1442, 'comprehensive': 1443, 'journalism': 1444, 'up': 1445, 'itemb': 1446, 'ctl': 1447, 'occ': 1448, 'prescl': 1449, 'action': 1450, 'shs': 1451, 'vocal': 1452, 'unemployment': 1453, 'kinderagrten': 1454, 'prek': 1455, 'june': 1456, 'budg': 1457, 'analysis': 1458, 'nbpts': 1459, 'section': 1460, 'ec': 1461, 'score': 1462, 'nvfb': 1463, 'emergency': 1464, 'university': 1465, 'ged': 1466, 'wrestling': 1467, 'itemac': 1468, 'cst': 1469, 'itemfd': 1470, 'kindergatn': 1471, 'cio': 1472, 'cto': 1473, 'minority': 1474, 'cf': 1475, 'speced': 1476, 'pl': 1477, 'asbestos': 1478, 'camera': 1479, 'alliance': 1480, 'esco': 1481, 'x': 1482, 'operatns': 1483, 'institutions': 1484, 'neg': 1485, 'paintng': 1486, 'watrproofng': 1487, 'cashier': 1488, 'trans': 1489, 'ft': 1490, 'investigator': 1491, 'air': 1492, 'millwright': 1493, 'dual': 1494, 'remodel': 1495, 'intel': 1496, 'isef': 1497, 'outre': 1498, 'international': 1499, 'metal': 1500, 'startup': 1501, 'claiming': 1502, 'gap': 1503, 'debate': 1504, 'bks': 1505, 'write': 1506, 'power': 1507, 'fair': 1508, 'engage': 1509, 'culture': 1510, 'fac': 1511, 'cop': 1512, 'itema': 1513, 'tba': 1514, 'ard': 1515, 'statistical': 1516, 'base': 1517, 'div': 1518, 'boost': 1519, 'logistics': 1520, 'fnd': 1521, 'inclusive': 1522, 'benchmark': 1523, 'housekeeping': 1524, 'overcrowding': 1525, 'qc': 1526, 'subaward': 1527, 'park': 1528, 'stim': 1529, 'train': 1530, 'shared': 1531, 'er': 1532, 'develpmt': 1533, 'hlth': 1534, 'gnets': 1535, 'locksmith': 1536, 'chdrn': 1537, 'receiver': 1538, 'brkfast': 1539, 'aids': 1540, 'eis': 1541, 'xtr': 1542, 'cocurriculum': 1543, 'prgm': 1544, 'best': 1545, 'interest': 1546, 'event': 1547, 'teen': 1548, 'character': 1549, 'typing': 1550, 'discretionary': 1551, 'bckflw': 1552, 'irrig': 1553, 'law': 1554, 'busn': 1555, 'intr': 1556, 'oh': 1557, 'sftball': 1558, 'salaried': 1559, 'intellect': 1560, 'certification': 1561, 'change': 1562, 'parnt': 1563, 'famly': 1564, 'involvmt': 1565, 'coalit': 1566, 'mimh': 1567, 'mildly': 1568, 'scheduler': 1569, 'j': 1570, 'interscholastic': 1571, 'annual': 1572, 'hris': 1573, 'behalf': 1574, 'demostration': 1575, 'lssp': 1576, 'roofing': 1577, 'rem': 1578, 'ib': 1579, 'step': 1580, 'neighborhood': 1581, 'ap': 1582, 'coac': 1583, 'closing': 1584, 'employ': 1585, 'affair': 1586, 'cable': 1587, 'assesment': 1588, 'mental': 1589, 'analy': 1590, 'lacrosse': 1591, 'itemgh': 1592, 'challenge': 1593, 'che': 1594, 'wk': 1595, 'collaboratives': 1596, 'experience': 1597, 'bilingua': 1598, 'agriscience': 1599, 'graphic': 1600, 'bb': 1601, 'itemab': 1602, 'church': 1603, 'absence': 1604, 'vertical': 1605, 'cov': 1606, 'fdtn': 1607, 'conf': 1608, 'hea': 1609, 'governance': 1610, 'boot': 1611, 'eqpt': 1612, 'deli': 1613, 'supporting': 1614, 'operated': 1615, 'theatre': 1616, 'ceo': 1617, 'voluntary': 1618, 'fica': 1619, 'equipmnt': 1620, 'notification': 1621, 'fleet': 1622, 'aid': 1623, 'body': 1624, 'auditing': 1625, 'residential': 1626, 'physic': 1627, 'cota': 1628, 'beh': 1629, 'counsel': 1630, 'suspen': 1631, 'mstr': 1632, 'alrm': 1633, 'classroon': 1634, 'collabo': 1635, 'observer': 1636, 'friend': 1637, 'iniative': 1638, 'assgmt': 1639, 'itemo': 1640, 'response': 1641, 'army': 1642, 'lotc': 1643, 'redemption': 1644, 'bilngl': 1645, 'capacity': 1646, 'lng': 1647, 'agricultural': 1648, 'cap': 1649, 'telecom': 1650, 'diagnostician': 1651, 'theater': 1652, '70hrs': 1653, 'culinary': 1654, '80': 1655, 'brick': 1656, 'emis': 1657, 'itemx': 1658, 'fm': 1659, 'landscape': 1660, 'renovations': 1661, 'agriculture': 1662, 'fix': 1663, 'facilites': 1664, 'ffe': 1665, 'coordinated': 1666, 'itempp': 1667, 'proc': 1668, 'intentional': 1669, 'digital': 1670, 'client': 1671, 'itemn': 1672, 'plancement': 1673, 'baccalaurate': 1674, 'playoff': 1675, 'itemaj': 1676, 'arboreal': 1677, 'newcomer': 1678, 'collaorative': 1679, 'tv': 1680, 'rsb': 1681, 'itemz': 1682, 'ogt': 1683, 'assmt': 1684, 'kindergarden': 1685, 'assgn': 1686, 'honor': 1687, 'model': 1688, 'gt': 1689, 'eg': 1690, 'installation': 1691, 'higher': 1692, 'sign': 1693, 'ribbon': 1694, 'dropout': 1695, 'return': 1696, 'coun': 1697, 'mariachi': 1698, 'technlgies': 1699, 'violence': 1700, 'mf': 1701, 'fa': 1702, 'sh': 1703, 'fvs': 1704, 'ameritech': 1705, 'u': 1706, 'usage': 1707, 'automation': 1708, 'natl': 1709, 'marching': 1710, 'partner': 1711, 'way': 1712, 'tst': 1713, 'swap': 1714, 'attend': 1715, 'emotional': 1716, 'chorus': 1717, 'succeed': 1718, 'within': 1719, 'de': 1720, 'schooled': 1721, 'production': 1722, 'itemaf': 1723, 'contributing': 1724, 'commerc': 1725, 'sponsor': 1726, 'mind': 1727, 'george': 1728, 'dose': 1729, 'vfb': 1730, 'bl': 1731, 'healthy': 1732, 'wealth': 1733, 'conservation': 1734, 'oil': 1735, 'geography': 1736, 'depreciation': 1737, 'rm': 1738, 'diploma': 1739, '6th': 1740, 'volunteer': 1741, 'env': 1742, 'another': 1743, 'msp': 1744, 'liason': 1745, 'positive': 1746, 'fitfun': 1747, 'bo': 1748, 'discipl': 1749, 'transp': 1750, 'recruiter': 1751, 'diversified': 1752, 'behavorial': 1753, 'entrprs': 1754, 'tobacco': 1755, 'blind': 1756, 'income': 1757, 'supl': 1758, 'inv': 1759, 'instructn': 1760, 'literac': 1761, 'grass': 1762, 'cutter': 1763, 'pack': 1764, 'disk': 1765, 'im': 1766, 'commercial': 1767, 'name': 1768, 'provision': 1769, 'tomor': 1770, 'itemg': 1771, 'regulr': 1772, 'swimming': 1773, 'drill': 1774, 'ohio': 1775, 'united': 1776, 'issue': 1777, 'ml': 1778, 'expend': 1779, 'dramatics': 1780, 'climate': 1781, 'justice': 1782, 'raising': 1783, 'bar': 1784, 'space': 1785, 'therp': 1786, 'messenger': 1787, 'destination': 1788, 'imagination': 1789, 'process': 1790, 'roofer': 1791, 'mycom': 1792, 'sn': 1793, 'programs': 1794, 'r': 1795, 'tool': 1796, 'countr': 1797, 'pep': 1798, 'recycling': 1799, 'gi': 1800, 'marzano': 1801, 'per': 1802, 'grease': 1803, 'grds': 1804, 'portable': 1805, 'submission': 1806, 'chef': 1807, 'orthopedically': 1808, 'assembler': 1809, 'gift': 1810, 'enhancing': 1811, 'christian': 1812, 'sol': 1813, 'publishing': 1814, 'profound': 1815, 'sv': 1816, 'multicult': 1817, 'parenting': 1818, 'hvy': 1819, 'rte': 1820, 'diesel': 1821, 'federation': 1822, 'boiler': 1823, 'pest': 1824, 'biling': 1825, 'books': 1826, '5': 1827, 'competency': 1828, 'rsrch': 1829, 'cntr': 1830, 'condition': 1831, 'scl': 1832, 'assur': 1833, 'slp': 1834, 'whiz': 1835, 'chrtr': 1836, 'conditioning': 1837, 'tchrs': 1838, 'contracting': 1839, 'grow': 1840, 'great': 1841, 'hi': 1842, 'dyslexia': 1843, 'fdn': 1844, 'itemad': 1845, 'plasterer': 1846, 'council': 1847, 'dollar': 1848, 'ld': 1849, 'tsa': 1850, 'others': 1851, 'mini': 1852, 'cosmotology': 1853, 'psc': 1854, 'mediation': 1855, 'implement': 1856, 'leadman': 1857, 'house': 1858, 'vesp': 1859, 'recrui': 1860, 'develpmnt': 1861, 'grad': 1862, 'charity': 1863, 'upk': 1864, 'intelligence': 1865, 'may': 1866, 'abc': 1867, 'facil': 1868, 'pal': 1869, 'astii': 1870, 'sexual': 1871, 'progrm': 1872, 'leased': 1873, 'conflict': 1874, 'fd': 1875, 'webinars': 1876, 'amendment': 1877, 'deseg': 1878, 'processor': 1879, 'bricklayer': 1880, 'del': 1881, 'policy': 1882, 'rock': 1883, 'appeal': 1884, 'insulator': 1885, 'diff': 1886, 'iid': 1887, 'selection': 1888, 'carry': 1889, 'bank': 1890, 'puppetry': 1891, 'tr': 1892, 'smed': 1893, 'whse': 1894, 'ret': 1895, 'nonbenefitted': 1896, 'envision': 1897, 'colorado': 1898, 'candy': 1899, 'ecse': 1900, 'side': 1901, 'workforce': 1902, 'rpr': 1903, 'ass': 1904, 'take': 1905, 'pension': 1906, 'intell': 1907, 'postsecondary': 1908, 'designated': 1909, 'acqu': 1910, 'kindrng': 1911, 'robotics': 1912, 'instrument': 1913, 'setaside': 1914, 'barrier': 1915, 'breaker': 1916, 'chem': 1917, 'equity': 1918, 'bsktbl': 1919, 'cabinetmaker': 1920, 'bottled': 1921, 'photography': 1922, 'cohort': 1923, 'charitable': 1924, 'pr': 1925, 'tire': 1926, 'fruit': 1927, 'geographic': 1928, 'cclc': 1929, 'alarm': 1930, 'orientation': 1931, 'anticipated': 1932, 'prim': 1933, 'fuse': 1934, 'cor': 1935, 'struggler': 1936, 'yth': 1937, 'loss': 1938, 'portables': 1939, 'sam': 1940, 'ends': 1941, 'mentorship': 1942, 'fin': 1943, 'ez': 1944, 'urog': 1945, 'combustion': 1946, 'play': 1947, 'provide': 1948, 'inspector': 1949, 'readi': 1950, 'string': 1951, 'instnl': 1952, 'edu': 1953, 'immunization': 1954, 'ref': 1955, 'feed': 1956, 'cdr': 1957, 'groundskeeper': 1958, 'audiology': 1959, 'aob': 1960, 'disposal': 1961, 'controller': 1962, 'negl': 1963, 'healty': 1964, 'dpia': 1965, 'restructuring': 1966, 'flag': 1967, 'investment': 1968, 'pipe': 1969, 'retired': 1970, 'scnd': 1971, 'bi': 1972, 'ba': 1973, 'itemc': 1974, 'rent': 1975, 'homegrown': 1976, 'pavement': 1977, 'invntry': 1978, 'architect': 1979, 'behavioral': 1980, 'liasons': 1981, 'smart': 1982, 'cntrl': 1983, 'cnslg': 1984, 'electronics': 1985, 'theat': 1986, 'dram': 1987, 'includes': 1988, 'developer': 1989, 'smh': 1990, 'trng': 1991, 'caretaker': 1992, 'boys': 1993, 'broad': 1994, 'grp': 1995, 'cover': 1996, 'tile': 1997, 'recreational': 1998, 'even': 1999, 'donations': 2000, 'ttl': 2001, 'dhh': 2002, 'linkage': 2003, 'trainee': 2004, 'homebased': 2005, 'girls': 2006, 'multicultural': 2007, 'nestle': 2008, 'jrvar': 2009, 'nwsppr': 2010, 'yrbk': 2011, 'lan': 2012, 'lieutenant': 2013, 'etc': 2014, 'cooperative': 2015, 'severely': 2016, 'retarded': 2017, 'bp': 2018, 'mil': 2019, 'jhs': 2020, 'mckinney': 2021, 'maj': 2022, 'expand': 2023, 'addition': 2024, 'strat': 2025, 'enrollment': 2026, 'mobility': 2027, 'ath': 2028, 'braille': 2029, 'mea': 2030, 'latin': 2031, 'professiona': 2032, 'profit': 2033, 'etech': 2034, 'trustee': 2035, 'sb': 2036, 'badge': 2037, 'netwrk': 2038, 'syst': 2039, 'parking': 2040, 'petro': 2041, 'vend': 2042, 'fluid': 2043, 'suppression': 2044, 'coll': 2045, 'chllnge': 2046, 'integr': 2047, 'leasehold': 2048, 'apprentice': 2049, 'instrc': 2050, 'delinq': 2051, 'institut': 2052, 'chiller': 2053, 'absorber': 2054, 'stock': 2055, 'diagnostic': 2056, 'assign': 2057, 'industy': 2058, 'farm': 2059, 'exeter': 2060, 'world': 2061, 'nsf': 2062, 'addit': 2063, 'cosmetology': 2064, 'foundat': 2065, 'sergeant': 2066, 'projects': 2067, 'financia': 2068, 'itemi': 2069, 'cch': 2070, 'ininerant': 2071, 'tti': 2072, 'assista': 2073, 'coating': 2074, 'criminal': 2075, 'nw': 2076, 'ymca': 2077, 'political': 2078, 'developmen': 2079, 'misical': 2080, 'empowerment': 2081, 'printshop': 2082, 'annex': 2083, 'epa': 2084, 'tester': 2085, 'chinese': 2086, 'reader': 2087, 'automotive': 2088, 'specia': 2089, 'strengthen': 2090, 'suppor': 2091, 'barbering': 2092, 'believer': 2093, 'similar': 2094, 'lua': 2095, 'population': 2096, 'publication': 2097, 'tch': 2098, 'uil': 2099, 'volly': 2100, 'trainr': 2101, 'resp': 2102, 'interim': 2103, 'resettlement': 2104, 'nursery': 2105, 'coteaching': 2106, 'cluster': 2107, 'exploring': 2108, 'hstw': 2109, 'wal': 2110, 'mart': 2111, 'cente': 2112, 'excl': 2113, 'star': 2114, 'healthier': 2115, 'psy': 2116, 'hurricane': 2117, 'destructive': 2118, 'decision': 2119, 'academ': 2120, 'lvl': 2121, 'empl': 2122, 'itemaa': 2123, 'insti': 2124, 'crit': 2125, 'five': 2126, 'toolroom': 2127, 'mentoring': 2128, 'chancellor': 2129, 'keybank': 2130, 'ind': 2131, 'deep': 2132, 'gymnastics': 2133, 'global': 2134, 'painting': 2135, 'competitive': 2136, 'advocate': 2137, 'inno': 2138, 'issn': 2139, 'lw': 2140, 'summ': 2141, 'genl': 2142, 'con': 2143, 'government': 2144, 'ther': 2145, 'englsh': 2146, 'wrest': 2147, 'adapt': 2148, 'key': 2149, 'integrated': 2150, 'hh': 2151, 'investigation': 2152, 'placem': 2153, 'kndgarten': 2154, 'sews': 2155, 'chal': 2156, 'rel': 2157, 'mailroom': 2158, 'compr': 2159, 'agent': 2160, 'acc': 2161, 'fsd': 2162, 'subclass': 2163, 'led': 2164, 'sal': 2165, 'sharepoint': 2166, 'dike': 2167, 'road': 2168, 'snack': 2169, 'autonamy': 2170, 'intl': 2171, 'auto': 2172, 'pregn': 2173, 'expans': 2174, 'guarantee': 2175, 'itemae': 2176, 'net': 2177, 'podcasting': 2178, 'wrk': 2179, 'op': 2180, 'inn': 2181, 'mn': 2182, 'protective': 2183, 'elev': 2184, 'celeb': 2185, 'eff': 2186, 'cao': 2187, 'renv': 2188, 'hub': 2189, 'fyii': 2190, 'cad': 2191, 'rode': 2192, 'phase': 2193, 'portio': 2194, 'contemporary': 2195, 'zuni': 2196, 'jcf': 2197, 'real': 2198, 'estate': 2199, 'asfepa': 2200, 'itemya': 2201, 'oni': 2202, 'hof': 2203, 'acti': 2204, 'constuction': 2205, 'banking': 2206, 'bureau': 2207, 'thnk': 2208, 'height': 2209, 'tube': 2210, 'acquis': 2211, 'ppg': 2212, 'hat': 2213, 'furnishing': 2214, 'corporal': 2215, 'gator': 2216, 'encounter': 2217, 'participation': 2218, 'cheerlea': 2219, 'interntl': 2220, 'ovac': 2221, 'hand': 2222, 'potential': 2223, 'constrct': 2224, 'occup': 2225, 'volleyb': 2226, 'cornerstone': 2227, 'ph': 2228, 'activties': 2229, 'aba': 2230, 'therapeutic': 2231, 'restorative': 2232, 'cc': 2233, 'coo': 2234, 'future': 2235, 'fy2': 2236, 'equine': 2237, 'subst': 2238, 'odnr': 2239, 'stance': 2240, 'video': 2241, 'acting': 2242, 'direc': 2243, 'stdnt': 2244, 'administrat': 2245, 'assn': 2246, 'vegetable': 2247, 'homework': 2248, 'buy': 2249, '7': 2250, 'char': 2251, 'gir': 2252, 'intrn': 2253, 'flat': 2254, 'sadd': 2255, 'techaide': 2256, 'datacoord': 2257, 'mandel': 2258, 'advances': 2259, 'appliance': 2260, 'clout': 2261, 'appl': 2262, 'grnt': 2263, 'spring': 2264, 'bacc': 2265, 'jv': 2266, 'ahc': 2267, 'footbl': 2268, 'volbl': 2269, 'varfb': 2270, 'tm': 2271, 'diagnosticia': 2272, 'sustainability': 2273, 'cr': 2274, 'ets': 2275, 'amer': 2276, 'rn': 2277, 'lost': 2278, 'damaged': 2279, '70hs': 2280, 'dietary': 2281, 'tag': 2282, 'mile': 2283, 'suppl': 2284, 'te': 2285, 'ksu': 2286, 'coalition': 2287, 'mcdonald': 2288, 'rite': 2289, 'finan': 2290, 'respon': 2291, 'itemd': 2292, 'dec': 2293, 'completion': 2294, 'age': 2295, 'reduction': 2296, 'green': 2297, 'code': 2298, 'pbs': 2299, 'maanger': 2300, 'fall': 2301, 'uniform': 2302, 'combination': 2303, 'point': 2304, 'dep': 2305, 'search': 2306, 'visio': 2307, 'current': 2308, 'nfl': 2309, 'ldbd': 2310, 'tmo': 2311, 'fencing': 2312, 'wildlife': 2313, 'equivalent': 2314, 'dipl': 2315, 'doctorate': 2316, 'german': 2317, 'asia': 2318, 'society': 2319, 'req': 2320, 'month': 2321, 'collaboration': 2322, 'august': 2323, 'provider': 2324, 'artist': 2325, 'tea': 2326, 'pedestrian': 2327, 'bicycle': 2328, 'faci': 2329, 'baseb': 2330, 'fto': 2331, 'baccalaureate': 2332, 'pri': 2333, 'supprt': 2334, 'agricul': 2335, 'fingerprinting': 2336, 'propos': 2337, 'match': 2338, 'dvlp': 2339, 'harvard': 2340, 'scienc': 2341, 'discovery': 2342, 'cti': 2343, 'desktop': 2344, 'collaborat': 2345, 'ronald': 2346, 'respons': 2347, 'customized': 2348, 'devel': 2349, 'metalwks': 2350, 'extg': 2351, 'grt': 2352, 'scc': 2353, 'swing': 2354, 'suite': 2355, 'ctag': 2356, 'hiv': 2357, 'prop': 2358, 'specialis': 2359, 'liability': 2360, 'nike': 2361, 'hist': 2362, 'cong': 2363, 'visiting': 2364, 'init': 2365, 'nonathletic': 2366, 'japanese': 2367, 'reimb': 2368, 'treasury': 2369, 'southern': 2370, 'anschut': 2371, 'otr': 2372, 'oak': 2373, 'bible': 2374, '4': 2375, 'thats': 2376, 'itempq': 2377, 'deve': 2378, 'wall': 2379, 'claim': 2380, 'stems': 2381, 'autistic': 2382, 'traffic': 2383, 'discipline': 2384, 'counter': 2385, 'mang': 2386, 'covered': 2387, 'advertisement': 2388, 'coupon': 2389, 'compl': 2390, 'right': 2391, 'settlement': 2392, 'rd': 2393, 'forensics': 2394, 'screener': 2395, 'su': 2396, 'softb': 2397, 'squad': 2398, 'procure': 2399, 'traditional': 2400, 'rifle': 2401, 'mtl': 2402, 'progr': 2403, 'bakery': 2404, 'trw': 2405, 'catholic': 2406, 'engin': 2407, 'la': 2408, 'teacehr': 2409, 'partnrs': 2410, 'initiatvs': 2411, 'option': 2412, 'veggie': 2413, 'par': 2414, 'contingency': 2415, 'refunding': 2416, 'sched': 2417, 'traditiona': 2418, 'spons': 2419, 'acte': 2420, 'show': 2421, 'attendence': 2422, 'ada': 2423, 'crt': 2424, 'brd': 2425, 'white': 2426, 'ercm': 2427, 'prvntn': 2428, 'intrvnt': 2429, 'answer': 2430, 'welcome': 2431, 'collision': 2432, 'outrch': 2433, 'spclst': 2434, 'resale': 2435, 'transfers': 2436, 'allcity': 2437, 'wc': 2438, 'pass': 2439, 'through': 2440, 'protectv': 2441, 'publish': 2442, 'adminis': 2443, 'preparatory': 2444, 'chosen': 2445, 'jf': 2446, 'desauze': 2447, 'extracurricula': 2448, 'rt': 2449, 'get': 2450, 'fit': 2451, 'psych': 2452, 'beginning': 2453, 'accessory': 2454, 'milk': 2455, 'dvlpmnt': 2456, 'speclst': 2457, 'traveling': 2458, 'devp': 2459, 'fun': 2460, 'ctemp': 2461, 'moc': 2462, 'translation': 2463, 'architectural': 2464, 'map': 2465, 'assistive': 2466, 'suppt': 2467, 'next': 2468, 'kind': 2469, 'pm': 2470, 'fine': 2471, 'graph': 2472, 'basebl': 2473, 'em': 2474, 'tran': 2475, 'diag': 2476, 'vac': 2477, 'combin': 2478, 'routing': 2479, 'offset': 2480, 'avenue': 2481, 'dvl': 2482, 'stds': 2483, 'implemnt': 2484, 'disabled': 2485, 'environmental': 2486, 'implm': 2487, 'col': 2488, 'heart': 2489, 'develop': 2490, 'fresh': 2491, 'statistician': 2492, 'ana': 2493, 'cty': 2494, 'eclar': 2495, 'carreer': 2496, 'voyager': 2497, 'enterprs': 2498, 'liter': 2499, 'bga': 2500, '56': 2501, 'responsible': 2502, 'behavi': 2503, 'developmentally': 2504, 'hndcpd': 2505, 'blk': 2506, 'lem': 2507, 'deductible': 2508, 'lowe': 2509, 'ecea': 2510, 'itemwz': 2511, 'steele': 2512, 'planetarium': 2513, 'offr': 2514, 'rdg': 2515, 'jul': 2516, 'retire': 2517, 'exploration': 2518, 'thriving': 2519, 'feb': 2520, 'jun': 2521, 'fasd': 2522, 'forum': 2523, 'humanware': 2524, 'writer': 2525, 'lib': 2526, 'rsrc': 2527, 'judgment': 2528, 'pla': 2529, 'intergovernment': 2530, 'homebnd': 2531, 'desktp': 2532, 'analyiii': 2533, 'dpa': 2534, 'inven': 2535, 'proportionate': 2536, 'funds': 2537, 'alcolhol': 2538, 'composition': 2539, 'staple': 2540, 'condiment': 2541, 'kappa': 2542, 'apprec': 2543, 'inquiry': 2544, 'pioneer': 2545, 'stand': 2546, 'grwpln': 2547, 'jail': 2548, 'afjrotc': 2549, 'foodsrv': 2550, 'caregiver': 2551, 'incentiv': 2552, 'exper': 2553, 'stone': 2554, 'truant': 2555, 'us': 2556, 'qwest': 2557, 'earth': 2558, 'bbb': 2559, 'west': 2560, 'bnc': 2561, 'mngr': 2562, 'accoun': 2563, 'realoc': 2564, 'unused': 2565, 'museum': 2566, 'transportaion': 2567, 'equipmen': 2568, 'cie': 2569, 'president': 2570, 'manufacturing': 2571, 'guitar': 2572, 'structure': 2573, 'erate': 2574, 'busines': 2575, 'ae': 2576, 'asthma': 2577, 'beyond': 2578, 'audiovisual': 2579, 'generic': 2580, 'concussion': 2581, 'swim': 2582, 'brother': 2583, 'keep': 2584, 'majr': 2585, 'twice': 2586, 'preparing': 2587, 'transitory': 2588, 'face': 2589, 'transformatio': 2590, 'residency': 2591, 'rtrs': 2592, 'collabor': 2593, 'router': 2594, 'ge': 2595, 'industria': 2596, 'inf': 2597, 'instrctn': 2598, 'appraisal': 2599, 'audio': 2600, 'groundwork': 2601, 'tru': 2602, 'tra': 2603, 'costume': 2604, 'samsa': 2605, 'noneducation': 2606, 'substance': 2607, 'abuse': 2608, 'dispatc': 2609, 'pol': 2610, 'elctrn': 2611, 'yearbook': 2612, 'journalis': 2613, 'kp': 2614, 'preshool': 2615, 'al': 2616, 'dsk': 2617, 'tosas': 2618, 'typist': 2619, 'cls': 2620, 'highway': 2621, 'pump': 2622, 'engmnt': 2623, 'psychometrician': 2624, 'indust': 2625, 'panasonic': 2626, 'pnsca': 2627, 'multihandicapped': 2628, 'intg': 2629, 'voe': 2630, 'ca': 2631, 'advantage': 2632, 'gardner': 2633, 'nsta': 2634, 'nasa': 2635, 'explorer': 2636, 'duplicator': 2637, 'layered': 2638, 'poly': 2639, 'hous': 2640, 'ett': 2641, 'atwll': 2642, 'connectivity': 2643, 'let': 2644, 'lli': 2645, 'itemgi': 2646, 'restr': 2647, 'rotary': 2648, 'addtn': 2649, 'designer': 2650, 'associate': 2651, 'leading': 2652, 'juvenile': 2653, 'dental': 2654, 'subpart': 2655, 'thro': 2656, 'itemq': 2657, 'stabilization': 2658, 'gallagher': 2659, 'noncert': 2660, 'sme': 2661, 'exe': 2662, 'reim': 2663, 'aft': 2664, 'fsfoa': 2665, 'pepsi': 2666, 'assi': 2667, 'suprv': 2668, 'transportion': 2669, 'integration': 2670, 'chp': 2671, 'enroll': 2672, 'min': 2673, 'walk': 2674, 'dot': 2675, 'adminstrative': 2676, 'shakespeare': 2677, 'festival': 2678, 'consult': 2679, 'numeracy': 2680, 'benef': 2681, 'marion': 2682, 'sterling': 2683, 'oi': 2684, 'sex': 2685, 'bulk': 2686, 'champion': 2687, 'planner': 2688, 'materials': 2689, 'steamfitter': 2690, 'itemfb': 2691, 'promise': 2692, 'receptionist': 2693, 'fellowship': 2694, 'recruit': 2695, 'memorial': 2696, 'black': 2697, 'gc': 2698, 'environ': 2699, 'lock': 2700, 'prnt': 2701, 'lutheran': 2702, 'employment': 2703, 'ita': 2704, 'daily': 2705, 'detective': 2706, 'invest': 2707, 'cler': 2708, 'chld': 2709, 'hw': 2710, 'tourism': 2711, 'hosp': 2712, 'hotel': 2713, 'mat': 2714, 'internship': 2715, 'itinerate': 2716, 'proff': 2717, 'phi': 2718, 'trai': 2719, 'broadcasting': 2720, 'aftercare': 2721, 'org': 2722, 'mound': 2723, 'acadmey': 2724, 'result': 2725, 'plcmt': 2726, 'serial': 2727, 'refund': 2728, 'prior': 2729, 'dancing': 2730, 'outside': 2731, 'street': 2732, 'positoin': 2733, 'programming': 2734, 'retrofit': 2735, 'matrls': 2736, 'coa': 2737, 'mangr': 2738, 'servs': 2739, 'strt': 2740, 'gems': 2741, 'trainin': 2742, 'heating': 2743, 'exps': 2744, 'profnd': 2745, 'vento': 2746, 'superintentents': 2747, 'interactive': 2748, 'envrmntl': 2749, 'mtg': 2750, 'lts': 2751, 'mem': 2752, 'itemgc': 2753, 'arch': 2754, 'expanding': 2755, 'technlogie': 2756, 'cnflct': 2757, 'hb': 2758, 'bookr': 2759, 'trav': 2760, 'strive': 2761, 'esthetician': 2762, 'alao': 2763, 'itemfg': 2764, 'pregnancy': 2765, 'impa': 2766, 'deb': 2767, 'inform': 2768, 'meat': 2769, 'affiliate': 2770, 'carnegie': 2771, 'kindegarten': 2772, 'schoolnet': 2773, 'link': 2774, 'clean': 2775, 'foun': 2776, 'max': 2777, 'prgrm': 2778, 'bolto': 2779, 'managemen': 2780, 'saftey': 2781, 'praxis': 2782, 'fapt': 2783, 'symposium': 2784, 'carryforward': 2785, 'cisco': 2786, 'voip': 2787, 'orl': 2788, 'examiner': 2789, 'fdlrs': 2790, 'resident': 2791, 'cpa': 2792, 'employees': 2793, 'cnfrn': 2794, 'rnvsafesc': 2795, 'ntwk': 2796, 'retention': 2797, 'carryo': 2798, 'upholstery': 2799, 'glass': 2800, 'clinical': 2801, 'moveable': 2802, 'target': 2803, 'helpline': 2804, 'tomorrow': 2805, 'accompanist': 2806, 'workstudy': 2807, 'sustainabilty': 2808, 'interpretation': 2809, 'grasscutters': 2810, 'dislocated': 2811, 'susp': 2812, 'rbi': 2813, 'depr': 2814, 'lmc': 2815, 'improved': 2816, '60': 2817, 'hsbc': 2818, 'broadcast': 2819, 'clothing': 2820, 'commission': 2821, 'promotion': 2822, 'occp': 2823, 'specalist': 2824, 'suppliment': 2825, 'union': 2826, 'intergovernmental': 2827, 'advncmnt': 2828, 'indiv': 2829, 'determ': 2830, 'montsorri': 2831, 'election': 2832, 'teletype': 2833, 'telegram': 2834, 'orien': 2835, 'mobil': 2836, 'cur': 2837, 'equipt': 2838, 'lld': 2839, 'ctrl': 2840, 'blue': 2841, 'redesign': 2842, 'cultural': 2843, 'inclusiveness': 2844, 'exter': 2845, 'networking': 2846, 'srvs': 2847, 'driveriii': 2848, 'vietnamese': 2849, 'sco': 2850, 'millworker': 2851, 'asbes': 2852, 'abate': 2853, 'spc': 2854, 'ss': 2855, 'dive': 2856, 'vacancy': 2857, 'endowment': 2858, 'itemff': 2859, 'interfund': 2860, 'confer': 2861, 'drafting': 2862, 'loan': 2863, 'coappp': 2864, 'rollout': 2865, 'grwpl': 2866, 'esernv': 2867, 'replacement': 2868, 'subteacher': 2869, 'aha': 2870, 'fmly': 2871, 'healt': 2872, 'allstate': 2873, 'compan': 2874, 'motivation': 2875, 'animal': 2876, 'form': 2877, 'freight': 2878, 'itemm': 2879, 'presch': 2880, 'officemax': 2881, 'facing': 2882, 'ded': 2883, 'dv': 2884, 'achv': 2885, 'manger': 2886, 'disc': 2887, 'reference': 2888, 'foundati': 2889, 'behaviorial': 2890, 'interv': 2891, 'vice': 2892, 'catalyst': 2893, 'gesp': 2894, 'number': 2895, 'rx': 2896, 'prescriptions': 2897, 'car': 2898, 'rentals': 2899, 'diversity': 2900, 'count': 2901, 'positon': 2902, 'partially': 2903, 'sighted': 2904, 'episcopal': 2905, 'jump': 2906, 'region': 2907, 'nutritionist': 2908, 'itemfc': 2909, 'rice': 2910, 'owen': 2911, 'strengthening': 2912, 'invent': 2913, 'insuranc': 2914, 'k12': 2915, 'adie': 2916, 'exceeding': 2917, 'expectation': 2918, 'make': 2919, 'irc': 2920, '80hrs': 2921, 'emerg': 2922, 'prtble': 2923, 'nwcnfrn': 2924, 'connect': 2925, 'healthiest': 2926, 'assitant': 2927, 'masonry': 2928, 'econ': 2929, 'ftes': 2930, 'headstar': 2931, 'gov': 2932, 'impairment': 2933, 'mason': 2934, 'opening': 2935, 'luncheo': 2936, 'ste': 2937, 'dispath': 2938, 'twilight': 2939, 'negotiation': 2940, 'itemhb': 2941, 'directory': 2942, 'ortho': 2943, 'ceis': 2944, 'rti': 2945, 'iss': 2946, 'saving': 2947, 'crisis': 2948, 'shell': 2949, 'princiapl': 2950, 'circle': 2951, 'place': 2952, 'wave': 2953, 'prjt': 2954, 'minute': 2955, 'men': 2956, 'mather': 2957, 'servic': 2958, 'examination': 2959, 'fte': 2960, 'interve': 2961, 'escrow': 2962, 'kng': 2963, 'yrbs': 2964, 'lawyer': 2965, 'infor': 2966, 'offi': 2967, 'modif': 2968, 'captain': 2969, 'shelter': 2970, 'madness': 2971, 'dream': 2972, 'progrming': 2973, 'pub': 2974, 'reimburse': 2975, 'reprod': 2976, 'wrong': 2977, 'po': 2978, 'invol': 2979, 'adl': 2980, 'hate': 2981, 'come': 2982, 'dolgencorp': 2983, 'baker': 2984, 'technolog': 2985, 'boilermaker': 2986, 'wired': 2987, 'optical': 2988, 'irrigation': 2989, 'audiologi': 2990, 'wsd': 2991, 'kept': 2992, 'realty': 2993, 'ctu': 2994, 'release': 2995, 'thinking': 2996, 'philliber': 2997, 'sewerman': 2998, 'cela': 2999, 'accounta': 3000, 'playscape': 3001, 'intn': 3002, 'aud': 3003, 'telec': 3004, 'chf': 3005, 'mult': 3006, 'cntl': 3007, 'electric': 3008, 'intrv': 3009, 'fees': 3010, 'advisory': 3011, 'facilit': 3012, 'carr': 3013, 'msgr': 3014, 'saf': 3015, 'playscapes': 3016, 'sems': 3017, 'algebra': 3018, 'skil': 3019, 'associa': 3020, 'edcuational': 3021, 'document': 3022, 'eaton': 3023, 'buhrer': 3024, 'contro': 3025, 'directr': 3026, 'john': 3027, 'hay': 3028, 'trnr': 3029, 'interagy': 3030, 'zeta': 3031, 'bel': 3032, 'manuf': 3033, 'ub': 3034, 'garfield': 3035, 'singing': 3036, 'searc': 3037, 'sl': 3038, 'liaso': 3039, 'sha': 3040, 'marsh': 3041, 'supportive': 3042, 'pcops': 3043, '70hr': 3044, 'official': 3045, 'itemfe': 3046, 'constit': 3047, 'solid': 3048, 'memo': 3049, 'wf': 3050, 'collinw': 3051, 'habitat': 3052, 'charting': 3053, 'corese': 3054, 'tournament': 3055, 'candle': 3056, 'yellow': 3057, 'enviro': 3058, 'prblm': 3059, 'unicare': 3060, 'corporati': 3061, 'strategist': 3062, 'wrhs': 3063, 'advaned': 3064, 'automechanics': 3065, 'alter': 3066, 'detent': 3067, 'slhs': 3068, 'concept': 3069, 'managemnt': 3070, 'phy': 3071, 'curator': 3072, 'as': 3073, 'insight': 3074, 'wingspread': 3075, 'tinner': 3076, 'actually': 3077, 'employed': 3078, 'foundatio': 3079, 'iteme': 3080, 'itemf': 3081, 'atsp': 3082, 'liceracy': 3083, 'nutritionfacilitator': 3084, 'itemfcco': 3085, 'kra': 3086, 'innov': 3087, 'portfolio': 3088, 'rvas': 3089, 'hannah': 3090, 'gibbon': 3091, 'lung': 3092, 'programmatic': 3093, 'quantity': 3094, 'stratigic': 3095, 'two': 3096, 'upload': 3097, 'rockefe': 3098, 'rpm': 3099, 'wrkr': 3100, 'zone': 3101, 'inventio': 3102, 'intervent': 3103, 'tomr': 3104, 'leisure': 3105, 'percussion': 3106, 'gvr': 3107, 'adapted': 3108, 'every': 3109, 'together': 3110, 'mttrs': 3111, 'offic': 3112, 'command': 3113, 'oai': 3114, 'stretch': 3115, 'cmsd': 3116, 'auditory': 3117, 'licensing': 3118, 'alum': 3119, 'bunch': 3120, 'open': 3121, 'conslt': 3122, 'bowl': 3123, 'initvs': 3124, 'etaa': 3125, 'sectio': 3126, 'copayment': 3127, 'consul': 3128, 'liste': 3129, 'isp': 3130, 'housing': 3131, 'demolition': 3132, 'opportuni': 3133, 'holiday': 3134, 'pedagogy': 3135, 'xmas': 3136, 'aeronaut': 3137, 'fame': 3138, 'october': 3139, 'phonics': 3140, 'mcginty': 3141, 'nsba': 3142, 'sql': 3143, 'hirin': 3144, 'lt': 3145, 'active': 3146, 'perm': 3147, 'currc': 3148, 'communicatio': 3149, 'strate': 3150, 'cohart': 3151, 'except': 3152, 'superv': 3153, 'careeer': 3154, 'technolgies': 3155, 'softall': 3156, 'guiness': 3157, 'donors': 3158, 'onthe': 3159, 'ceramic': 3160, 'reside': 3161, 'binligual': 3162, 'dietician': 3163, 'lic': 3164, 'ombudsman': 3165, 'manag': 3166, 'increment': 3167, 'glazier': 3168, 'tapestry': 3169, 'cde': 3170, 'weekend': 3171, 'backpack': 3172, 'dhr': 3173, 'electr': 3174, 'zoo': 3175, 'ne': 3176, 'restaurant': 3177, 'legl': 3178, 'iteml': 3179, 'hidden': 3180, 'valley': 3181, 'love': 3182, 'cafe': 3183, 'vndg': 3184, 'musi': 3185, 'supvr': 3186, 'decathlon': 3187, 'teachr': 3188, 'think': 3189, 'voice': 3190, 'fitness': 3191, 'dinner': 3192, 'rope': 3193, 'colle': 3194, 'harass': 3195, 'li': 3196, 'childn': 3197, 'sim': 3198, 'schoolwides': 3199, 'store': 3200, 'knowledge': 3201, 'essay': 3202, 'drnge': 3203, 'retntn': 3204, 'constrt': 3205, 'witness': 3206, 'ministr': 3207, 'forng': 3208, 'fairfax': 3209, 'taylor': 3210, 'watterson': 3211, 'biological': 3212, 'playgrd': 3213, 'bolton': 3214, 'gelber': 3215, 'ceu': 3216, 'robotic': 3217, 'mlb': 3218, 'equ': 3219, 'grown': 3220, 'archivist': 3221, 'mallet': 3222, 'collegiate': 3223, 'athle': 3224, 'cbla': 3225, 'beat': 3226, 'csx': 3227, 'news': 3228, 'square': 3229, 'sepc': 3230, 'hhs': 3231, 'retrofif': 3232, 'drum': 3233, 'carrier': 3234, 'ourselve': 3235, 'itemha': 3236, 'maison': 3237, 'francaise': 3238, 'violin': 3239, 'paralegal': 3240, 'msu': 3241, 'reimbursment': 3242, 'aetna': 3243, 'corporatio': 3244, 'duck': 3245, 'timer': 3246, 'scholarsh': 3247, 'ernst': 3248, 'young': 3249, 'faster': 3250, 'ancora': 3251, 'occupancy': 3252, 'ldrship': 3253, 'prgms': 3254, 'accident': 3255, 'janitorial': 3256, 'sherwin': 3257, 'williams': 3258, 'ent': 3259, 'mutual': 3260, 'scholarshi': 3261, 'consultanc': 3262, 'ev': 3263, 'imprv': 3264, 'uniforms': 3265, 'campaign': 3266, 'adminsitrative': 3267, 'anonymous': 3268, 'itemfccentral': 3269, 'curric': 3270, 'select': 3271, 'governmental': 3272, 'accounts': 3273, 'wash': 3274, 'dc': 3275, 'mtrls': 3276, 'retreat': 3277, 'nationwide': 3278, 'diabetes': 3279, 'musical': 3280, 'repairman': 3281, 'gamma': 3282, 'tau': 3283, 'generator': 3284, 'excess': 3285, 'court': 3286, 'ode': 3287, 'wallace': 3288, 'move': 3289, 'supper': 3290, 'receives': 3291, 'drumline': 3292, 'distinction': 3293, 'chapter': 3294, 'padas': 3295, 'itl': 3296, 'turning': 3297, 'ranch': 3298, 'recr': 3299, 'retainage': 3300, 'people': 3301, 'hoa': 3302, 'unix': 3303, 'cond': 3304, 'engnr': 3305, 'grants': 3306, 'actbly': 3307, 'vetp': 3308, 'appreciation': 3309, 'anticipation': 3310, 'note': 3311, 'tan': 3312, 'aa': 3313, 'mu': 3314, 'ope': 3315, 'cosme': 3316, 'cafm': 3317, 'build': 3318, 'civ': 3319, 'drainage': 3320, 'relat': 3321, 'frm': 3322, 'suppr': 3323, 'moni': 3324, 'clas': 3325, 'mold': 3326, 'mkt': 3327, 'shcl': 3328, 'systm': 3329, 'appren': 3330, 'prn': 3331, 'heritage': 3332, 'spl': 3333, 'pel': 3334, 'dba': 3335, 'ln': 3336, 'supported': 3337, 'spectrum': 3338, 'roundup': 3339, 'transfe': 3340, 'agenda': 3341, 'svr': 3342, 'appropriation': 3343, 'adj': 3344, 'pga': 3345, 'educatoinal': 3346, 'progs': 3347, 'schedule': 3348, 'ipad': 3349, 'yard': 3350, 'press': 3351, 'compass': 3352, 'background': 3353, 'hazardous': 3354, 'netwk': 3355, 'comptr': 3356, 'demnd': 3357, 'cvn': 3358, 'horticulture': 3359, 'good': 3360, 'sold': 3361, 'enforcement': 3362, 'thearpy': 3363, 'colleyball': 3364, 'portble': 3365, 'fidelity': 3366, 'scoial': 3367, 'increase': 3368, 'kindergart': 3369, 'graftech': 3370, 'internl': 3371, 'dis': 3372, 'qzab': 3373, 'implem': 3374, 'improvment': 3375, 'cusotidan': 3376, 'review': 3377, 'sponsorship': 3378, 'hire': 3379, 'piano': 3380, 'garageman': 3381, 'improvmt': 3382, 'sufficient': 3383, 'scope': 3384, 'teachre': 3385, 'ticket': 3386, 'secetary': 3387, 'stationary': 3388, 'blngl': 3389, 'reimbursem': 3390, 'plaster': 3391, 'cm': 3392, 'roof': 3393, 'van': 3394, 'coop': 3395, 'lbr': 3396, 'cult': 3397, 'elumalai': 3398, 'mala': 3399, 'appachi': 3400, 'tailoring': 3401, 'discharged': 3402, 'chanclr': 3403, 'file': 3404, 'embsy': 3405, 'adopt': 3406, 'geometry': 3407, 'lanschool': 3408, 'byot': 3409, 'spending': 3410, 'obsolete': 3411, 'plato': 3412, 'pirncipal': 3413, 'aviation': 3414, 'compen': 3415, 'brdg': 3416, 'ctae': 3417, 'xerox': 3418, 'matenance': 3419, 'issuance': 3420, 'portal': 3421, 'back': 3422, 'psycologist': 3423, 'remaining': 3424, 'literary': 3425, 'joliet': 3426, 'intrvtn': 3427, 'bilng': 3428, 'pricipal': 3429, 'climbing': 3430, 'suncorp': 3431, 'sep': 3432, 'decrease': 3433, 'flex': 3434, 'inner': 3435, 'identified': 3436, 'ncta': 3437, 'personel': 3438, 'zz': 3439, 'mntl': 3440, '60hrs': 3441, 'transprtn': 3442, 'lghtng': 3443, 'octo': 3444, 'rescs': 3445, 'reasource': 3446, 'lodging': 3447, 'kidergarten': 3448, 'anlayst': 3449, 'partnershi': 3450, 'licensure': 3451, 'ptr': 3452, 'reinforce': 3453, 'oye': 3454, 'chai': 3455, 'manage': 3456, 'custodain': 3457, 'universit': 3458, 'teacjer': 3459, 'lsta': 3460, 'macy': 3461, 'librar': 3462, 'cood': 3463, 'toolkit': 3464, 'prgram': 3465, 'videographer': 3466, 'technologist': 3467, 'party': 3468, 'clos': 3469, 'achiev': 3470, 'suspense': 3471, 'healthly': 3472, 'series': 3473, 'variable': 3474, 'autobody': 3475, 'organizational': 3476, 'greek': 3477, 'ikon': 3478, 'chemical': 3479, 'initial': 3480, 'adjustme': 3481, 'pup': 3482, 'graduate': 3483, 'showcase': 3484, 'diags': 3485, 'itemfh': 3486, 'woman': 3487, 'nonresident': 3488, 'achievment': 3489, 'legislative': 3490, 'famis': 3491, 'corporation': 3492, 'evaluator': 3493, 'foremman': 3494, 'aquatic': 3495, 'd': 3496, 'vegrtables': 3497, 'editor': 3498, 'bird': 3499, 'plot': 3500, 'ints': 3501, 'develope': 3502, 'webmaster': 3503, 'maintenacne': 3504, 'transisition': 3505, 'transform': 3506, 'targt': 3507, 'supensio': 3508, 'edc': 3509, 'nclusion': 3510, 'involvment': 3511, 'prinicp': 3512, 'etiquette': 3513, 'ironworker': 3514, 'adminstriative': 3515, 'techer': 3516, 'reroofng': 3517, 'counterman': 3518, 'investigative': 3519, 'alpha': 3520, 'facilitato': 3521, 'finearts': 3522, 'cape': 3523, 'rplm': 3524, 'supervisory': 3525, 'mass': 3526, 'desgn': 3527, 'warm': 3528, 'saturda': 3529, 'depty': 3530, '80hs': 3531, 'pschologist': 3532, 'price': 3533, 'variance': 3534, 'starbucks': 3535, 'quest': 3536, 'metlife': 3537, 'ambassador': 3538, 'abatement': 3539, 'stratey': 3540, 'ncaa': 3541, 'trainier': 3542, 'interp': 3543, 'lv': 3544, 'esy': 3545, 'aided': 3546, 'ospr': 3547, 'alumnus': 3548, 'evaluati': 3549, 'distinguished': 3550, 'educat': 3551, 'assistane': 3552, 'buisness': 3553, 'supplimental': 3554, 'educato': 3555, 'got': 3556, 'archaelogical': 3557, 'ofitemfc': 3558, 'computing': 3559, 'plcmnt': 3560, 'reinsurance': 3561, 'premiums': 3562, 'bcbs': 3563, 'intergov': 3564, 'porgram': 3565, 'districtwide': 3566, 'contact': 3567, 'eii': 3568, 'keycorp': 3569, 'investme': 3570, 'scoring': 3571, 'sftwre': 3572, 'dcta': 3573, 'finch': 3574, 'actuary': 3575, 'install': 3576, 'carpet': 3577, 'installer': 3578, 'janitor': 3579, 'internet': 3580, 'baccalaur': 3581, 'imporvoment': 3582, 'specialsit': 3583, 'bright': 3584, 'noncap': 3585, 'instru': 3586, 'cfo': 3587, 'miscellenous': 3588, 'sytms': 3589, 'cadd': 3590, 'specials': 3591, 'infra': 3592, 'autonomous': 3593, 'disord': 3594, 'fil': 3595, 'incarcerated': 3596, 'practice': 3597, 'crystal': 3598, 'mach': 3599, 'intgr': 3600, 'pert': 3601, 'verification': 3602, 'targ': 3603, 'create': 3604, 'citizen': 3605, 'prinicpal': 3606, 'closeures': 3607, 'hmn': 3608, 'resourcs': 3609, 'inovation': 3610, 'tagging': 3611, 'staduim': 3612, 'fundra': 3613, 'hbsc': 3614, 'incl': 3615, 'corod': 3616, 'garden': 3617, 'surrogate': 3618, 'intructional': 3619, 'tabacco': 3620, 'brandmuscle': 3621, 'adobe': 3622, 'volleybally': 3623, 'assistan': 3624, 'listening': 3625, 'device': 3626, 'front': 3627, 'matching': 3628, 'mainenance': 3629, 'gardener': 3630, 'bio': 3631, 'serg': 3632, 'maintance': 3633, 'speaki': 3634, 'significant': 3635, 'bsi': 3636, 'libraian': 3637, 'gang': 3638, 'instrum': 3639, 'administ': 3640, 'cadre': 3641, 'bilinguial': 3642, 'modification': 3643, 'tn': 3644, 'forman': 3645, 'cogat': 3646, 'recreation': 3647, 'lifeguar': 3648, 'nutrit': 3649, 'ipd': 3650, 'finalist': 3651, 'pshycologist': 3652, 'orea': 3653, 'ntnl': 3654, 'worke': 3655, 'facilities': 3656, 'donat': 3657, 'evening': 3658, 'crdt': 3659, 'wirelesscontvty': 3660, 'autsm': 3661, 'sepcial': 3662, 'approp': 3663, 'domestic': 3664, 'cdb': 3665, 'drgp': 3666, 'spgcrk': 3667, 'expanded': 3668, 'iep': 3669, 'functional': 3670, 'articulated': 3671, 'arbitrage': 3672, 'modified': 3673, 'zero': 3674, 'tolerance': 3675, 'effec': 3676, 'txt': 3677, 'lightning': 3678, 'media': 3679, 'pmt': 3680, 'refunded': 3681, 'perfomance': 3682, 'apple': 3683, 'sequence': 3684, 'judgement': 3685, 'indemnity': 3686, 'supplemented': 3687, 'broken': 3688, 'empower': 3689, 'finisher': 3690, 'entity': 3691, 'lrc': 3692, 'bnfts': 3693, 'intrp': 3694, 'config': 3695, 'secur': 3696, 'anly': 3697, 'comptroller': 3698, 'elec': 3699, 'cord': 3700, 'psychology': 3701, 'du': 3702, 'tactical': 3703, 'storekeeper': 3704, 'paper': 3705, 'accntab': 3706, 'mth': 3707, 'sta': 3708, 'prmo': 3709, 'arrangements': 3710, 'powerlifting': 3711, 'hl': 3712, 'architectur': 3713, 'turnsch': 3714, 'needed': 3715, 'cred': 3716, 'speci': 3717, 'operato': 3718, 'veh': 3719, 'swt': 3720, 'anst': 3721, 'vehicles': 3722, 'reduced': 3723, 'sysadm': 3724, 'preferred': 3725, 'jour': 3726, 'sfty': 3727, 'frmn': 3728, 'pager': 3729, 'construct': 3730, 'pln': 3731, 'spi': 3732, 'hispanic': 3733, 'leasership': 3734, 'directly': 3735, 'eap': 3736, 'enterp': 3737, 'pda': 3738, 'permit': 3739, 'capitol': 3740, 'qual': 3741, 'successor': 3742, 'grd': 3743, 'braillist': 3744, 'welder': 3745, 'libr': 3746, 'trex': 3747, 'strcom': 3748, 'qua': 3749, '7th': 3750, '8th': 3751, 'sprt': 3752, 'pcard': 3753, 'ar': 3754, 'wan': 3755, 'disco': 3756, 'ssa': 3757, 'payments': 3758, 'arrangement': 3759, 'plmg': 3760, 'heat': 3761, 'registra': 3762, 'hum': 3763, 'cpl': 3764, 'ppcd': 3765, 'commun': 3766, 'itin': 3767, 'th': 3768, 'accts': 3769, 'ombuds': 3770, 'assessmen': 3771, 'ast': 3772, 'cataloging': 3773, 'african': 3774, 'lifeskills': 3775, 'immigr': 3776, 'aff': 3777, 'baptist': 3778, 'photog': 3779, 'problem': 3780, 'solving': 3781, 'fi': 3782, 'lifework': 3783, 'instrucional': 3784, 'association': 3785, 'negotiatio': 3786, 'mg': 3787, 'alteration': 3788, 'coga': 3789, 'administr': 3790, 'asperger': 3791, 'teasher': 3792, 'administratvie': 3793, 'instrucational': 3794, 'fash': 3795, 'dsgn': 3796, 'monster': 3797, 'worldwide': 3798, 'honda': 3799, 'walmart': 3800, 'subcert': 3801, 'ann': 3802, 'clinicans': 3803}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(X_numeric, X_text, X_numeric_test, X_text_test, y):\n",
    "    \"\"\"\n",
    "    Return compiled keras-model model\n",
    "    \n",
    "    param numpy array X: feature matrix for classification\n",
    "    param numpy array y: labels matrix for classification\n",
    "    \n",
    "    Required Libraries: keras\n",
    "    \"\"\"\n",
    "    \n",
    "    dropout_value = 0.5\n",
    "    embedding_vector_length = 400\n",
    "    \n",
    "    numeric_input = Input(shape=(X_numeric.shape[1],) , name='numeric_input') \n",
    "    text_input = Input(shape=(X_text.shape[1],) , name='text_input')\n",
    "#     word_embedding = Embedding(input_dim=3804, output_dim=50, mask_zero=True, input_length=50)(text_input)\n",
    "#     word_embedding = Flatten()(word_embedding)\n",
    "    \n",
    "    # Function\n",
    "    word_embedding_function = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_function = Flatten()(word_embedding_function)\n",
    "    text_function_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_function)\n",
    "    text_function_hidden_layer_1 = Dropout(dropout_value)(text_function_hidden_layer_1)\n",
    "    text_function_hidden_layer_2 = Dense(100, activation='relu')(text_function_hidden_layer_1)\n",
    "    text_function_hidden_layer_2 = Dropout(dropout_value)(text_function_hidden_layer_2)\n",
    "    text_function_hidden_layer_3 = Dense(50, activation='relu')(text_function_hidden_layer_2)\n",
    "    text_function_hidden_layer_3 = Dropout(dropout_value)(text_function_hidden_layer_3)\n",
    "    numeric_function_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_function_hidden_layer_1 = Dropout(dropout_value)(numeric_function_hidden_layer_1)\n",
    "    combined_function_layer = concatenate([numeric_function_hidden_layer_1, text_function_hidden_layer_2])\n",
    "    function_output_layer = Dense(37, activation='softmax')(combined_function_layer)\n",
    "    \n",
    "    # Object_Type\n",
    "    word_embedding_object_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_object_type = Flatten()(word_embedding_object_type)\n",
    "    text_object_type_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_object_type)\n",
    "    text_object_type_hidden_layer_1 = Dropout(dropout_value)(text_object_type_hidden_layer_1)\n",
    "    text_object_type_hidden_layer_2 = Dense(100, activation='relu')(text_object_type_hidden_layer_1)\n",
    "    text_object_type_hidden_layer_2 = Dropout(dropout_value)(text_object_type_hidden_layer_2)\n",
    "    text_object_type_hidden_layer_3 = Dense(50, activation='relu')(text_object_type_hidden_layer_2)\n",
    "    text_object_type_hidden_layer_3 = Dropout(dropout_value)(text_object_type_hidden_layer_3)\n",
    "    text_object_type_hidden_layer_4 = Dense(25, activation='relu')(text_object_type_hidden_layer_3)\n",
    "    text_object_type_hidden_layer_4 = Dropout(dropout_value)(text_object_type_hidden_layer_4)\n",
    "    numeric_object_type_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_object_type_hidden_layer_1 = Dropout(dropout_value)(numeric_object_type_hidden_layer_1)\n",
    "    combined_object_type_layer = concatenate([numeric_object_type_hidden_layer_1, text_object_type_hidden_layer_4])\n",
    "    object_type_output_layer = Dense(11, activation='softmax')(combined_object_type_layer)\n",
    "    \n",
    "    # Operating_Status\n",
    "    word_embedding_operating_status = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_operating_status = Flatten()(word_embedding_operating_status)\n",
    "    text_operating_status_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_operating_status)\n",
    "    text_operating_status_hidden_layer_1 = Dropout(dropout_value)(text_operating_status_hidden_layer_1)\n",
    "    text_operating_status_hidden_layer_2 = Dense(100, activation='relu')(text_operating_status_hidden_layer_1)\n",
    "    text_operating_status_hidden_layer_2 = Dropout(dropout_value)(text_operating_status_hidden_layer_2)\n",
    "    text_operating_status_hidden_layer_3 = Dense(50, activation='relu')(text_operating_status_hidden_layer_2)\n",
    "    text_operating_status_hidden_layer_3 = Dropout(dropout_value)(text_operating_status_hidden_layer_3)\n",
    "    text_operating_status_hidden_layer_4 = Dense(25, activation='relu')(text_operating_status_hidden_layer_3)\n",
    "    text_operating_status_hidden_layer_4 = Dropout(dropout_value)(text_operating_status_hidden_layer_4)\n",
    "    numeric_operating_status_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_operating_status_hidden_layer_1 = Dropout(dropout_value)(numeric_operating_status_hidden_layer_1)\n",
    "    combined_operating_status_layer = concatenate([numeric_operating_status_hidden_layer_1, text_operating_status_hidden_layer_4])\n",
    "    operating_status_output_layer = Dense(3, activation='softmax')(combined_operating_status_layer)\n",
    "    \n",
    "    # Position_Type\n",
    "    word_embedding_position_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_position_type = Flatten()(word_embedding_position_type)\n",
    "    text_position_type_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_operating_status)\n",
    "    text_position_type_hidden_layer_1 = Dropout(dropout_value)(text_position_type_hidden_layer_1)\n",
    "    text_position_type_hidden_layer_2 = Dense(100, activation='relu')(text_position_type_hidden_layer_1)\n",
    "    text_position_type_hidden_layer_2 = Dropout(dropout_value)(text_position_type_hidden_layer_2)\n",
    "    text_position_type_hidden_layer_3 = Dense(50, activation='relu')(text_position_type_hidden_layer_2)\n",
    "    text_position_type_hidden_layer_3 = Dropout(dropout_value)(text_position_type_hidden_layer_3)\n",
    "    numeric_position_type_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_position_type_hidden_layer_1 = Dropout(dropout_value)(numeric_position_type_hidden_layer_1)\n",
    "    combined_position_type_layer = concatenate([numeric_position_type_hidden_layer_1, text_position_type_hidden_layer_3])\n",
    "    position_type_output_layer = Dense(25, activation='softmax')(combined_position_type_layer)\n",
    "    \n",
    "    # Pre_K\n",
    "    word_embedding_pre_k = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_pre_k = Flatten()(word_embedding_pre_k)\n",
    "    text_pre_k_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_pre_k)\n",
    "    text_pre_k_hidden_layer_1 = Dropout(dropout_value)(text_pre_k_hidden_layer_1)\n",
    "    text_pre_k_hidden_layer_2 = Dense(100, activation='relu')(text_pre_k_hidden_layer_1)\n",
    "    text_pre_k_hidden_layer_2 = Dropout(dropout_value)(text_pre_k_hidden_layer_2)\n",
    "    text_pre_k_hidden_layer_3 = Dense(50, activation='relu')(text_pre_k_hidden_layer_2)\n",
    "    text_pre_k_hidden_layer_3 = Dropout(dropout_value)(text_pre_k_hidden_layer_3)\n",
    "    text_pre_k_hidden_layer_4 = Dense(25, activation='relu')(text_pre_k_hidden_layer_3)\n",
    "    text_pre_k_hidden_layer_4 = Dropout(dropout_value)(text_pre_k_hidden_layer_4)\n",
    "    numeric_pre_k_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_pre_k_hidden_layer_1 = Dropout(dropout_value)(numeric_pre_k_hidden_layer_1)\n",
    "    combined_pre_k_layer = concatenate([numeric_pre_k_hidden_layer_1, text_pre_k_hidden_layer_4])\n",
    "    pre_k_output_layer = Dense(3, activation='softmax')(combined_pre_k_layer)\n",
    "    \n",
    "    # Reporting\n",
    "    word_embedding_reporting = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_reporting = Flatten()(word_embedding_reporting)\n",
    "    text_reporting_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_reporting)\n",
    "    text_reporting_hidden_layer_1 = Dropout(dropout_value)(text_reporting_hidden_layer_1)\n",
    "    text_reporting_hidden_layer_2 = Dense(100, activation='relu')(text_reporting_hidden_layer_1)\n",
    "    text_reporting_hidden_layer_2 = Dropout(dropout_value)(text_reporting_hidden_layer_2)\n",
    "    text_reporting_hidden_layer_3 = Dense(50, activation='relu')(text_reporting_hidden_layer_2)\n",
    "    text_reporting_hidden_layer_3 = Dropout(dropout_value)(text_reporting_hidden_layer_3)\n",
    "    text_reporting_hidden_layer_4 = Dense(25, activation='relu')(text_reporting_hidden_layer_3)\n",
    "    text_reporting_hidden_layer_4 = Dropout(dropout_value)(text_reporting_hidden_layer_4)\n",
    "    numeric_reporting_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_reporting_hidden_layer_1 = Dropout(dropout_value)(numeric_reporting_hidden_layer_1)\n",
    "    combined_reporting_layer = concatenate([numeric_reporting_hidden_layer_1, text_reporting_hidden_layer_4])\n",
    "    reporting_output_layer = Dense(3, activation='softmax')(combined_reporting_layer)\n",
    "    \n",
    "    # Sharing\n",
    "    word_embedding_sharing = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_sharing = Flatten()(word_embedding_sharing)\n",
    "    text_sharing_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_sharing)\n",
    "    text_sharing_hidden_layer_1 = Dropout(dropout_value)(text_sharing_hidden_layer_1)\n",
    "    text_sharing_hidden_layer_2 = Dense(100, activation='relu')(text_sharing_hidden_layer_1)\n",
    "    text_sharing_hidden_layer_2 = Dropout(dropout_value)(text_sharing_hidden_layer_2)\n",
    "    text_sharing_hidden_layer_3 = Dense(50, activation='relu')(text_sharing_hidden_layer_2)\n",
    "    text_sharing_hidden_layer_3 = Dropout(dropout_value)(text_sharing_hidden_layer_3)\n",
    "    text_sharing_hidden_layer_4 = Dense(25, activation='relu')(text_sharing_hidden_layer_3)\n",
    "    text_sharing_hidden_layer_4 = Dropout(dropout_value)(text_sharing_hidden_layer_4)\n",
    "    numeric_sharing_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_sharing_hidden_layer_1 = Dropout(dropout_value)(numeric_sharing_hidden_layer_1)\n",
    "    combined_sharing_layer = concatenate([numeric_sharing_hidden_layer_1, text_sharing_hidden_layer_4])\n",
    "    sharing_output_layer = Dense(5, activation='softmax')(combined_sharing_layer)\n",
    "    \n",
    "    # Student_Type\n",
    "    word_embedding_student_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_student_type = Flatten()(word_embedding_student_type)\n",
    "    text_student_type_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_student_type)\n",
    "    text_student_type_hidden_layer_1 = Dropout(dropout_value)(text_student_type_hidden_layer_1)\n",
    "    text_student_type_hidden_layer_2 = Dense(100, activation='relu')(text_student_type_hidden_layer_1)\n",
    "    text_student_type_hidden_layer_2 = Dropout(dropout_value)(text_student_type_hidden_layer_2)\n",
    "    text_student_type_hidden_layer_3 = Dense(50, activation='relu')(text_student_type_hidden_layer_2)\n",
    "    text_student_type_hidden_layer_3 = Dropout(dropout_value)(text_student_type_hidden_layer_3)\n",
    "    text_student_type_hidden_layer_4 = Dense(25, activation='relu')(text_student_type_hidden_layer_3)\n",
    "    text_student_type_hidden_layer_4 = Dropout(dropout_value)(text_student_type_hidden_layer_4)\n",
    "    numeric_student_type_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_student_type_hidden_layer_1 = Dropout(dropout_value)(numeric_student_type_hidden_layer_1)\n",
    "    combined_student_type_layer = concatenate([numeric_student_type_hidden_layer_1, text_student_type_hidden_layer_4])\n",
    "    student_type_output_layer = Dense(9, activation='softmax')(combined_student_type_layer)\n",
    "    \n",
    "    # Use\n",
    "    word_embedding_use = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    word_embedding_use = Flatten()(word_embedding_use)\n",
    "    text_use_hidden_layer_1 = Dense(200, activation='relu')(word_embedding_use)\n",
    "    text_use_hidden_layer_1 = Dropout(dropout_value)(text_use_hidden_layer_1)\n",
    "    text_use_hidden_layer_2 = Dense(100, activation='relu')(text_use_hidden_layer_1)\n",
    "    text_use_hidden_layer_2 = Dropout(dropout_value)(text_use_hidden_layer_2)\n",
    "    text_use_hidden_layer_3 = Dense(50, activation='relu')(text_use_hidden_layer_2)\n",
    "    text_use_hidden_layer_3 = Dropout(dropout_value)(text_use_hidden_layer_3)\n",
    "    text_use_hidden_layer_4 = Dense(25, activation='relu')(text_use_hidden_layer_3)\n",
    "    text_use_hidden_layer_4 = Dropout(dropout_value)(text_use_hidden_layer_4)\n",
    "    numeric_use_hidden_layer_1 = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_use_hidden_layer_1 = Dropout(dropout_value)(numeric_use_hidden_layer_1)\n",
    "    combined_use_layer = concatenate([numeric_use_hidden_layer_1, text_use_hidden_layer_4])\n",
    "    use_output_layer = Dense(8, activation='softmax')(combined_use_layer)\n",
    "    \n",
    "    # Output\n",
    "    combined_output_layer = concatenate([function_output_layer, \n",
    "                                         object_type_output_layer,\n",
    "                                         operating_status_output_layer,\n",
    "                                         position_type_output_layer,\n",
    "                                         pre_k_output_layer,\n",
    "                                         reporting_output_layer,\n",
    "                                         sharing_output_layer,\n",
    "                                         student_type_output_layer,\n",
    "                                         use_output_layer])\n",
    "    \n",
    "    model = Model(inputs=[numeric_input, text_input], outputs=[combined_output_layer])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280193 samples, validate on 120084 samples\n",
      "Epoch 1/150\n",
      "280193/280193 [==============================] - 1262s 5ms/step - loss: 45.5544 - acc: 0.2811 - val_loss: 33.3113 - val_acc: 0.3280\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 33.31125, saving model to embedding_model.h5\n",
      "Epoch 2/150\n",
      "280193/280193 [==============================] - 1300s 5ms/step - loss: 33.8043 - acc: 0.2652 - val_loss: 31.8438 - val_acc: 0.2665\n",
      "\n",
      "Epoch 00002: val_loss improved from 33.31125 to 31.84376, saving model to embedding_model.h5\n",
      "Epoch 3/150\n",
      "280193/280193 [==============================] - 1313s 5ms/step - loss: 32.1280 - acc: 0.2472 - val_loss: 29.8972 - val_acc: 0.3023\n",
      "\n",
      "Epoch 00003: val_loss improved from 31.84376 to 29.89720, saving model to embedding_model.h5\n",
      "Epoch 4/150\n",
      "280193/280193 [==============================] - 1317s 5ms/step - loss: 31.1090 - acc: 0.2539 - val_loss: 29.4945 - val_acc: 0.3087\n",
      "\n",
      "Epoch 00004: val_loss improved from 29.89720 to 29.49446, saving model to embedding_model.h5\n",
      "Epoch 5/150\n",
      "280193/280193 [==============================] - 1324s 5ms/step - loss: 30.3128 - acc: 0.2687 - val_loss: 30.7017 - val_acc: 0.2981\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 29.49446\n",
      "Epoch 6/150\n",
      "280193/280193 [==============================] - 1240s 4ms/step - loss: 29.5219 - acc: 0.2816 - val_loss: 28.9324 - val_acc: 0.3238\n",
      "\n",
      "Epoch 00006: val_loss improved from 29.49446 to 28.93242, saving model to embedding_model.h5\n",
      "Epoch 7/150\n",
      "280193/280193 [==============================] - 1311s 5ms/step - loss: 29.0074 - acc: 0.2939 - val_loss: 28.1599 - val_acc: 0.3457\n",
      "\n",
      "Epoch 00007: val_loss improved from 28.93242 to 28.15993, saving model to embedding_model.h5\n",
      "Epoch 8/150\n",
      "280193/280193 [==============================] - 1350s 5ms/step - loss: 29.1181 - acc: 0.3049 - val_loss: 27.7409 - val_acc: 0.3410\n",
      "\n",
      "Epoch 00008: val_loss improved from 28.15993 to 27.74094, saving model to embedding_model.h5\n",
      "Epoch 9/150\n",
      "280193/280193 [==============================] - 1335s 5ms/step - loss: 28.3534 - acc: 0.3063 - val_loss: 27.9740 - val_acc: 0.3510\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 27.74094\n",
      "Epoch 10/150\n",
      "280193/280193 [==============================] - 1277s 5ms/step - loss: 28.1159 - acc: 0.3220 - val_loss: 27.6406 - val_acc: 0.3867\n",
      "\n",
      "Epoch 00010: val_loss improved from 27.74094 to 27.64061, saving model to embedding_model.h5\n",
      "Epoch 11/150\n",
      "280193/280193 [==============================] - 1325s 5ms/step - loss: 27.8039 - acc: 0.3401 - val_loss: 27.4200 - val_acc: 0.4069\n",
      "\n",
      "Epoch 00011: val_loss improved from 27.64061 to 27.41999, saving model to embedding_model.h5\n",
      "Epoch 12/150\n",
      "280193/280193 [==============================] - 1323s 5ms/step - loss: 27.4744 - acc: 0.3462 - val_loss: 26.8718 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00012: val_loss improved from 27.41999 to 26.87181, saving model to embedding_model.h5\n",
      "Epoch 13/150\n",
      "280193/280193 [==============================] - 1338s 5ms/step - loss: 27.0474 - acc: 0.3507 - val_loss: 26.5179 - val_acc: 0.3984\n",
      "\n",
      "Epoch 00013: val_loss improved from 26.87181 to 26.51795, saving model to embedding_model.h5\n",
      "Epoch 14/150\n",
      "280193/280193 [==============================] - 1341s 5ms/step - loss: 26.6959 - acc: 0.3641 - val_loss: 26.8378 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 26.51795\n",
      "Epoch 15/150\n",
      "280193/280193 [==============================] - 1299s 5ms/step - loss: 26.4008 - acc: 0.3663 - val_loss: 25.8690 - val_acc: 0.3980\n",
      "\n",
      "Epoch 00015: val_loss improved from 26.51795 to 25.86897, saving model to embedding_model.h5\n",
      "Epoch 16/150\n",
      "280193/280193 [==============================] - 1339s 5ms/step - loss: 26.0398 - acc: 0.3734 - val_loss: 25.6819 - val_acc: 0.4365\n",
      "\n",
      "Epoch 00016: val_loss improved from 25.86897 to 25.68187, saving model to embedding_model.h5\n",
      "Epoch 17/150\n",
      "280193/280193 [==============================] - 1362s 5ms/step - loss: 26.0721 - acc: 0.3935 - val_loss: 25.8234 - val_acc: 0.4410\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 25.68187\n",
      "Epoch 18/150\n",
      "280193/280193 [==============================] - 1280s 5ms/step - loss: 26.1139 - acc: 0.3983 - val_loss: 25.8031 - val_acc: 0.4399\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 25.68187\n",
      "Epoch 19/150\n",
      "280193/280193 [==============================] - 1290s 5ms/step - loss: 26.0348 - acc: 0.4107 - val_loss: 26.0394 - val_acc: 0.4791\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 25.68187\n",
      "Epoch 20/150\n",
      "280193/280193 [==============================] - 1293s 5ms/step - loss: 27.6156 - acc: 0.4052 - val_loss: 25.9020 - val_acc: 0.4712\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 25.68187\n",
      "Epoch 21/150\n",
      "280193/280193 [==============================] - 1305s 5ms/step - loss: 25.9479 - acc: 0.4223 - val_loss: 25.6691 - val_acc: 0.4762\n",
      "\n",
      "Epoch 00021: val_loss improved from 25.68187 to 25.66907, saving model to embedding_model.h5\n",
      "Epoch 22/150\n",
      "280193/280193 [==============================] - 1372s 5ms/step - loss: 26.1701 - acc: 0.4086 - val_loss: 26.6492 - val_acc: 0.5070\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 25.66907\n",
      "Epoch 23/150\n",
      "280193/280193 [==============================] - 1319s 5ms/step - loss: 26.1741 - acc: 0.4215 - val_loss: 25.7132 - val_acc: 0.5192\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 25.66907\n",
      "Epoch 24/150\n",
      "280193/280193 [==============================] - 1330s 5ms/step - loss: 25.8901 - acc: 0.4412 - val_loss: 26.2142 - val_acc: 0.5151\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 25.66907\n",
      "Epoch 25/150\n",
      "280193/280193 [==============================] - 1465s 5ms/step - loss: 26.2360 - acc: 0.4412 - val_loss: 25.7569 - val_acc: 0.4904\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 25.66907\n",
      "Epoch 26/150\n",
      "280193/280193 [==============================] - 1437s 5ms/step - loss: 25.8686 - acc: 0.4460 - val_loss: 25.7697 - val_acc: 0.5237\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 25.66907\n",
      "Epoch 27/150\n",
      "280193/280193 [==============================] - 1444s 5ms/step - loss: 25.8968 - acc: 0.4485 - val_loss: 25.4322 - val_acc: 0.5178\n",
      "\n",
      "Epoch 00027: val_loss improved from 25.66907 to 25.43216, saving model to embedding_model.h5\n",
      "Epoch 28/150\n",
      "280193/280193 [==============================] - 1468s 5ms/step - loss: 25.7820 - acc: 0.4466 - val_loss: 25.4268 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00028: val_loss improved from 25.43216 to 25.42680, saving model to embedding_model.h5\n",
      "Epoch 29/150\n",
      "280193/280193 [==============================] - 1474s 5ms/step - loss: 25.4887 - acc: 0.4581 - val_loss: 24.9022 - val_acc: 0.5414\n",
      "\n",
      "Epoch 00029: val_loss improved from 25.42680 to 24.90216, saving model to embedding_model.h5\n",
      "Epoch 30/150\n",
      "280193/280193 [==============================] - 1438s 5ms/step - loss: 25.4310 - acc: 0.4660 - val_loss: 24.8519 - val_acc: 0.5502\n",
      "\n",
      "Epoch 00030: val_loss improved from 24.90216 to 24.85189, saving model to embedding_model.h5\n",
      "Epoch 31/150\n",
      "280193/280193 [==============================] - 1412s 5ms/step - loss: 24.5531 - acc: 0.4604 - val_loss: 24.5248 - val_acc: 0.5240\n",
      "\n",
      "Epoch 00031: val_loss improved from 24.85189 to 24.52479, saving model to embedding_model.h5\n",
      "Epoch 32/150\n",
      "280193/280193 [==============================] - 1460s 5ms/step - loss: 24.5954 - acc: 0.4586 - val_loss: 24.1141 - val_acc: 0.5356\n",
      "\n",
      "Epoch 00032: val_loss improved from 24.52479 to 24.11409, saving model to embedding_model.h5\n",
      "Epoch 33/150\n",
      "280193/280193 [==============================] - 1406s 5ms/step - loss: 24.2291 - acc: 0.4697 - val_loss: 24.5242 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 24.11409\n",
      "Epoch 34/150\n",
      "280193/280193 [==============================] - 1351s 5ms/step - loss: 24.3323 - acc: 0.4879 - val_loss: 24.0481 - val_acc: 0.5515\n",
      "\n",
      "Epoch 00034: val_loss improved from 24.11409 to 24.04806, saving model to embedding_model.h5\n",
      "Epoch 35/150\n",
      "280193/280193 [==============================] - 1468s 5ms/step - loss: 24.3886 - acc: 0.4909 - val_loss: 24.3405 - val_acc: 0.5717\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 24.04806\n",
      "Epoch 36/150\n",
      "280193/280193 [==============================] - 1567s 6ms/step - loss: 24.1531 - acc: 0.4986 - val_loss: 23.8816 - val_acc: 0.5832\n",
      "\n",
      "Epoch 00036: val_loss improved from 24.04806 to 23.88161, saving model to embedding_model.h5\n",
      "Epoch 37/150\n",
      "280193/280193 [==============================] - 1524s 5ms/step - loss: 24.0366 - acc: 0.4991 - val_loss: 23.9090 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 23.88161\n",
      "Epoch 38/150\n",
      "255488/280193 [==========================>...] - ETA: 2:06 - loss: 24.2698 - acc: 0.4937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-76935c5f2231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"embedding_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = build_network(X_numeric, X_text, X_numeric_test, X_text_test, y)\n",
    "# clf.load_weights('embedding_model.h5')\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "checkpointer = ModelCheckpoint(filepath=\"embedding_model.h5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history_clf = clf.fit([X_numeric, X_text], y, epochs=150, batch_size=256, validation_split=0.3, callbacks=[early_stopping_monitor, checkpointer])\n",
    "\n",
    "clf.save_weights(\"embedding_model.h5\")\n",
    "model_json = clf.to_json()\n",
    "with open(\"embedding_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
