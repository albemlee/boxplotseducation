{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnWCGPLQ5ePG"
   },
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1618,
     "status": "ok",
     "timestamp": 1534606028924,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "Nrg9OIDy5ePJ",
    "outputId": "9a9200d1-e791-4465-fd4c-ff5f390f84a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# To load data\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import Imputer\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To build model\n",
    "import keras\n",
    "from keras.layers import Dense, concatenate, Input, Dropout, Embedding, Flatten, Bidirectional, GRU, Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "\n",
    "# To train model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# To evaluate model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# To track time elapsed\n",
    "import time\n",
    "\n",
    "# To save results\n",
    "import dill\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPLEdpRv5ePM"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF3nUD615ePM"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Return pandas dataframe data_train: training data (features + labels)\n",
    "    Return pandas dataframe data_test: test data (only features)\n",
    "    \n",
    "    Required Libraries: zipfile, pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load zipped folder with data files\n",
    "    resource_archive = zipfile.ZipFile('resources.zip', 'r')\n",
    "\n",
    "    # Load testing data\n",
    "    data_test = pd.read_csv(resource_archive.open('TestData.csv'), \n",
    "                            dtype={\n",
    "                                'Object_Description': str, \n",
    "                                'Program_Description': str, \n",
    "                                'SubFund_Description': str, \n",
    "                                'Job_Title_Description': str, \n",
    "                                'Facility_or_Department': str,\n",
    "                                'Sub_Object_Description': str, \n",
    "                                'Location_Description': str, \n",
    "                                'FTE': float,\n",
    "                                'Function_Description': str, \n",
    "                                'Position_Extra': str, \n",
    "                                'Text_4': str, \n",
    "                                'Total': float, \n",
    "                                'Text_2': str,\n",
    "                                'Text_3': str, \n",
    "                                'Fund_Description': str, \n",
    "                                'Text_1': str\n",
    "                            },\n",
    "                            index_col=0)\n",
    "\n",
    "    # Load training data\n",
    "    data_train = pd.read_csv(resource_archive.open('TrainingData.csv'), \n",
    "                            dtype={\n",
    "                                'Object_Description': str, \n",
    "                                'Program_Description': str, \n",
    "                                'SubFund_Description': str, \n",
    "                                'Job_Title_Description': str, \n",
    "                                'Facility_or_Department': str,\n",
    "                                'Sub_Object_Description': str, \n",
    "                                'Location_Description': str, \n",
    "                                'FTE': float,\n",
    "                                'Function_Description': str, \n",
    "                                'Position_Extra': str, \n",
    "                                'Text_4': str, \n",
    "                                'Total': float, \n",
    "                                'Text_2': str,\n",
    "                                'Text_3': str, \n",
    "                                'Fund_Description': str, \n",
    "                                'Text_1': str,\n",
    "                                'Function': 'category',\n",
    "                                'Object_Type': 'category',\n",
    "                                'Operating_Status': 'category',\n",
    "                                'Position_Type': 'category',\n",
    "                                'Pre_K': 'category',\n",
    "                                'Reporting': 'category',\n",
    "                                'Sharing': 'category',\n",
    "                                'Student_Type': 'category',\n",
    "                                'Use': 'category',\n",
    "                            },\n",
    "                             index_col=0)\n",
    "    \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2871,
     "status": "ok",
     "timestamp": 1534606036665,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "GVz1rkaX5ePP",
    "outputId": "d8a0ba71-d2fe-4f27-e579-5c0a5b3c4221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape: (400277, 25)\n",
      "data_test shape: (50064, 16)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = load_data()\n",
    "print('data_train shape:', data_train.shape)\n",
    "print('data_test shape:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i203UxGy5ePT"
   },
   "outputs": [],
   "source": [
    "def load_features(data_train, data_test):\n",
    "    \"\"\"\n",
    "    Return pandas dataframe data_features: data in feature columns of data_train and data_test\n",
    "    \n",
    "    Param pandas dataframe data_train: training data (features + labels)\n",
    "    Param pandas dataframe data_test: test data (only features)\n",
    "    \n",
    "    Required Libraries: pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_columns = data_test.columns # data_test only contains features\n",
    "    \n",
    "    data_features = pd.concat([data_train[feature_columns], data_test])\n",
    "    \n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1534606037726,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "vBZekpVd5ePV",
    "outputId": "02995365-986f-41fb-ae6f-5ab52507e73a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_features shape: (450341, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load Features\n",
    "data_features = load_features(data_train, data_test)\n",
    "print('data_features shape:', data_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ITNF9275ePY"
   },
   "source": [
    "# Prepare Data for Classification\n",
    "Run the cells below if prepped data files have not been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ID0Uo8GT5ePY"
   },
   "outputs": [],
   "source": [
    "def text_processing(phrase):\n",
    "    \"\"\"\n",
    "    Return list processed_phrase: phrase tokens after processing has been completed\n",
    "    \n",
    "    param string phrase: phrase to be processed\n",
    "    \n",
    "    Required Libraries: re, nltk\n",
    "    \"\"\"\n",
    "    \n",
    "    # Case Normalization\n",
    "    processed_phrase = phrase.lower()\n",
    "    \n",
    "    # Remove Punctuations\n",
    "    processed_phrase = re.sub(r\"[^a-z0-9-]\", \" \", processed_phrase)\n",
    "    \n",
    "    # Tokenize Phrase\n",
    "    processed_phrase = processed_phrase.split()\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    processed_phrase = [word for word in processed_phrase if word not in stopwords.words(\"english\") and word != '-']\n",
    "    \n",
    "    # Lemmatization\n",
    "    processed_phrase = [WordNetLemmatizer().lemmatize(word) for word in processed_phrase]\n",
    "    \n",
    "    # Recombine list into phrase\n",
    "    processed_phrase = ' '.join(processed_phrase)\n",
    "    \n",
    "    return processed_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZapkVld5ePb",
    "outputId": "8bf67ef2-f47a-4d30-84cf-7bb823a5cd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past patiently waitin passionately smashin every expectation every action act creation laughin face casualty sorrow first time thinkin past tomorrow\n",
      "2.5811121463775635\n"
     ]
    }
   ],
   "source": [
    "# test text_processing function (with quote from Hamilton: The Musical)\n",
    "start_time = time.time()\n",
    "print(text_processing(\n",
    "    \"I’m past patiently waitin’. I’m passionately smashin’ every expectation. \" + \n",
    "    \"Every action’s an act of creation! \" +\n",
    "    \"I’m laughin’ in the face of casualties and sorrow. \" +\n",
    "    \"For the first time, I’m thinkin’ past tomorrow\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFQgJuJ_5ePd"
   },
   "outputs": [],
   "source": [
    "def init_prep(data_train, data_test, data_features, label=None):\n",
    "    \"\"\"\n",
    "    Return numpy array X_numeric: numerical feature matrix of test set\n",
    "    Return numpy array X_text: text feature matrix for classification model fitting\n",
    "    Return numpy array X_numeric_test: numerical feature matrix of test set\n",
    "    Return numpy array X_text_test: text feature matrix for classification model fitting\n",
    "    Return numpy array y: labels matrix for classification model fitting\n",
    "    Return keras.Tokenizer() tokenize: contains word to token mapping\n",
    "    \n",
    "    Param pandas dataframe data_train: training data (features + labels)\n",
    "    Param pandas dataframe data_test: test data (features)\n",
    "    Param pandas dataframe data_features: data in feature columns of data_train and data_test\n",
    "    \n",
    "    Required Libraries: pandas, numpy, keras\n",
    "    Required helper functions: text_processing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combined and preprocess text columns\n",
    "    data_train['combined_text'] = (data_train[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                  )\n",
    "    data_test['combined_text'] = (data_test[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                 )\n",
    "    data_features['combined_text'] = (data_features\n",
    "                                          .drop(columns=['FTE', 'Total'])\n",
    "                                          .fillna(\"\")\n",
    "                                          .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                          .apply(lambda x: text_processing(x))\n",
    "                                     )\n",
    "    \n",
    "    # Vectorizer text columns in training data\n",
    "    tokenize = Tokenizer()\n",
    "    tokenize.fit_on_texts(data_features['combined_text'])\n",
    "    \n",
    "    X_text = tokenize.texts_to_sequences(data_train['combined_text'])\n",
    "    X_text_test = tokenize.texts_to_sequences(data_test['combined_text'])\n",
    "    \n",
    "    X_text = pad_sequences(X_text, padding='post', maxlen=50, truncating='post')\n",
    "    X_text_test = pad_sequences(X_text_test, padding='post', maxlen=50, truncating='post')\n",
    "    \n",
    "    # Impute missing numerical data\n",
    "    imp_total = Imputer(strategy='median')\n",
    "    imp_total.fit(data_features['Total'].values.reshape(-1, 1))\n",
    "\n",
    "    total_not_missing = pd.isnull(data_train['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing = pd.isnull(data_train['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total = imp_total.transform(data_train['Total'].values.reshape(-1, 1))\n",
    "    fte = data_train['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "\n",
    "    total_not_missing_test = pd.isnull(data_test['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing_test = pd.isnull(data_test['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total_test = imp_total.transform(data_test['Total'].values.reshape(-1, 1))\n",
    "    fte_test = data_test['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X_numeric = np.concatenate([total, total_not_missing, fte, fte_not_missing], axis=1)\n",
    "    X_numeric_test = np.concatenate([total_test, total_not_missing_test, fte_test, fte_not_missing_test], axis=1)\n",
    "    \n",
    "    # Create labels matrix\n",
    "    if label:\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    else:\n",
    "        label = ['Function',\n",
    "                 'Object_Type',\n",
    "                 'Operating_Status',\n",
    "                 'Position_Type',\n",
    "                 'Pre_K',\n",
    "                 'Reporting',\n",
    "                 'Sharing',\n",
    "                 'Student_Type',\n",
    "                 'Use']\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    \n",
    "    return X_numeric, X_text, X_numeric_test, X_text_test, y, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IISwk-c5ePf"
   },
   "outputs": [],
   "source": [
    "X_numeric, X_text, X_test_numeric, X_test_text, y, tokenize = init_prep(data_train, data_test, data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeEwXBk75ePi"
   },
   "outputs": [],
   "source": [
    "# Save X_test_text and X_test_numeric\n",
    "np.savez('X_test_text.npz', X_test_text)\n",
    "np.savez('X_test_numeric.npz', X_test_numeric)\n",
    "\n",
    "# Pickle tokenize\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenize, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3wYrZqv5ePp"
   },
   "outputs": [],
   "source": [
    "def prep_for_classification(X_numeric, X_text, y, validation_size=50064):\n",
    "    \"\"\"\n",
    "    Split training data into training and validation sets\n",
    "    \n",
    "    Return pandas dataframe X_train_numeric: training data (features)\n",
    "    Return pandas dataframe X_train_text: training data (features)\n",
    "    Return pandas dataframe X_val_numeric: validation data (features)\n",
    "    Return pandas dataframe X_val_text: validation data (features)\n",
    "    Return pandas dataframe y_train: training data (labels)\n",
    "    Return pandas dataframe y_val: validation data (labels)\n",
    "    \n",
    "    param numpy array X_numeric: numerical feature matrix of test set\n",
    "    param numpy array X_text: text feature matrix for classification model fitting\n",
    "    param numpy array X_numeric_test: numerical feature matrix of test set\n",
    "    param numpy array X_text_test: text feature matrix for classification model fitting\n",
    "    param numpy array y: labels matrix for classification model fitting\n",
    "    \n",
    "    Required Libraries: pandas, sklearn.model_selection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split into training and development sets\n",
    "    X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val = train_test_split(X_numeric, X_text, y, test_size=validation_size, random_state=93)\n",
    "    \n",
    "    return X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drbaQuel5ePr",
    "outputId": "09b43a88-46f1-4b6e-8bd6-4be33d7986d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_numeric (350213, 4)\n",
      "X_train_text (350213, 50)\n",
      "y_train (350213, 104)\n",
      "X_val_numeric (50064, 4)\n",
      "X_val_text (50064, 50)\n",
      "y_val (50064, 104)\n"
     ]
    }
   ],
   "source": [
    "X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val = prep_for_classification(X_numeric, X_text, y)\n",
    "print('X_train_numeric', X_train_numeric.shape)\n",
    "print('X_train_text', X_train_text.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val_numeric', X_val_numeric.shape)\n",
    "print('X_val_text', X_val_text.shape)\n",
    "print('y_val', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhVYZEmx5ePv"
   },
   "outputs": [],
   "source": [
    "# Save prepped data\n",
    "y_train = sparse.csr_matrix(y_train)\n",
    "y_val = sparse.csr_matrix(y_val)\n",
    "\n",
    "np.savez('X_train_text.npz', X_train_text)\n",
    "np.savez('X_val_text.npz', X_val_text)\n",
    "np.savez('X_train_numeric.npz', X_train_numeric)\n",
    "np.savez('X_val_numeric.npz', X_val_numeric)\n",
    "sparse.save_npz('y_train.npz', y_train)\n",
    "sparse.save_npz('y_val.npz', y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Prepped Data\n",
    "Run these cells below if prepped data files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1534606083642,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "hGz1Dw0S5ePx",
    "outputId": "1e80f718-b864-42ab-a118-2833c8cc8d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_numeric (350213, 4)\n",
      "X_train_text (350213, 50)\n",
      "y_train (350213, 104)\n",
      "X_val_numeric (50064, 4)\n",
      "X_val_text (50064, 50)\n",
      "y_val (50064, 104)\n",
      "X_test_numeric (50064, 4)\n",
      "X_test_text (50064, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_text = np.load('X_train_text.npz')['arr_0']\n",
    "X_val_text = np.load('X_val_text.npz')['arr_0']\n",
    "X_train_numeric = np.load('X_train_numeric.npz')['arr_0']\n",
    "X_val_numeric = np.load('X_val_numeric.npz')['arr_0']\n",
    "y_train = sparse.load_npz('y_train.npz')\n",
    "y_val = sparse.load_npz('y_val.npz')\n",
    "X_test_numeric = np.load('X_test_numeric.npz')['arr_0']\n",
    "X_test_text = np.load('X_test_text.npz')['arr_0']\n",
    "\n",
    "print('X_train_numeric', X_train_numeric.shape)\n",
    "print('X_train_text', X_train_text.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val_numeric', X_val_numeric.shape)\n",
    "print('X_val_text', X_val_text.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test_numeric', X_test_numeric.shape)\n",
    "print('X_test_text', X_test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfppW7oi5eP0"
   },
   "source": [
    "# Build Model\n",
    "Run cells below if model has not been fitted yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtnM3_nE5eP0"
   },
   "outputs": [],
   "source": [
    "def build_network(X_numeric=X_train_numeric, X_text=X_train_text, y=y_train):\n",
    "    \"\"\"\n",
    "    Return compiled keras-model model\n",
    "    \n",
    "    param numpy array X: feature matrix for classification\n",
    "    param numpy array y: labels matrix for classification\n",
    "    \n",
    "    Required Libraries: keras\n",
    "    \"\"\"\n",
    "    \n",
    "    dropout_value = 0.5\n",
    "    embedding_vector_length = 8\n",
    "    kernel_size_value = 8\n",
    "    padding_value = 'same'\n",
    "    stride_value = 2\n",
    "    pool_size_value = 2\n",
    "    \n",
    "    numeric_input = Input(shape=(X_numeric.shape[1],) , name='numeric_input') \n",
    "    text_input = Input(shape=(X_text.shape[1],) , name='text_input')\n",
    "    \n",
    "    # Function\n",
    "    word_embedding_function = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_function_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_function)\n",
    "    text_function_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = Dropout(dropout_value)(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = Dropout(dropout_value)(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_function_hidden_layer)\n",
    "    text_function_hidden_layer = Dropout(dropout_value)(text_function_hidden_layer)\n",
    "    dense_function_layer = Flatten()(text_function_hidden_layer)\n",
    "    dense_function_layer = Dense(64, activation='relu')(dense_function_layer)\n",
    "    numeric_function_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_function_hidden_layer = Dropout(dropout_value)(numeric_function_hidden_layer)\n",
    "    combined_function_layer = concatenate([numeric_function_hidden_layer, dense_function_layer])\n",
    "    function_output_layer = Dense(37, activation='softmax')(combined_function_layer)\n",
    "    \n",
    "    # Object_Type\n",
    "    word_embedding_object_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_object_type_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_object_type)\n",
    "    text_object_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Dropout(dropout_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Dropout(dropout_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Dropout(dropout_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Dropout(dropout_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_object_type_hidden_layer)\n",
    "    text_object_type_hidden_layer = Dropout(dropout_value)(text_object_type_hidden_layer)\n",
    "    dense_object_type_layer = Flatten()(text_object_type_hidden_layer)\n",
    "    dense_object_type_layer = Dense(16, activation='relu')(dense_object_type_layer)\n",
    "    numeric_object_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_object_type_hidden_layer = Dropout(dropout_value)(numeric_object_type_hidden_layer)\n",
    "    combined_object_type_layer = concatenate([numeric_object_type_hidden_layer, dense_object_type_layer])\n",
    "    object_type_output_layer = Dense(11, activation='softmax')(combined_object_type_layer)\n",
    "    \n",
    "    # Operating_Status\n",
    "    word_embedding_operating_status = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_operating_status_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_operating_status)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(8, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Conv1D(4, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_operating_status_hidden_layer)\n",
    "    text_operating_status_hidden_layer = Dropout(dropout_value)(text_operating_status_hidden_layer)\n",
    "    dense_operating_status_layer = Flatten()(text_operating_status_hidden_layer)\n",
    "    dense_operating_status_layer = Dense(4, activation='relu')(dense_operating_status_layer)\n",
    "    numeric_operating_status_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_operating_status_hidden_layer = Dropout(dropout_value)(numeric_operating_status_hidden_layer)\n",
    "    combined_operating_status_layer = concatenate([numeric_operating_status_hidden_layer, dense_operating_status_layer])\n",
    "    operating_status_output_layer = Dense(3, activation='softmax')(combined_operating_status_layer)\n",
    "    \n",
    "    # Position_Type\n",
    "    word_embedding_position_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_position_type_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_position_type)\n",
    "    text_position_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Dropout(dropout_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Dropout(dropout_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Dropout(dropout_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_position_type_hidden_layer)\n",
    "    text_position_type_hidden_layer = Dropout(dropout_value)(text_position_type_hidden_layer)\n",
    "    dense_position_type_layer = Flatten()(text_position_type_hidden_layer)\n",
    "    dense_position_type_layer = Dense(32, activation='relu')(dense_position_type_layer)\n",
    "    numeric_position_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_position_type_hidden_layer = Dropout(dropout_value)(numeric_position_type_hidden_layer)\n",
    "    combined_position_type_layer = concatenate([numeric_position_type_hidden_layer, dense_position_type_layer])\n",
    "    position_type_output_layer = Dense(25, activation='softmax')(combined_position_type_layer)\n",
    "    \n",
    "    # Pre_K\n",
    "    word_embedding_pre_k = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_pre_k_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_pre_k)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(8, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Conv1D(4, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_pre_k_hidden_layer)\n",
    "    text_pre_k_hidden_layer = Dropout(dropout_value)(text_pre_k_hidden_layer)\n",
    "    dense_pre_k_layer = Flatten()(text_pre_k_hidden_layer)\n",
    "    dense_pre_k_layer = Dense(4, activation='relu')(dense_pre_k_layer)\n",
    "    numeric_pre_k_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_pre_k_hidden_layer = Dropout(dropout_value)(numeric_pre_k_hidden_layer)\n",
    "    combined_pre_k_layer = concatenate([numeric_pre_k_hidden_layer, dense_pre_k_layer])\n",
    "    pre_k_output_layer = Dense(3, activation='softmax')(combined_pre_k_layer)\n",
    "    \n",
    "    # Reporting\n",
    "    word_embedding_reporting = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_reporting_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_reporting)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(8, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Conv1D(4, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_reporting_hidden_layer)\n",
    "    text_reporting_hidden_layer = Dropout(dropout_value)(text_reporting_hidden_layer)\n",
    "    dense_reporting_layer = Flatten()(text_pre_k_hidden_layer)\n",
    "    dense_reporting_layer = Dense(4, activation='relu')(dense_reporting_layer)\n",
    "    numeric_reporting_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_reporting_hidden_layer = Dropout(dropout_value)(numeric_reporting_hidden_layer)\n",
    "    combined_reporting_layer = concatenate([numeric_reporting_hidden_layer, dense_reporting_layer])\n",
    "    reporting_output_layer = Dense(3, activation='softmax')(combined_reporting_layer)\n",
    "    \n",
    "    # Sharing\n",
    "    word_embedding_sharing = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_sharing_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_sharing)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Conv1D(8, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_sharing_hidden_layer)\n",
    "    text_sharing_hidden_layer = Dropout(dropout_value)(text_sharing_hidden_layer)\n",
    "    dense_sharing_layer = Flatten()(text_sharing_hidden_layer)\n",
    "    dense_sharing_layer = Dense(8, activation='relu')(dense_sharing_layer)\n",
    "    numeric_sharing_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_sharing_hidden_layer = Dropout(dropout_value)(numeric_sharing_hidden_layer)\n",
    "    combined_sharing_layer = concatenate([numeric_sharing_hidden_layer, dense_sharing_layer])\n",
    "    sharing_output_layer = Dense(5, activation='softmax')(combined_sharing_layer)\n",
    "    \n",
    "    # Student_Type\n",
    "    word_embedding_student_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_student_type_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_student_type)\n",
    "    text_student_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Dropout(dropout_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Dropout(dropout_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Dropout(dropout_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Dropout(dropout_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_student_type_hidden_layer)\n",
    "    text_student_type_hidden_layer = Dropout(dropout_value)(text_student_type_hidden_layer)\n",
    "    dense_student_type_layer = Flatten()(text_student_type_hidden_layer)\n",
    "    dense_student_type_layer = Dense(16, activation='relu')(dense_student_type_layer)\n",
    "    numeric_student_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_student_type_hidden_layer = Dropout(dropout_value)(numeric_student_type_hidden_layer)\n",
    "    combined_student_type_layer = concatenate([numeric_student_type_hidden_layer, dense_student_type_layer])\n",
    "    student_type_output_layer = Dense(9, activation='softmax')(combined_student_type_layer)\n",
    "    \n",
    "    # Use\n",
    "    word_embedding_use = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=False, input_length=50)(text_input)\n",
    "    text_use_hidden_layer = Conv1D(256, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(word_embedding_use)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Conv1D(128, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Conv1D(64, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Conv1D(32, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Conv1D(16, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Conv1D(8, kernel_size=kernel_size_value, padding=padding_value, strides=stride_value, activation='relu')(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = MaxPooling1D(pool_size=pool_size_value, padding=padding_value, strides=stride_value)(text_use_hidden_layer)\n",
    "    text_use_hidden_layer = Dropout(dropout_value)(text_use_hidden_layer)\n",
    "    dense_use_layer = Flatten()(text_use_hidden_layer)\n",
    "    dense_use_layer = Dense(8, activation='relu')(dense_use_layer)\n",
    "    numeric_use_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_use_hidden_layer = Dropout(dropout_value)(numeric_use_hidden_layer)\n",
    "    combined_use_layer = concatenate([numeric_use_hidden_layer, dense_use_layer])\n",
    "    use_output_layer = Dense(8, activation='softmax')(combined_use_layer)\n",
    "    \n",
    "    # Output\n",
    "    combined_output_layer = concatenate([function_output_layer, \n",
    "                                         object_type_output_layer,\n",
    "                                         operating_status_output_layer,\n",
    "                                         position_type_output_layer,\n",
    "                                         pre_k_output_layer,\n",
    "                                         reporting_output_layer,\n",
    "                                         sharing_output_layer,\n",
    "                                         student_type_output_layer,\n",
    "                                         use_output_layer])\n",
    "    \n",
    "    model = Model(inputs=[numeric_input, text_input], outputs=[combined_output_layer])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkm6VVkF5eP2"
   },
   "outputs": [],
   "source": [
    "cnn_NN = build_network()\n",
    "\n",
    "# Save model architecture\n",
    "model_json = cnn_NN.to_json()\n",
    "with open('cnn_NN_model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INIHpqTn5eP4"
   },
   "source": [
    "# Train model and generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1992339,
     "status": "ok",
     "timestamp": 1534620483870,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "h2fWentL1If6",
    "outputId": "21afe851-b455-4a6a-ce16-80925a6f5553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315191 samples, validate on 35022 samples\n",
      "Epoch 1/100\n",
      "315191/315191 [==============================] - 179s 569us/step - loss: 68.7306 - acc: 0.0252 - val_loss: 61.7684 - val_acc: 0.0563\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 61.76838, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 2/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 49.5048 - acc: 0.1147 - val_loss: 50.5769 - val_acc: 0.1872\n",
      "\n",
      "Epoch 00002: val_loss improved from 61.76838 to 50.57688, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 3/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 41.2320 - acc: 0.1683 - val_loss: 36.3888 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00003: val_loss improved from 50.57688 to 36.38877, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 4/100\n",
      "315191/315191 [==============================] - 171s 543us/step - loss: 35.2857 - acc: 0.1882 - val_loss: 33.4225 - val_acc: 0.1951\n",
      "\n",
      "Epoch 00004: val_loss improved from 36.38877 to 33.42253, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 5/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 33.6412 - acc: 0.1642 - val_loss: 32.9633 - val_acc: 0.1831\n",
      "\n",
      "Epoch 00005: val_loss improved from 33.42253 to 32.96327, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 6/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 32.2925 - acc: 0.1487 - val_loss: 30.9964 - val_acc: 0.1750\n",
      "\n",
      "Epoch 00006: val_loss improved from 32.96327 to 30.99641, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 7/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 31.5322 - acc: 0.1458 - val_loss: 30.2955 - val_acc: 0.1719\n",
      "\n",
      "Epoch 00007: val_loss improved from 30.99641 to 30.29552, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 8/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 30.9468 - acc: 0.1473 - val_loss: 29.9167 - val_acc: 0.1751\n",
      "\n",
      "Epoch 00008: val_loss improved from 30.29552 to 29.91674, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 9/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 30.7094 - acc: 0.1499 - val_loss: 30.0747 - val_acc: 0.1765\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 29.91674\n",
      "Epoch 10/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 30.3605 - acc: 0.1582 - val_loss: 29.5956 - val_acc: 0.1864\n",
      "\n",
      "Epoch 00010: val_loss improved from 29.91674 to 29.59557, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 11/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 29.7625 - acc: 0.1629 - val_loss: 28.9923 - val_acc: 0.1853\n",
      "\n",
      "Epoch 00011: val_loss improved from 29.59557 to 28.99226, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 12/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 29.3562 - acc: 0.1662 - val_loss: 29.0818 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 28.99226\n",
      "Epoch 13/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 29.1431 - acc: 0.1716 - val_loss: 28.5252 - val_acc: 0.1819\n",
      "\n",
      "Epoch 00013: val_loss improved from 28.99226 to 28.52523, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 14/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 28.8890 - acc: 0.1764 - val_loss: 28.3327 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00014: val_loss improved from 28.52523 to 28.33266, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 15/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 28.6693 - acc: 0.1798 - val_loss: 28.3409 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 28.33266\n",
      "Epoch 16/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 28.4453 - acc: 0.1815 - val_loss: 27.6308 - val_acc: 0.2193\n",
      "\n",
      "Epoch 00016: val_loss improved from 28.33266 to 27.63075, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 17/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 28.3596 - acc: 0.1860 - val_loss: 27.6682 - val_acc: 0.1996\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 27.63075\n",
      "Epoch 18/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 28.2103 - acc: 0.1883 - val_loss: 27.4634 - val_acc: 0.2097\n",
      "\n",
      "Epoch 00018: val_loss improved from 27.63075 to 27.46342, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 19/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 28.1044 - acc: 0.1923 - val_loss: 27.3689 - val_acc: 0.2173\n",
      "\n",
      "Epoch 00019: val_loss improved from 27.46342 to 27.36890, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 20/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 28.1167 - acc: 0.1927 - val_loss: 26.8357 - val_acc: 0.2289\n",
      "\n",
      "Epoch 00020: val_loss improved from 27.36890 to 26.83574, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 21/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 27.7609 - acc: 0.1922 - val_loss: 27.0233 - val_acc: 0.2157\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 26.83574\n",
      "Epoch 22/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 27.5400 - acc: 0.1968 - val_loss: 26.2059 - val_acc: 0.2068\n",
      "\n",
      "Epoch 00022: val_loss improved from 26.83574 to 26.20588, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 23/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 27.2628 - acc: 0.2174 - val_loss: 25.5559 - val_acc: 0.2499\n",
      "\n",
      "Epoch 00023: val_loss improved from 26.20588 to 25.55588, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 24/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 27.0627 - acc: 0.2148 - val_loss: 25.8837 - val_acc: 0.2392\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 25.55588\n",
      "Epoch 25/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 26.9363 - acc: 0.2046 - val_loss: 25.9602 - val_acc: 0.2402\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 25.55588\n",
      "Epoch 26/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.8496 - acc: 0.1997 - val_loss: 25.7016 - val_acc: 0.2283\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 25.55588\n",
      "Epoch 27/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 26.7254 - acc: 0.2030 - val_loss: 26.2311 - val_acc: 0.2355\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 25.55588\n",
      "Epoch 28/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.6736 - acc: 0.2039 - val_loss: 25.4587 - val_acc: 0.2216\n",
      "\n",
      "Epoch 00028: val_loss improved from 25.55588 to 25.45870, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 29/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.6608 - acc: 0.2018 - val_loss: 25.1649 - val_acc: 0.2285\n",
      "\n",
      "Epoch 00029: val_loss improved from 25.45870 to 25.16495, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 30/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.5513 - acc: 0.2015 - val_loss: 25.6780 - val_acc: 0.2018\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 25.16495\n",
      "Epoch 31/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.5094 - acc: 0.1957 - val_loss: 25.3406 - val_acc: 0.1934\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 25.16495\n",
      "Epoch 32/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 26.4690 - acc: 0.1929 - val_loss: 25.0548 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00032: val_loss improved from 25.16495 to 25.05484, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 33/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 26.4274 - acc: 0.1974 - val_loss: 26.2710 - val_acc: 0.2006\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 25.05484\n",
      "Epoch 34/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.4538 - acc: 0.1980 - val_loss: 25.5366 - val_acc: 0.2158\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 25.05484\n",
      "Epoch 35/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.3305 - acc: 0.1997 - val_loss: 25.3379 - val_acc: 0.1957\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 25.05484\n",
      "Epoch 36/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.3021 - acc: 0.1975 - val_loss: 25.3892 - val_acc: 0.2002\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 25.05484\n",
      "Epoch 37/100\n",
      "315191/315191 [==============================] - 171s 542us/step - loss: 26.3428 - acc: 0.2075 - val_loss: 25.2659 - val_acc: 0.2071\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 25.05484\n",
      "Epoch 38/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.1588 - acc: 0.2101 - val_loss: 25.4759 - val_acc: 0.1686\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 25.05484\n",
      "Epoch 39/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 26.2536 - acc: 0.2079 - val_loss: 25.6855 - val_acc: 0.2003\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 25.05484\n",
      "Epoch 40/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.2128 - acc: 0.2064 - val_loss: 24.6933 - val_acc: 0.2012\n",
      "\n",
      "Epoch 00040: val_loss improved from 25.05484 to 24.69326, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 41/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.2793 - acc: 0.2043 - val_loss: 25.1740 - val_acc: 0.2193\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 24.69326\n",
      "Epoch 42/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 26.1345 - acc: 0.2105 - val_loss: 25.4862 - val_acc: 0.1978\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 24.69326\n",
      "Epoch 43/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 26.0543 - acc: 0.2123 - val_loss: 25.3753 - val_acc: 0.2202\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 24.69326\n",
      "Epoch 44/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 26.0763 - acc: 0.2102 - val_loss: 25.3024 - val_acc: 0.2013\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 24.69326\n",
      "Epoch 45/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.9683 - acc: 0.2061 - val_loss: 24.9070 - val_acc: 0.2018\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 24.69326\n",
      "Epoch 46/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.8604 - acc: 0.1990 - val_loss: 24.8390 - val_acc: 0.2008\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 24.69326\n",
      "Epoch 47/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.8294 - acc: 0.2041 - val_loss: 24.9468 - val_acc: 0.2030\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 24.69326\n",
      "Epoch 48/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.7623 - acc: 0.2036 - val_loss: 24.8306 - val_acc: 0.1576\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 24.69326\n",
      "Epoch 49/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 25.7878 - acc: 0.2013 - val_loss: 24.4871 - val_acc: 0.1520\n",
      "\n",
      "Epoch 00049: val_loss improved from 24.69326 to 24.48714, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 50/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 25.6951 - acc: 0.1983 - val_loss: 24.9289 - val_acc: 0.1461\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 24.48714\n",
      "Epoch 51/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 25.7585 - acc: 0.1993 - val_loss: 24.9774 - val_acc: 0.1915\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 24.48714\n",
      "Epoch 52/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.7826 - acc: 0.1990 - val_loss: 24.5336 - val_acc: 0.1633\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 24.48714\n",
      "Epoch 53/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.7614 - acc: 0.2118 - val_loss: 24.5044 - val_acc: 0.1538\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 24.48714\n",
      "Epoch 54/100\n",
      "315191/315191 [==============================] - 170s 538us/step - loss: 25.7133 - acc: 0.2033 - val_loss: 24.9698 - val_acc: 0.1709\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 24.48714\n",
      "Epoch 55/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.6286 - acc: 0.2049 - val_loss: 24.5583 - val_acc: 0.1529\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 24.48714\n",
      "Epoch 56/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 25.5722 - acc: 0.2020 - val_loss: 24.2078 - val_acc: 0.1492\n",
      "\n",
      "Epoch 00056: val_loss improved from 24.48714 to 24.20778, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 57/100\n",
      "315191/315191 [==============================] - 171s 541us/step - loss: 25.5592 - acc: 0.1974 - val_loss: 24.1063 - val_acc: 0.1478\n",
      "\n",
      "Epoch 00057: val_loss improved from 24.20778 to 24.10633, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 58/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 25.4998 - acc: 0.2032 - val_loss: 24.3822 - val_acc: 0.1733\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 24.10633\n",
      "Epoch 59/100\n",
      "315191/315191 [==============================] - 170s 538us/step - loss: 25.5384 - acc: 0.2025 - val_loss: 24.9190 - val_acc: 0.1767\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 24.10633\n",
      "Epoch 60/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.6371 - acc: 0.2007 - val_loss: 24.7059 - val_acc: 0.1780\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 24.10633\n",
      "Epoch 61/100\n",
      "315191/315191 [==============================] - 170s 538us/step - loss: 25.5435 - acc: 0.1971 - val_loss: 24.8524 - val_acc: 0.1818\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 24.10633\n",
      "Epoch 62/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.5561 - acc: 0.2029 - val_loss: 24.4078 - val_acc: 0.1447\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 24.10633\n",
      "Epoch 63/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.5241 - acc: 0.2023 - val_loss: 24.7053 - val_acc: 0.1688\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 24.10633\n",
      "Epoch 64/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 25.5327 - acc: 0.1955 - val_loss: 24.8157 - val_acc: 0.1894\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 24.10633\n",
      "Epoch 65/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 25.5898 - acc: 0.2021 - val_loss: 24.7686 - val_acc: 0.1519\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 24.10633\n",
      "Epoch 66/100\n",
      "315191/315191 [==============================] - 170s 540us/step - loss: 25.4244 - acc: 0.1988 - val_loss: 24.0819 - val_acc: 0.1799\n",
      "\n",
      "Epoch 00066: val_loss improved from 24.10633 to 24.08195, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 67/100\n",
      "315191/315191 [==============================] - 170s 539us/step - loss: 25.3301 - acc: 0.2045 - val_loss: 24.6804 - val_acc: 0.1513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 24.08195\n",
      "Epoch 68/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 25.4626 - acc: 0.2012 - val_loss: 24.6731 - val_acc: 0.1678\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 24.08195\n",
      "Epoch 69/100\n",
      "315191/315191 [==============================] - 170s 541us/step - loss: 25.4464 - acc: 0.2006 - val_loss: 24.5710 - val_acc: 0.1883\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 24.08195\n",
      "Epoch 70/100\n",
      "315191/315191 [==============================] - 171s 543us/step - loss: 25.3300 - acc: 0.1976 - val_loss: 23.6433 - val_acc: 0.1820\n",
      "\n",
      "Epoch 00070: val_loss improved from 24.08195 to 23.64327, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 71/100\n",
      "315191/315191 [==============================] - 172s 546us/step - loss: 25.3019 - acc: 0.2014 - val_loss: 23.6398 - val_acc: 0.1876\n",
      "\n",
      "Epoch 00071: val_loss improved from 23.64327 to 23.63976, saving model to drive/cnn_NN_model.h5\n",
      "Epoch 72/100\n",
      "315191/315191 [==============================] - 173s 548us/step - loss: 25.3273 - acc: 0.2085 - val_loss: 24.4165 - val_acc: 0.1574\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 23.63976\n",
      "Epoch 73/100\n",
      "315191/315191 [==============================] - 172s 545us/step - loss: 25.3339 - acc: 0.1988 - val_loss: 24.2773 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 23.63976\n",
      "Epoch 74/100\n",
      "315191/315191 [==============================] - 172s 546us/step - loss: 25.2395 - acc: 0.2003 - val_loss: 24.5518 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 23.63976\n",
      "Epoch 75/100\n",
      "315191/315191 [==============================] - 172s 545us/step - loss: 25.2907 - acc: 0.1981 - val_loss: 24.0006 - val_acc: 0.1819\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 23.63976\n",
      "Epoch 76/100\n",
      "315191/315191 [==============================] - 172s 545us/step - loss: 25.2453 - acc: 0.2020 - val_loss: 24.3289 - val_acc: 0.1793\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 23.63976\n",
      "Epoch 77/100\n",
      "315191/315191 [==============================] - 172s 546us/step - loss: 25.2558 - acc: 0.2057 - val_loss: 24.3747 - val_acc: 0.1628\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 23.63976\n",
      "Epoch 78/100\n",
      "315191/315191 [==============================] - 172s 547us/step - loss: 25.2678 - acc: 0.1990 - val_loss: 24.6473 - val_acc: 0.1825\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 23.63976\n",
      "Epoch 79/100\n",
      "315191/315191 [==============================] - 172s 545us/step - loss: 25.2133 - acc: 0.2015 - val_loss: 24.1976 - val_acc: 0.1524\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 23.63976\n",
      "Epoch 80/100\n",
      "315191/315191 [==============================] - 173s 548us/step - loss: 25.2490 - acc: 0.1896 - val_loss: 23.9547 - val_acc: 0.1680\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 23.63976\n",
      "Epoch 81/100\n",
      "315191/315191 [==============================] - 172s 544us/step - loss: 25.1693 - acc: 0.1936 - val_loss: 23.9527 - val_acc: 0.1774\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 23.63976\n"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "checkpointer = ModelCheckpoint(filepath=\"cnn_NN_model.h5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history_cnn_NN = cnn_NN.fit([X_train_numeric, X_train_text], y_train, epochs=100, batch_size=2048, validation_split=0.1, callbacks=[early_stopping_monitor, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1534621630758,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "Aqfq_Q9VDf5B",
    "outputId": "c2790c22-4e96-4863-d50d-cd76b74044af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFnCAYAAACLnxFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f629ebf47f0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_cnn_NN.history['loss'])\n",
    "plt.plot(history_cnn_NN.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model\n",
    "Run cell below if model has already been trained, and json and h5 files are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzyY-6uQNQCT"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "with open('cnn_NN_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    \n",
    "cnn_NN = model_from_json(loaded_model_json)\n",
    "cnn_NN.load_weights(\"cnn_NN_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions on test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlXYzPrd5eP4"
   },
   "outputs": [],
   "source": [
    "label_class_counts = {\n",
    "    'Function': [0, 37], \n",
    "    'Object_Type': [37, 48], \n",
    "    'Operating_Status': [48, 51], \n",
    "    'Position_Type': [51, 76], \n",
    "    'Pre_K': [76, 79], \n",
    "    'Reporting': [79, 82], \n",
    "    'Sharing': [82, 87], \n",
    "    'Student_Type': [87, 96], \n",
    "    'Use': [96, 104]\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "val_predictions = cnn_NN.predict([X_val_numeric, X_val_text])\n",
    "\n",
    "# Calculate validation logloss for each label\n",
    "for label, indices in label_class_counts.items():\n",
    "    # Get values for specific label\n",
    "    start_idx = indices[0]\n",
    "    end_idx = indices[1]\n",
    "    y_val_label = y_val[:, start_idx:end_idx]\n",
    "    val_predictions_label = val_predictions[:, start_idx:end_idx]\n",
    "    \n",
    "    \n",
    "    # Get logloss score of mode\n",
    "    scores[label] = log_loss(y_val_label, val_predictions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6d9EwoxGX3z"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for test set\n",
    "predictions = cnn_NN.predict([X_test_numeric, X_test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-pJMVIr5eP7"
   },
   "source": [
    "# Save score and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngyDlM8A5eP7"
   },
   "outputs": [],
   "source": [
    "# Save predictions for test set\n",
    "label = ['Function',\n",
    "         'Object_Type',\n",
    "         'Operating_Status',\n",
    "         'Position_Type',\n",
    "         'Pre_K',\n",
    "         'Reporting',\n",
    "         'Sharing',\n",
    "         'Student_Type',\n",
    "         'Use']\n",
    "y = pd.get_dummies(data_train[label]).astype('float64')\n",
    "\n",
    "submission = pd.DataFrame(predictions, index=data_test.index, columns=y.columns)\n",
    "submission.to_csv('cnn_NN_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1534621845424,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "uRHjIso15eP8",
    "outputId": "9e830f25-ee1e-48e2-c2b4-6f0a31bf920b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Function': 0.18381029245675215,\n",
       " 'Object_Type': 0.1767483893181308,\n",
       " 'Operating_Status': 0.44045025440946356,\n",
       " 'Position_Type': 0.1440102000181701,\n",
       " 'Pre_K': 0.30560131965580367,\n",
       " 'Reporting': 0.5625786333094639,\n",
       " 'Sharing': 0.23058234376702044,\n",
       " 'Student_Type': 0.4918790614674071,\n",
       " 'Use': 2.686110029018423}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1534621845828,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "yQd8s_q85eP_",
    "outputId": "38644d79-11e6-4e94-e477-041948beac3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5801967248245149"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([score for score in scores.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQxW3L5o5eQC"
   },
   "outputs": [],
   "source": [
    "with open('cnn_NN_score.json', 'w') as file:\n",
    "     file.write(json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn_NN_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
