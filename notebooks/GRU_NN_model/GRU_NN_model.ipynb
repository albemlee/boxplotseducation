{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnWCGPLQ5ePG"
   },
   "source": [
    "# Setup Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10723,
     "status": "ok",
     "timestamp": 1534736520929,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "Nrg9OIDy5ePJ",
    "outputId": "ca7445e7-1e05-4568-c8cb-c093e3d78329"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# To load data\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import Imputer\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To build model\n",
    "import keras\n",
    "from keras.layers import Dense, concatenate, Input, Dropout, Embedding, Flatten, Bidirectional, GRU\n",
    "from keras.models import Model\n",
    "\n",
    "# To train model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# To evaluate model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# To track time elapsed\n",
    "import time\n",
    "\n",
    "# To save results\n",
    "import dill\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPLEdpRv5ePM"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF3nUD615ePM"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Return pandas dataframe data_train: training data (features + labels)\n",
    "    Return pandas dataframe data_test: test data (only features)\n",
    "    \n",
    "    Required Libraries: zipfile, pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load zipped folder with data files\n",
    "    resource_archive = zipfile.ZipFile('resources.zip', 'r')\n",
    "\n",
    "    # Load testing data\n",
    "    data_test = pd.read_csv(resource_archive.open('TestData.csv'), \n",
    "                            dtype={\n",
    "                                'Object_Description': str, \n",
    "                                'Program_Description': str, \n",
    "                                'SubFund_Description': str, \n",
    "                                'Job_Title_Description': str, \n",
    "                                'Facility_or_Department': str,\n",
    "                                'Sub_Object_Description': str, \n",
    "                                'Location_Description': str, \n",
    "                                'FTE': float,\n",
    "                                'Function_Description': str, \n",
    "                                'Position_Extra': str, \n",
    "                                'Text_4': str, \n",
    "                                'Total': float, \n",
    "                                'Text_2': str,\n",
    "                                'Text_3': str, \n",
    "                                'Fund_Description': str, \n",
    "                                'Text_1': str\n",
    "                            },\n",
    "                            index_col=0)\n",
    "\n",
    "    # Load training data\n",
    "    data_train = pd.read_csv(resource_archive.open('TrainingData.csv'), \n",
    "                            dtype={\n",
    "                                'Object_Description': str, \n",
    "                                'Program_Description': str, \n",
    "                                'SubFund_Description': str, \n",
    "                                'Job_Title_Description': str, \n",
    "                                'Facility_or_Department': str,\n",
    "                                'Sub_Object_Description': str, \n",
    "                                'Location_Description': str, \n",
    "                                'FTE': float,\n",
    "                                'Function_Description': str, \n",
    "                                'Position_Extra': str, \n",
    "                                'Text_4': str, \n",
    "                                'Total': float, \n",
    "                                'Text_2': str,\n",
    "                                'Text_3': str, \n",
    "                                'Fund_Description': str, \n",
    "                                'Text_1': str,\n",
    "                                'Function': 'category',\n",
    "                                'Object_Type': 'category',\n",
    "                                'Operating_Status': 'category',\n",
    "                                'Position_Type': 'category',\n",
    "                                'Pre_K': 'category',\n",
    "                                'Reporting': 'category',\n",
    "                                'Sharing': 'category',\n",
    "                                'Student_Type': 'category',\n",
    "                                'Use': 'category',\n",
    "                            },\n",
    "                             index_col=0)\n",
    "    \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2968,
     "status": "ok",
     "timestamp": 1534736527771,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "GVz1rkaX5ePP",
    "outputId": "48d6f38e-6abf-4a9f-ffc4-ffaefbb15d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape: (400277, 25)\n",
      "data_test shape: (50064, 16)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = load_data()\n",
    "print('data_train shape:', data_train.shape)\n",
    "print('data_test shape:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i203UxGy5ePT"
   },
   "outputs": [],
   "source": [
    "def load_features(data_train, data_test):\n",
    "    \"\"\"\n",
    "    Return pandas dataframe data_features: data in feature columns of data_train and data_test\n",
    "    \n",
    "    Param pandas dataframe data_train: training data (features + labels)\n",
    "    Param pandas dataframe data_test: test data (only features)\n",
    "    \n",
    "    Required Libraries: pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_columns = data_test.columns # data_test only contains features\n",
    "    \n",
    "    data_features = pd.concat([data_train[feature_columns], data_test])\n",
    "    \n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1534736528579,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "vBZekpVd5ePV",
    "outputId": "ab45dcb6-f1f4-42a5-b89d-bde4f6177d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_features shape: (450341, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load Features\n",
    "data_features = load_features(data_train, data_test)\n",
    "print('data_features shape:', data_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ITNF9275ePY"
   },
   "source": [
    "# Prepare Data for Classification\n",
    "Run the cells below if prepped data files have not been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ID0Uo8GT5ePY"
   },
   "outputs": [],
   "source": [
    "def text_processing(phrase):\n",
    "    \"\"\"\n",
    "    Return list processed_phrase: phrase tokens after processing has been completed\n",
    "    \n",
    "    param string phrase: phrase to be processed\n",
    "    \n",
    "    Required Libraries: re, nltk\n",
    "    \"\"\"\n",
    "    \n",
    "    # Case Normalization\n",
    "    processed_phrase = phrase.lower()\n",
    "    \n",
    "    # Remove Punctuations\n",
    "    processed_phrase = re.sub(r\"[^a-z0-9-]\", \" \", processed_phrase)\n",
    "    \n",
    "    # Tokenize Phrase\n",
    "    processed_phrase = processed_phrase.split()\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    processed_phrase = [word for word in processed_phrase if word not in stopwords.words(\"english\") and word != '-']\n",
    "    \n",
    "    # Lemmatization\n",
    "    processed_phrase = [WordNetLemmatizer().lemmatize(word) for word in processed_phrase]\n",
    "    \n",
    "    # Recombine list into phrase\n",
    "    processed_phrase = ' '.join(processed_phrase)\n",
    "    \n",
    "    return processed_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZapkVld5ePb",
    "outputId": "8bf67ef2-f47a-4d30-84cf-7bb823a5cd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past patiently waitin passionately smashin every expectation every action act creation laughin face casualty sorrow first time thinkin past tomorrow\n",
      "2.5811121463775635\n"
     ]
    }
   ],
   "source": [
    "# test text_processing function (with quote from Hamilton: The Musical)\n",
    "start_time = time.time()\n",
    "print(text_processing(\n",
    "    \"I’m past patiently waitin’. I’m passionately smashin’ every expectation. \" + \n",
    "    \"Every action’s an act of creation! \" +\n",
    "    \"I’m laughin’ in the face of casualties and sorrow. \" +\n",
    "    \"For the first time, I’m thinkin’ past tomorrow\"))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFQgJuJ_5ePd"
   },
   "outputs": [],
   "source": [
    "def init_prep(data_train, data_test, data_features, label=None):\n",
    "    \"\"\"\n",
    "    Return numpy array X_numeric: numerical feature matrix of test set\n",
    "    Return numpy array X_text: text feature matrix for classification model fitting\n",
    "    Return numpy array X_numeric_test: numerical feature matrix of test set\n",
    "    Return numpy array X_text_test: text feature matrix for classification model fitting\n",
    "    Return numpy array y: labels matrix for classification model fitting\n",
    "    Return keras.Tokenizer() tokenize: contains word to token mapping\n",
    "    \n",
    "    Param pandas dataframe data_train: training data (features + labels)\n",
    "    Param pandas dataframe data_test: test data (features)\n",
    "    Param pandas dataframe data_features: data in feature columns of data_train and data_test\n",
    "    \n",
    "    Required Libraries: pandas, numpy, keras\n",
    "    Required helper functions: text_processing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combined and preprocess text columns\n",
    "    data_train['combined_text'] = (data_train[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                  )\n",
    "    data_test['combined_text'] = (data_test[data_features.columns]\n",
    "                                       .drop(columns=['FTE', 'Total'])\n",
    "                                       .fillna(\"\")\n",
    "                                       .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                       .apply(lambda x: text_processing(x))\n",
    "                                 )\n",
    "    data_features['combined_text'] = (data_features\n",
    "                                          .drop(columns=['FTE', 'Total'])\n",
    "                                          .fillna(\"\")\n",
    "                                          .apply(lambda x: \" \".join(x), axis=1)\n",
    "                                          .apply(lambda x: text_processing(x))\n",
    "                                     )\n",
    "    \n",
    "    # Vectorizer text columns in training data\n",
    "    tokenize = Tokenizer()\n",
    "    tokenize.fit_on_texts(data_features['combined_text'])\n",
    "    \n",
    "    X_text = tokenize.texts_to_sequences(data_train['combined_text'])\n",
    "    X_text_test = tokenize.texts_to_sequences(data_test['combined_text'])\n",
    "    \n",
    "    X_text = pad_sequences(X_text, padding='post', maxlen=50, truncating='post')\n",
    "    X_text_test = pad_sequences(X_text_test, padding='post', maxlen=50, truncating='post')\n",
    "    \n",
    "    # Impute missing numerical data\n",
    "    imp_total = Imputer(strategy='median')\n",
    "    imp_total.fit(data_features['Total'].values.reshape(-1, 1))\n",
    "\n",
    "    total_not_missing = pd.isnull(data_train['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing = pd.isnull(data_train['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total = imp_total.transform(data_train['Total'].values.reshape(-1, 1))\n",
    "    fte = data_train['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "\n",
    "    total_not_missing_test = pd.isnull(data_test['Total']).astype(int).values.reshape(-1, 1)\n",
    "    fte_not_missing_test = pd.isnull(data_test['FTE']).astype(int).values.reshape(-1, 1)\n",
    "    total_test = imp_total.transform(data_test['Total'].values.reshape(-1, 1))\n",
    "    fte_test = data_test['FTE'].fillna('0').values.reshape(-1, 1)\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X_numeric = np.concatenate([total, total_not_missing, fte, fte_not_missing], axis=1)\n",
    "    X_numeric_test = np.concatenate([total_test, total_not_missing_test, fte_test, fte_not_missing_test], axis=1)\n",
    "    \n",
    "    # Create labels matrix\n",
    "    if label:\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    else:\n",
    "        label = ['Function',\n",
    "                 'Object_Type',\n",
    "                 'Operating_Status',\n",
    "                 'Position_Type',\n",
    "                 'Pre_K',\n",
    "                 'Reporting',\n",
    "                 'Sharing',\n",
    "                 'Student_Type',\n",
    "                 'Use']\n",
    "        y = pd.get_dummies(data_train[label]).values.astype('float64')\n",
    "    \n",
    "    return X_numeric, X_text, X_numeric_test, X_text_test, y, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IISwk-c5ePf"
   },
   "outputs": [],
   "source": [
    "X_numeric, X_text, X_test_numeric, X_test_text, y, tokenize = init_prep(data_train, data_test, data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeEwXBk75ePi"
   },
   "outputs": [],
   "source": [
    "# Save X_test_text and X_test_numeric\n",
    "np.savez('X_test_text.npz', X_test_text)\n",
    "np.savez('X_test_numeric.npz', X_test_numeric)\n",
    "\n",
    "# Pickle tokenize\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenize, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3wYrZqv5ePp"
   },
   "outputs": [],
   "source": [
    "def prep_for_classification(X_numeric, X_text, y, validation_size=50064):\n",
    "    \"\"\"\n",
    "    Split training data into training and validation sets\n",
    "    \n",
    "    Return pandas dataframe X_train_numeric: training data (features)\n",
    "    Return pandas dataframe X_train_text: training data (features)\n",
    "    Return pandas dataframe X_val_numeric: validation data (features)\n",
    "    Return pandas dataframe X_val_text: validation data (features)\n",
    "    Return pandas dataframe y_train: training data (labels)\n",
    "    Return pandas dataframe y_val: validation data (labels)\n",
    "    \n",
    "    param numpy array X_numeric: numerical feature matrix of test set\n",
    "    param numpy array X_text: text feature matrix for classification model fitting\n",
    "    param numpy array X_numeric_test: numerical feature matrix of test set\n",
    "    param numpy array X_text_test: text feature matrix for classification model fitting\n",
    "    param numpy array y: labels matrix for classification model fitting\n",
    "    \n",
    "    Required Libraries: pandas, sklearn.model_selection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split into training and development sets\n",
    "    X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val = train_test_split(X_numeric, X_text, y, test_size=validation_size, random_state=93)\n",
    "    \n",
    "    return X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drbaQuel5ePr",
    "outputId": "09b43a88-46f1-4b6e-8bd6-4be33d7986d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_numeric (350213, 4)\n",
      "X_train_text (350213, 50)\n",
      "y_train (350213, 104)\n",
      "X_val_numeric (50064, 4)\n",
      "X_val_text (50064, 50)\n",
      "y_val (50064, 104)\n"
     ]
    }
   ],
   "source": [
    "X_train_numeric, X_val_numeric, X_train_text, X_val_text, y_train, y_val = prep_for_classification(X_numeric, X_text, y)\n",
    "print('X_train_numeric', X_train_numeric.shape)\n",
    "print('X_train_text', X_train_text.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val_numeric', X_val_numeric.shape)\n",
    "print('X_val_text', X_val_text.shape)\n",
    "print('y_val', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhVYZEmx5ePv"
   },
   "outputs": [],
   "source": [
    "# Save prepped data\n",
    "y_train = sparse.csr_matrix(y_train)\n",
    "y_val = sparse.csr_matrix(y_val)\n",
    "\n",
    "np.savez('X_train_text.npz', X_train_text)\n",
    "np.savez('X_val_text.npz', X_val_text)\n",
    "np.savez('X_train_numeric.npz', X_train_numeric)\n",
    "np.savez('X_val_numeric.npz', X_val_numeric)\n",
    "sparse.save_npz('y_train.npz', y_train)\n",
    "sparse.save_npz('y_val.npz', y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Prepped Data\n",
    "Run these cells below if prepped data files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 212386,
     "status": "ok",
     "timestamp": 1534736758583,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "hGz1Dw0S5ePx",
    "outputId": "924fd394-4ed8-45e4-ccd7-fa318e6b43cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_numeric (350213, 4)\n",
      "X_train_text (350213, 50)\n",
      "y_train (350213, 104)\n",
      "X_val_numeric (50064, 4)\n",
      "X_val_text (50064, 50)\n",
      "y_val (50064, 104)\n",
      "X_test_numeric (50064, 4)\n",
      "X_test_text (50064, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_text = np.load('X_train_text.npz')['arr_0']\n",
    "X_val_text = np.load('X_val_text.npz')['arr_0']\n",
    "X_train_numeric = np.load('X_train_numeric.npz')['arr_0']\n",
    "X_val_numeric = np.load('X_val_numeric.npz')['arr_0']\n",
    "y_train = sparse.load_npz('y_train.npz')\n",
    "y_val = sparse.load_npz('y_val.npz')\n",
    "X_test_numeric = np.load('X_test_numeric.npz')['arr_0']\n",
    "X_test_text = np.load('X_test_text.npz')['arr_0']\n",
    "\n",
    "print('X_train_numeric', X_train_numeric.shape)\n",
    "print('X_train_text', X_train_text.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val_numeric', X_val_numeric.shape)\n",
    "print('X_val_text', X_val_text.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test_numeric', X_test_numeric.shape)\n",
    "print('X_test_text', X_test_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfppW7oi5eP0"
   },
   "source": [
    "# Build Model\n",
    "Run cells below if model has not been fitted yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtnM3_nE5eP0"
   },
   "outputs": [],
   "source": [
    "def build_network(X_numeric=X_train_numeric, X_text=X_train_text, y=y_train):\n",
    "    \"\"\"\n",
    "    Return compiled keras-model model\n",
    "    \n",
    "    param numpy array X: feature matrix for classification\n",
    "    param numpy array y: labels matrix for classification\n",
    "    \n",
    "    Required Libraries: keras\n",
    "    \"\"\"\n",
    "    \n",
    "    dropout_value = 0.5\n",
    "    embedding_vector_length = 8\n",
    "    \n",
    "    numeric_input = Input(shape=(X_numeric.shape[1],) , name='numeric_input') \n",
    "    text_input = Input(shape=(X_text.shape[1],) , name='text_input')\n",
    "    \n",
    "    # Function\n",
    "    word_embedding_function = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_function_hidden_layer = Bidirectional(GRU(37, activation='relu', dropout=dropout_value))(word_embedding_function)\n",
    "    numeric_function_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_function_hidden_layer = Dropout(dropout_value)(numeric_function_hidden_layer)\n",
    "    combined_function_layer = concatenate([numeric_function_hidden_layer, text_function_hidden_layer])\n",
    "    function_output_layer = Dense(37, activation='softmax')(combined_function_layer)\n",
    "    \n",
    "    # Object_Type\n",
    "    word_embedding_object_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_object_type_hidden_layer = Bidirectional(GRU(11, activation='relu', dropout=dropout_value))(word_embedding_object_type)\n",
    "    numeric_object_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_object_type_hidden_layer = Dropout(dropout_value)(numeric_object_type_hidden_layer)\n",
    "    combined_object_type_layer = concatenate([numeric_object_type_hidden_layer, text_object_type_hidden_layer])\n",
    "    object_type_output_layer = Dense(11, activation='softmax')(combined_object_type_layer)\n",
    "    \n",
    "    # Operating_Status\n",
    "    word_embedding_operating_status = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_operating_status_hidden_layer = Bidirectional(GRU(3, activation='relu', dropout=dropout_value))(word_embedding_operating_status)\n",
    "    numeric_operating_status_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_operating_status_hidden_layer = Dropout(dropout_value)(numeric_operating_status_hidden_layer)\n",
    "    combined_operating_status_layer = concatenate([numeric_operating_status_hidden_layer, text_operating_status_hidden_layer])\n",
    "    operating_status_output_layer = Dense(3, activation='softmax')(combined_operating_status_layer)\n",
    "    \n",
    "    # Position_Type\n",
    "    word_embedding_position_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_position_type_hidden_layer = Bidirectional(GRU(25, activation='relu', dropout=dropout_value))(word_embedding_position_type)\n",
    "    numeric_position_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_position_type_hidden_layer = Dropout(dropout_value)(numeric_position_type_hidden_layer)\n",
    "    combined_position_type_layer = concatenate([numeric_position_type_hidden_layer, text_position_type_hidden_layer])\n",
    "    position_type_output_layer = Dense(25, activation='softmax')(combined_position_type_layer)\n",
    "    \n",
    "    # Pre_K\n",
    "    word_embedding_pre_k = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_pre_k_hidden_layer = Bidirectional(GRU(3, activation='relu', dropout=dropout_value))(word_embedding_pre_k)\n",
    "    numeric_pre_k_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_pre_k_hidden_layer = Dropout(dropout_value)(numeric_pre_k_hidden_layer)\n",
    "    combined_pre_k_layer = concatenate([numeric_pre_k_hidden_layer, text_pre_k_hidden_layer])\n",
    "    pre_k_output_layer = Dense(3, activation='softmax')(combined_pre_k_layer)\n",
    "    \n",
    "    # Reporting\n",
    "    word_embedding_reporting = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_reporting_hidden_layer = Bidirectional(GRU(3, activation='relu', dropout=dropout_value))(word_embedding_reporting)\n",
    "    numeric_reporting_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_reporting_hidden_layer = Dropout(dropout_value)(numeric_reporting_hidden_layer)\n",
    "    combined_reporting_layer = concatenate([numeric_reporting_hidden_layer, text_reporting_hidden_layer])\n",
    "    reporting_output_layer = Dense(3, activation='softmax')(combined_reporting_layer)\n",
    "    \n",
    "    # Sharing\n",
    "    word_embedding_sharing = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_sharing_hidden_layer = Bidirectional(GRU(5, activation='relu', dropout=dropout_value))(word_embedding_sharing)\n",
    "    numeric_sharing_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_sharing_hidden_layer = Dropout(dropout_value)(numeric_sharing_hidden_layer)\n",
    "    combined_sharing_layer = concatenate([numeric_sharing_hidden_layer, text_sharing_hidden_layer])\n",
    "    sharing_output_layer = Dense(5, activation='softmax')(combined_sharing_layer)\n",
    "    \n",
    "    # Student_Type\n",
    "    word_embedding_student_type = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_student_type_hidden_layer = Bidirectional(GRU(9, activation='relu', dropout=dropout_value))(word_embedding_student_type)\n",
    "    numeric_student_type_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_student_type_hidden_layer = Dropout(dropout_value)(numeric_student_type_hidden_layer)\n",
    "    combined_student_type_layer = concatenate([numeric_student_type_hidden_layer, text_student_type_hidden_layer])\n",
    "    student_type_output_layer = Dense(9, activation='softmax')(combined_student_type_layer)\n",
    "    \n",
    "    # Use\n",
    "    word_embedding_use = Embedding(input_dim=3804, output_dim=embedding_vector_length, mask_zero=True, input_length=50)(text_input)\n",
    "    text_use_hidden_layer = Bidirectional(GRU(8, activation='relu', dropout=dropout_value))(word_embedding_student_type)\n",
    "    numeric_use_hidden_layer = Dense(4, activation='relu')(numeric_input)\n",
    "    numeric_use_hidden_layer = Dropout(dropout_value)(numeric_use_hidden_layer)\n",
    "    combined_use_layer = concatenate([numeric_use_hidden_layer, text_use_hidden_layer])\n",
    "    use_output_layer = Dense(8, activation='softmax')(combined_use_layer)\n",
    "    \n",
    "    # Output\n",
    "    combined_output_layer = concatenate([function_output_layer, \n",
    "                                         object_type_output_layer,\n",
    "                                         operating_status_output_layer,\n",
    "                                         position_type_output_layer,\n",
    "                                         pre_k_output_layer,\n",
    "                                         reporting_output_layer,\n",
    "                                         sharing_output_layer,\n",
    "                                         student_type_output_layer,\n",
    "                                         use_output_layer])\n",
    "    \n",
    "    model = Model(inputs=[numeric_input, text_input], outputs=[combined_output_layer])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkm6VVkF5eP2"
   },
   "outputs": [],
   "source": [
    "gru_NN = build_network()\n",
    "\n",
    "model_json = gru_NN.to_json()\n",
    "with open('gru_NN_model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INIHpqTn5eP4"
   },
   "source": [
    "# Train model and generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5879
    },
    "colab_type": "code",
    "id": "h2fWentL1If6",
    "outputId": "3a3c48d5-de19-414a-a416-81b66dc07933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315191 samples, validate on 35022 samples\n",
      "Epoch 1/100\n",
      "315191/315191 [==============================] - 483s 2ms/step - loss: 79.0316 - acc: 0.0680 - val_loss: 73.2577 - val_acc: 0.0984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 73.25773, saving model to drive/gru_NN_model.h5\n",
      "Epoch 2/100\n",
      "315191/315191 [==============================] - 478s 2ms/step - loss: 47.6784 - acc: 0.0579 - val_loss: 38.8251 - val_acc: 0.0548\n",
      "\n",
      "Epoch 00002: val_loss improved from 73.25773 to 38.82506, saving model to drive/gru_NN_model.h5\n",
      "Epoch 3/100\n",
      "315191/315191 [==============================] - 471s 1ms/step - loss: 34.3271 - acc: 0.0364 - val_loss: 31.5897 - val_acc: 0.0436\n",
      "\n",
      "Epoch 00003: val_loss improved from 38.82506 to 31.58968, saving model to drive/gru_NN_model.h5\n",
      "Epoch 4/100\n",
      "315191/315191 [==============================] - 471s 1ms/step - loss: 29.3927 - acc: 0.0503 - val_loss: 28.3602 - val_acc: 0.0601\n",
      "\n",
      "Epoch 00004: val_loss improved from 31.58968 to 28.36025, saving model to drive/gru_NN_model.h5\n",
      "Epoch 5/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 26.9522 - acc: 0.0484 - val_loss: 25.4814 - val_acc: 0.0325\n",
      "\n",
      "Epoch 00005: val_loss improved from 28.36025 to 25.48138, saving model to drive/gru_NN_model.h5\n",
      "Epoch 6/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 25.0139 - acc: 0.0403 - val_loss: 24.1423 - val_acc: 0.0404\n",
      "\n",
      "Epoch 00006: val_loss improved from 25.48138 to 24.14234, saving model to drive/gru_NN_model.h5\n",
      "Epoch 7/100\n",
      "315191/315191 [==============================] - 467s 1ms/step - loss: 24.1415 - acc: 0.0410 - val_loss: 23.4231 - val_acc: 0.0343\n",
      "\n",
      "Epoch 00007: val_loss improved from 24.14234 to 23.42310, saving model to drive/gru_NN_model.h5\n",
      "Epoch 8/100\n",
      "315191/315191 [==============================] - 480s 2ms/step - loss: 23.4601 - acc: 0.0461 - val_loss: 22.6989 - val_acc: 0.0422\n",
      "\n",
      "Epoch 00008: val_loss improved from 23.42310 to 22.69887, saving model to drive/gru_NN_model.h5\n",
      "Epoch 9/100\n",
      "315191/315191 [==============================] - 492s 2ms/step - loss: 23.0916 - acc: 0.0558 - val_loss: 22.4633 - val_acc: 0.0701\n",
      "\n",
      "Epoch 00009: val_loss improved from 22.69887 to 22.46327, saving model to drive/gru_NN_model.h5\n",
      "Epoch 10/100\n",
      "315191/315191 [==============================] - 501s 2ms/step - loss: 22.8547 - acc: 0.0605 - val_loss: 22.2565 - val_acc: 0.0808\n",
      "\n",
      "Epoch 00010: val_loss improved from 22.46327 to 22.25648, saving model to drive/gru_NN_model.h5\n",
      "Epoch 11/100\n",
      "315191/315191 [==============================] - 486s 2ms/step - loss: 22.6555 - acc: 0.0622 - val_loss: 22.1187 - val_acc: 0.0821\n",
      "\n",
      "Epoch 00011: val_loss improved from 22.25648 to 22.11870, saving model to drive/gru_NN_model.h5\n",
      "Epoch 12/100\n",
      "315191/315191 [==============================] - 522s 2ms/step - loss: 22.5199 - acc: 0.0650 - val_loss: 21.9988 - val_acc: 0.0687\n",
      "\n",
      "Epoch 00012: val_loss improved from 22.11870 to 21.99884, saving model to drive/gru_NN_model.h5\n",
      "Epoch 13/100\n",
      "315191/315191 [==============================] - 482s 2ms/step - loss: 22.3869 - acc: 0.0645 - val_loss: 21.9174 - val_acc: 0.0846\n",
      "\n",
      "Epoch 00013: val_loss improved from 21.99884 to 21.91738, saving model to drive/gru_NN_model.h5\n",
      "Epoch 14/100\n",
      "315191/315191 [==============================] - 502s 2ms/step - loss: 22.2699 - acc: 0.0625 - val_loss: 21.7656 - val_acc: 0.0782\n",
      "\n",
      "Epoch 00014: val_loss improved from 21.91738 to 21.76560, saving model to drive/gru_NN_model.h5\n",
      "Epoch 15/100\n",
      "315191/315191 [==============================] - 511s 2ms/step - loss: 22.1455 - acc: 0.0620 - val_loss: 21.6766 - val_acc: 0.0840\n",
      "\n",
      "Epoch 00015: val_loss improved from 21.76560 to 21.67661, saving model to drive/gru_NN_model.h5\n",
      "Epoch 16/100\n",
      "315191/315191 [==============================] - 521s 2ms/step - loss: 22.0607 - acc: 0.0595 - val_loss: 21.6251 - val_acc: 0.0828\n",
      "\n",
      "Epoch 00016: val_loss improved from 21.67661 to 21.62507, saving model to drive/gru_NN_model.h5\n",
      "Epoch 17/100\n",
      "315191/315191 [==============================] - 458s 1ms/step - loss: 21.9958 - acc: 0.0591 - val_loss: 21.5536 - val_acc: 0.0686\n",
      "\n",
      "Epoch 00017: val_loss improved from 21.62507 to 21.55362, saving model to drive/gru_NN_model.h5\n",
      "Epoch 18/100\n",
      "315191/315191 [==============================] - 524s 2ms/step - loss: 21.9054 - acc: 0.0533 - val_loss: 21.4679 - val_acc: 0.0603\n",
      "\n",
      "Epoch 00018: val_loss improved from 21.55362 to 21.46791, saving model to drive/gru_NN_model.h5\n",
      "Epoch 19/100\n",
      "315191/315191 [==============================] - 481s 2ms/step - loss: 21.8405 - acc: 0.0526 - val_loss: 21.4191 - val_acc: 0.0785\n",
      "\n",
      "Epoch 00019: val_loss improved from 21.46791 to 21.41908, saving model to drive/gru_NN_model.h5\n",
      "Epoch 20/100\n",
      "315191/315191 [==============================] - 506s 2ms/step - loss: 21.7873 - acc: 0.0499 - val_loss: 21.3882 - val_acc: 0.0653\n",
      "\n",
      "Epoch 00020: val_loss improved from 21.41908 to 21.38820, saving model to drive/gru_NN_model.h5\n",
      "Epoch 21/100\n",
      "315191/315191 [==============================] - 470s 1ms/step - loss: 21.7625 - acc: 0.0449 - val_loss: 21.3513 - val_acc: 0.0529\n",
      "\n",
      "Epoch 00021: val_loss improved from 21.38820 to 21.35128, saving model to drive/gru_NN_model.h5\n",
      "Epoch 22/100\n",
      "315191/315191 [==============================] - 505s 2ms/step - loss: 21.6913 - acc: 0.0485 - val_loss: 21.3114 - val_acc: 0.0784\n",
      "\n",
      "Epoch 00022: val_loss improved from 21.35128 to 21.31135, saving model to drive/gru_NN_model.h5\n",
      "Epoch 23/100\n",
      "315191/315191 [==============================] - 484s 2ms/step - loss: 21.6626 - acc: 0.0556 - val_loss: 21.2808 - val_acc: 0.0724\n",
      "\n",
      "Epoch 00023: val_loss improved from 21.31135 to 21.28084, saving model to drive/gru_NN_model.h5\n",
      "Epoch 24/100\n",
      "315191/315191 [==============================] - 510s 2ms/step - loss: 21.6258 - acc: 0.0554 - val_loss: 21.2583 - val_acc: 0.0794\n",
      "\n",
      "Epoch 00024: val_loss improved from 21.28084 to 21.25831, saving model to drive/gru_NN_model.h5\n",
      "Epoch 25/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 21.5822 - acc: 0.0550 - val_loss: 21.2264 - val_acc: 0.0709\n",
      "\n",
      "Epoch 00025: val_loss improved from 21.25831 to 21.22638, saving model to drive/gru_NN_model.h5\n",
      "Epoch 26/100\n",
      "315191/315191 [==============================] - 528s 2ms/step - loss: 21.5489 - acc: 0.0565 - val_loss: 21.2038 - val_acc: 0.0790\n",
      "\n",
      "Epoch 00026: val_loss improved from 21.22638 to 21.20381, saving model to drive/gru_NN_model.h5\n",
      "Epoch 27/100\n",
      "315191/315191 [==============================] - 482s 2ms/step - loss: 21.5112 - acc: 0.0518 - val_loss: 21.1738 - val_acc: 0.0857\n",
      "\n",
      "Epoch 00027: val_loss improved from 21.20381 to 21.17381, saving model to drive/gru_NN_model.h5\n",
      "Epoch 28/100\n",
      "315191/315191 [==============================] - 537s 2ms/step - loss: 21.4893 - acc: 0.0547 - val_loss: 21.1784 - val_acc: 0.0738\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 21.17381\n",
      "Epoch 29/100\n",
      "315191/315191 [==============================] - 463s 1ms/step - loss: 21.4578 - acc: 0.0517 - val_loss: 21.1276 - val_acc: 0.0756\n",
      "\n",
      "Epoch 00029: val_loss improved from 21.17381 to 21.12761, saving model to drive/gru_NN_model.h5\n",
      "Epoch 30/100\n",
      "315191/315191 [==============================] - 508s 2ms/step - loss: 21.4552 - acc: 0.0543 - val_loss: 21.1321 - val_acc: 0.0578\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 21.12761\n",
      "Epoch 31/100\n",
      "315191/315191 [==============================] - 502s 2ms/step - loss: 21.4198 - acc: 0.0492 - val_loss: 21.1176 - val_acc: 0.0700\n",
      "\n",
      "Epoch 00031: val_loss improved from 21.12761 to 21.11758, saving model to drive/gru_NN_model.h5\n",
      "Epoch 32/100\n",
      "315191/315191 [==============================] - 487s 2ms/step - loss: 21.4024 - acc: 0.0499 - val_loss: 21.1094 - val_acc: 0.0670\n",
      "\n",
      "Epoch 00032: val_loss improved from 21.11758 to 21.10937, saving model to drive/gru_NN_model.h5\n",
      "Epoch 33/100\n",
      "315191/315191 [==============================] - 508s 2ms/step - loss: 21.3773 - acc: 0.0528 - val_loss: 21.0904 - val_acc: 0.0708\n",
      "\n",
      "Epoch 00033: val_loss improved from 21.10937 to 21.09045, saving model to drive/gru_NN_model.h5\n",
      "Epoch 34/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 21.3414 - acc: 0.0504 - val_loss: 21.0171 - val_acc: 0.0727\n",
      "\n",
      "Epoch 00034: val_loss improved from 21.09045 to 21.01714, saving model to drive/gru_NN_model.h5\n",
      "Epoch 35/100\n",
      "315191/315191 [==============================] - 524s 2ms/step - loss: 21.2934 - acc: 0.0469 - val_loss: 20.9972 - val_acc: 0.0588\n",
      "\n",
      "Epoch 00035: val_loss improved from 21.01714 to 20.99721, saving model to drive/gru_NN_model.h5\n",
      "Epoch 36/100\n",
      "315191/315191 [==============================] - 486s 2ms/step - loss: 21.2716 - acc: 0.0492 - val_loss: 21.0031 - val_acc: 0.0697\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 20.99721\n",
      "Epoch 37/100\n",
      "315191/315191 [==============================] - 519s 2ms/step - loss: 21.2579 - acc: 0.0494 - val_loss: 20.9921 - val_acc: 0.0678\n",
      "\n",
      "Epoch 00037: val_loss improved from 20.99721 to 20.99213, saving model to drive/gru_NN_model.h5\n",
      "Epoch 38/100\n",
      "315191/315191 [==============================] - 465s 1ms/step - loss: 21.2473 - acc: 0.0472 - val_loss: 20.9432 - val_acc: 0.0643\n",
      "\n",
      "Epoch 00038: val_loss improved from 20.99213 to 20.94323, saving model to drive/gru_NN_model.h5\n",
      "Epoch 39/100\n",
      "315191/315191 [==============================] - 526s 2ms/step - loss: 21.2276 - acc: 0.0484 - val_loss: 20.9633 - val_acc: 0.0573\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 20.94323\n",
      "Epoch 40/100\n",
      "315191/315191 [==============================] - 484s 2ms/step - loss: 21.2148 - acc: 0.0456 - val_loss: 20.9453 - val_acc: 0.0592\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 20.94323\n",
      "Epoch 41/100\n",
      "315191/315191 [==============================] - 525s 2ms/step - loss: 21.1909 - acc: 0.0447 - val_loss: 20.9251 - val_acc: 0.0640\n",
      "\n",
      "Epoch 00041: val_loss improved from 20.94323 to 20.92508, saving model to drive/gru_NN_model.h5\n",
      "Epoch 42/100\n",
      "315191/315191 [==============================] - 465s 1ms/step - loss: 21.1873 - acc: 0.0474 - val_loss: 20.9346 - val_acc: 0.0597\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 20.92508\n",
      "Epoch 43/100\n",
      "315191/315191 [==============================] - 508s 2ms/step - loss: 21.1858 - acc: 0.0480 - val_loss: 20.9157 - val_acc: 0.0515\n",
      "\n",
      "Epoch 00043: val_loss improved from 20.92508 to 20.91574, saving model to drive/gru_NN_model.h5\n",
      "Epoch 44/100\n",
      "315191/315191 [==============================] - 495s 2ms/step - loss: 21.1720 - acc: 0.0479 - val_loss: 20.9152 - val_acc: 0.0620\n",
      "\n",
      "Epoch 00044: val_loss improved from 20.91574 to 20.91522, saving model to drive/gru_NN_model.h5\n",
      "Epoch 45/100\n",
      "315191/315191 [==============================] - 499s 2ms/step - loss: 21.1553 - acc: 0.0457 - val_loss: 20.9262 - val_acc: 0.0388\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 20.91522\n",
      "Epoch 46/100\n",
      "315191/315191 [==============================] - 490s 2ms/step - loss: 21.2596 - acc: 0.0443 - val_loss: 20.9254 - val_acc: 0.0618\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 20.91522\n",
      "Epoch 47/100\n",
      "315191/315191 [==============================] - 516s 2ms/step - loss: 21.1669 - acc: 0.0436 - val_loss: 20.8892 - val_acc: 0.0489\n",
      "\n",
      "Epoch 00047: val_loss improved from 20.91522 to 20.88918, saving model to drive/gru_NN_model.h5\n",
      "Epoch 48/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 21.1337 - acc: 0.0461 - val_loss: 20.8755 - val_acc: 0.0559\n",
      "\n",
      "Epoch 00048: val_loss improved from 20.88918 to 20.87545, saving model to drive/gru_NN_model.h5\n",
      "Epoch 49/100\n",
      "315191/315191 [==============================] - 510s 2ms/step - loss: 21.1123 - acc: 0.0472 - val_loss: 20.8659 - val_acc: 0.0444\n",
      "\n",
      "Epoch 00049: val_loss improved from 20.87545 to 20.86595, saving model to drive/gru_NN_model.h5\n",
      "Epoch 50/100\n",
      "315191/315191 [==============================] - 491s 2ms/step - loss: 21.0949 - acc: 0.0447 - val_loss: 20.8656 - val_acc: 0.0428\n",
      "\n",
      "Epoch 00050: val_loss improved from 20.86595 to 20.86562, saving model to drive/gru_NN_model.h5\n",
      "Epoch 51/100\n",
      "315191/315191 [==============================] - 521s 2ms/step - loss: 21.0894 - acc: 0.0423 - val_loss: 20.8439 - val_acc: 0.0433\n",
      "\n",
      "Epoch 00051: val_loss improved from 20.86562 to 20.84385, saving model to drive/gru_NN_model.h5\n",
      "Epoch 52/100\n",
      "315191/315191 [==============================] - 464s 1ms/step - loss: 21.0714 - acc: 0.0428 - val_loss: 20.8342 - val_acc: 0.0433\n",
      "\n",
      "Epoch 00052: val_loss improved from 20.84385 to 20.83418, saving model to drive/gru_NN_model.h5\n",
      "Epoch 53/100\n",
      "315191/315191 [==============================] - 525s 2ms/step - loss: 21.0702 - acc: 0.0431 - val_loss: 20.8552 - val_acc: 0.0559\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 20.83418\n",
      "Epoch 54/100\n",
      "315191/315191 [==============================] - 495s 2ms/step - loss: 21.0746 - acc: 0.0445 - val_loss: 20.9283 - val_acc: 0.0435\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 20.83418\n",
      "Epoch 55/100\n",
      "315191/315191 [==============================] - 503s 2ms/step - loss: 21.0579 - acc: 0.0448 - val_loss: 20.8309 - val_acc: 0.0473\n",
      "\n",
      "Epoch 00055: val_loss improved from 20.83418 to 20.83088, saving model to drive/gru_NN_model.h5\n",
      "Epoch 56/100\n",
      "315191/315191 [==============================] - 485s 2ms/step - loss: 21.0485 - acc: 0.0429 - val_loss: 20.8268 - val_acc: 0.0506\n",
      "\n",
      "Epoch 00056: val_loss improved from 20.83088 to 20.82679, saving model to drive/gru_NN_model.h5\n",
      "Epoch 57/100\n",
      "315191/315191 [==============================] - 515s 2ms/step - loss: 21.0567 - acc: 0.0451 - val_loss: 20.8318 - val_acc: 0.0465\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 20.82679\n",
      "Epoch 58/100\n",
      "315191/315191 [==============================] - 507s 2ms/step - loss: 21.0407 - acc: 0.0467 - val_loss: 20.8379 - val_acc: 0.0549\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 20.82679\n",
      "Epoch 59/100\n",
      "315191/315191 [==============================] - 485s 2ms/step - loss: 21.0364 - acc: 0.0520 - val_loss: 20.8223 - val_acc: 0.0447\n",
      "\n",
      "Epoch 00059: val_loss improved from 20.82679 to 20.82229, saving model to drive/gru_NN_model.h5\n",
      "Epoch 60/100\n",
      "315191/315191 [==============================] - 492s 2ms/step - loss: 21.0269 - acc: 0.0481 - val_loss: 20.8116 - val_acc: 0.0482\n",
      "\n",
      "Epoch 00060: val_loss improved from 20.82229 to 20.81160, saving model to drive/gru_NN_model.h5\n",
      "Epoch 61/100\n",
      "315191/315191 [==============================] - 456s 1ms/step - loss: 21.0206 - acc: 0.0471 - val_loss: 20.8003 - val_acc: 0.0612\n",
      "\n",
      "Epoch 00061: val_loss improved from 20.81160 to 20.80028, saving model to drive/gru_NN_model.h5\n",
      "Epoch 62/100\n",
      "315191/315191 [==============================] - 456s 1ms/step - loss: 21.0210 - acc: 0.0523 - val_loss: 20.8168 - val_acc: 0.0509\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 20.80028\n",
      "Epoch 63/100\n",
      "315191/315191 [==============================] - 458s 1ms/step - loss: 21.0159 - acc: 0.0494 - val_loss: 20.7981 - val_acc: 0.0572\n",
      "\n",
      "Epoch 00063: val_loss improved from 20.80028 to 20.79813, saving model to drive/gru_NN_model.h5\n",
      "Epoch 64/100\n",
      "315191/315191 [==============================] - 487s 2ms/step - loss: 20.9967 - acc: 0.0511 - val_loss: 20.7982 - val_acc: 0.0550\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 20.79813\n",
      "Epoch 65/100\n",
      "315191/315191 [==============================] - 486s 2ms/step - loss: 20.9914 - acc: 0.0491 - val_loss: 20.7983 - val_acc: 0.0537\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 20.79813\n",
      "Epoch 66/100\n",
      "315191/315191 [==============================] - 487s 2ms/step - loss: 20.9872 - acc: 0.0522 - val_loss: 20.7785 - val_acc: 0.0554\n",
      "\n",
      "Epoch 00066: val_loss improved from 20.79813 to 20.77847, saving model to drive/gru_NN_model.h5\n",
      "Epoch 67/100\n",
      "315191/315191 [==============================] - 507s 2ms/step - loss: 20.9923 - acc: 0.0470 - val_loss: 20.7904 - val_acc: 0.0540\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 20.77847\n",
      "Epoch 68/100\n",
      "315191/315191 [==============================] - 501s 2ms/step - loss: 20.9880 - acc: 0.0496 - val_loss: 20.7958 - val_acc: 0.0566\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 20.77847\n",
      "Epoch 69/100\n",
      "315191/315191 [==============================] - 490s 2ms/step - loss: 20.9863 - acc: 0.0498 - val_loss: 20.7710 - val_acc: 0.0523\n",
      "\n",
      "Epoch 00069: val_loss improved from 20.77847 to 20.77101, saving model to drive/gru_NN_model.h5\n",
      "Epoch 70/100\n",
      "315191/315191 [==============================] - 523s 2ms/step - loss: 20.9723 - acc: 0.0530 - val_loss: 20.7828 - val_acc: 0.0652\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 20.77101\n",
      "Epoch 71/100\n",
      "315191/315191 [==============================] - 478s 2ms/step - loss: 20.9677 - acc: 0.0535 - val_loss: 20.7862 - val_acc: 0.0695\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 20.77101\n",
      "Epoch 72/100\n",
      "315191/315191 [==============================] - 524s 2ms/step - loss: 20.9735 - acc: 0.0530 - val_loss: 20.7857 - val_acc: 0.0627\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 20.77101\n",
      "Epoch 73/100\n",
      "315191/315191 [==============================] - 490s 2ms/step - loss: 20.9615 - acc: 0.0511 - val_loss: 20.7821 - val_acc: 0.0576\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 20.77101\n",
      "Epoch 74/100\n",
      "315191/315191 [==============================] - 496s 2ms/step - loss: 20.9676 - acc: 0.0487 - val_loss: 20.7699 - val_acc: 0.0568\n",
      "\n",
      "Epoch 00074: val_loss improved from 20.77101 to 20.76988, saving model to drive/gru_NN_model.h5\n",
      "Epoch 75/100\n",
      "315191/315191 [==============================] - 510s 2ms/step - loss: 20.9436 - acc: 0.0470 - val_loss: 20.7525 - val_acc: 0.0501\n",
      "\n",
      "Epoch 00075: val_loss improved from 20.76988 to 20.75253, saving model to drive/gru_NN_model.h5\n",
      "Epoch 76/100\n",
      "315191/315191 [==============================] - 508s 2ms/step - loss: 20.9414 - acc: 0.0434 - val_loss: 20.7603 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 20.75253\n",
      "Epoch 77/100\n",
      "315191/315191 [==============================] - 489s 2ms/step - loss: 20.9331 - acc: 0.0457 - val_loss: 20.7536 - val_acc: 0.0573\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 20.75253\n",
      "Epoch 78/100\n",
      "315191/315191 [==============================] - 498s 2ms/step - loss: 20.9311 - acc: 0.0448 - val_loss: 20.7469 - val_acc: 0.0579\n",
      "\n",
      "Epoch 00078: val_loss improved from 20.75253 to 20.74689, saving model to drive/gru_NN_model.h5\n",
      "Epoch 79/100\n",
      "315191/315191 [==============================] - 490s 2ms/step - loss: 20.9261 - acc: 0.0487 - val_loss: 20.7449 - val_acc: 0.0655\n",
      "\n",
      "Epoch 00079: val_loss improved from 20.74689 to 20.74492, saving model to drive/gru_NN_model.h5\n",
      "Epoch 80/100\n",
      "315191/315191 [==============================] - 513s 2ms/step - loss: 20.9364 - acc: 0.0511 - val_loss: 20.7577 - val_acc: 0.0615\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 20.74492\n",
      "Epoch 81/100\n",
      "315191/315191 [==============================] - 508s 2ms/step - loss: 20.9356 - acc: 0.0500 - val_loss: 20.7575 - val_acc: 0.0581\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 20.74492\n",
      "Epoch 82/100\n",
      "315191/315191 [==============================] - 485s 2ms/step - loss: 20.9326 - acc: 0.0507 - val_loss: 20.7456 - val_acc: 0.0618\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 20.74492\n",
      "Epoch 83/100\n",
      "315191/315191 [==============================] - 514s 2ms/step - loss: 20.9164 - acc: 0.0512 - val_loss: 20.7334 - val_acc: 0.0669\n",
      "\n",
      "Epoch 00083: val_loss improved from 20.74492 to 20.73344, saving model to drive/gru_NN_model.h5\n",
      "Epoch 84/100\n",
      "151552/315191 [=============>................] - ETA: 4:02 - loss: 20.9115 - acc: 0.0497"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "checkpointer = ModelCheckpoint(filepath='gru_NN_model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "history_gru_NN = gru_NN.fit([X_train_numeric, X_train_text], y_train, epochs=100, batch_size=2048, validation_split=0.1, callbacks=[early_stopping_monitor, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7316,
     "status": "ok",
     "timestamp": 1534737111374,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "Tf46X5w4ctiR",
    "outputId": "36127bd6-6659-435b-80cc-a4775302e3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "with open('gru_NN_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "gru_NN = model_from_json(loaded_model_json)\n",
    "# load weights into model\n",
    "gru_NN.load_weights('gru_NN_model.h5')\n",
    "gru_NN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2554
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16503025,
     "status": "ok",
     "timestamp": 1534753617180,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "KSnTYHWBdJed",
    "outputId": "ddf8f6f9-75f6-42ba-c6c5-292c7fce6179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315191 samples, validate on 35022 samples\n",
      "Epoch 1/100\n",
      "315191/315191 [==============================] - 469s 1ms/step - loss: 20.9087 - acc: 0.0494 - val_loss: 20.7300 - val_acc: 0.0644\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 20.73003, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 2/100\n",
      "315191/315191 [==============================] - 455s 1ms/step - loss: 20.9090 - acc: 0.0519 - val_loss: 20.7396 - val_acc: 0.0618\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 20.73003\n",
      "Epoch 3/100\n",
      "315191/315191 [==============================] - 454s 1ms/step - loss: 20.9016 - acc: 0.0503 - val_loss: 20.7190 - val_acc: 0.0688\n",
      "\n",
      "Epoch 00003: val_loss improved from 20.73003 to 20.71900, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 4/100\n",
      "315191/315191 [==============================] - 448s 1ms/step - loss: 20.8979 - acc: 0.0507 - val_loss: 20.7328 - val_acc: 0.0578\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 20.71900\n",
      "Epoch 5/100\n",
      "315191/315191 [==============================] - 454s 1ms/step - loss: 20.8991 - acc: 0.0491 - val_loss: 20.7290 - val_acc: 0.0616\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 20.71900\n",
      "Epoch 6/100\n",
      "315191/315191 [==============================] - 452s 1ms/step - loss: 20.8965 - acc: 0.0473 - val_loss: 20.7328 - val_acc: 0.0694\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 20.71900\n",
      "Epoch 7/100\n",
      "315191/315191 [==============================] - 445s 1ms/step - loss: 20.8934 - acc: 0.0486 - val_loss: 20.7264 - val_acc: 0.0641\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 20.71900\n",
      "Epoch 8/100\n",
      "315191/315191 [==============================] - 458s 1ms/step - loss: 20.8924 - acc: 0.0476 - val_loss: 20.7304 - val_acc: 0.0657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 20.71900\n",
      "Epoch 9/100\n",
      "315191/315191 [==============================] - 440s 1ms/step - loss: 20.8922 - acc: 0.0484 - val_loss: 20.7253 - val_acc: 0.0663\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 20.71900\n",
      "Epoch 10/100\n",
      "315191/315191 [==============================] - 445s 1ms/step - loss: 20.8946 - acc: 0.0494 - val_loss: 20.7286 - val_acc: 0.0626\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 20.71900\n",
      "Epoch 11/100\n",
      "315191/315191 [==============================] - 455s 1ms/step - loss: 20.8876 - acc: 0.0488 - val_loss: 20.7260 - val_acc: 0.0617\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 20.71900\n",
      "Epoch 12/100\n",
      "315191/315191 [==============================] - 441s 1ms/step - loss: 20.8854 - acc: 0.0494 - val_loss: 20.7238 - val_acc: 0.0648\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 20.71900\n",
      "Epoch 13/100\n",
      "315191/315191 [==============================] - 449s 1ms/step - loss: 20.8805 - acc: 0.0479 - val_loss: 20.7119 - val_acc: 0.0592\n",
      "\n",
      "Epoch 00013: val_loss improved from 20.71900 to 20.71190, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 14/100\n",
      "315191/315191 [==============================] - 454s 1ms/step - loss: 20.8830 - acc: 0.0460 - val_loss: 20.6988 - val_acc: 0.0556\n",
      "\n",
      "Epoch 00014: val_loss improved from 20.71190 to 20.69881, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 15/100\n",
      "315191/315191 [==============================] - 441s 1ms/step - loss: 20.8742 - acc: 0.0457 - val_loss: 20.7255 - val_acc: 0.0552\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 20.69881\n",
      "Epoch 16/100\n",
      "315191/315191 [==============================] - 462s 1ms/step - loss: 20.8835 - acc: 0.0446 - val_loss: 20.7144 - val_acc: 0.0646\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 20.69881\n",
      "Epoch 17/100\n",
      "315191/315191 [==============================] - 445s 1ms/step - loss: 20.8802 - acc: 0.0517 - val_loss: 20.7183 - val_acc: 0.0664\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 20.69881\n",
      "Epoch 18/100\n",
      "315191/315191 [==============================] - 450s 1ms/step - loss: 20.8705 - acc: 0.0514 - val_loss: 20.6990 - val_acc: 0.0615\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 20.69881\n",
      "Epoch 19/100\n",
      "315191/315191 [==============================] - 450s 1ms/step - loss: 20.8645 - acc: 0.0479 - val_loss: 20.7143 - val_acc: 0.0659\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 20.69881\n",
      "Epoch 20/100\n",
      "315191/315191 [==============================] - 442s 1ms/step - loss: 20.8733 - acc: 0.0477 - val_loss: 20.7228 - val_acc: 0.0657\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 20.69881\n",
      "Epoch 21/100\n",
      "315191/315191 [==============================] - 457s 1ms/step - loss: 20.8674 - acc: 0.0496 - val_loss: 20.7207 - val_acc: 0.0670\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 20.69881\n",
      "Epoch 22/100\n",
      "315191/315191 [==============================] - 440s 1ms/step - loss: 20.8606 - acc: 0.0493 - val_loss: 20.6974 - val_acc: 0.0614\n",
      "\n",
      "Epoch 00022: val_loss improved from 20.69881 to 20.69743, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 23/100\n",
      "315191/315191 [==============================] - 453s 1ms/step - loss: 20.8515 - acc: 0.0486 - val_loss: 20.6995 - val_acc: 0.0658\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 20.69743\n",
      "Epoch 24/100\n",
      "315191/315191 [==============================] - 447s 1ms/step - loss: 20.8579 - acc: 0.0528 - val_loss: 20.6900 - val_acc: 0.0672\n",
      "\n",
      "Epoch 00024: val_loss improved from 20.69743 to 20.68996, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 25/100\n",
      "315191/315191 [==============================] - 447s 1ms/step - loss: 20.8423 - acc: 0.0489 - val_loss: 20.6883 - val_acc: 0.0665\n",
      "\n",
      "Epoch 00025: val_loss improved from 20.68996 to 20.68834, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 26/100\n",
      "315191/315191 [==============================] - 459s 1ms/step - loss: 20.8433 - acc: 0.0467 - val_loss: 20.6839 - val_acc: 0.0606\n",
      "\n",
      "Epoch 00026: val_loss improved from 20.68834 to 20.68386, saving model to drive/gru_NN_model2.h5\n",
      "Epoch 27/100\n",
      "315191/315191 [==============================] - 440s 1ms/step - loss: 20.8436 - acc: 0.0480 - val_loss: 20.7008 - val_acc: 0.0627\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 20.68386\n",
      "Epoch 28/100\n",
      "315191/315191 [==============================] - 455s 1ms/step - loss: 20.8481 - acc: 0.0498 - val_loss: 20.7215 - val_acc: 0.0715\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 20.68386\n",
      "Epoch 29/100\n",
      "315191/315191 [==============================] - 457s 1ms/step - loss: 20.8588 - acc: 0.0529 - val_loss: 20.7018 - val_acc: 0.0624\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 20.68386\n",
      "Epoch 30/100\n",
      "315191/315191 [==============================] - 472s 1ms/step - loss: 20.8422 - acc: 0.0497 - val_loss: 20.6922 - val_acc: 0.0748\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 20.68386\n",
      "Epoch 31/100\n",
      "315191/315191 [==============================] - 488s 2ms/step - loss: 20.8382 - acc: 0.0495 - val_loss: 20.6918 - val_acc: 0.0646\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 20.68386\n",
      "Epoch 32/100\n",
      "315191/315191 [==============================] - 473s 2ms/step - loss: 20.8366 - acc: 0.0510 - val_loss: 20.6985 - val_acc: 0.0745\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 20.68386\n",
      "Epoch 33/100\n",
      "315191/315191 [==============================] - 476s 2ms/step - loss: 20.8538 - acc: 0.0546 - val_loss: 20.6881 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 20.68386\n",
      "Epoch 34/100\n",
      "315191/315191 [==============================] - 479s 2ms/step - loss: 20.8346 - acc: 0.0526 - val_loss: 20.6947 - val_acc: 0.0637\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 20.68386\n",
      "Epoch 35/100\n",
      "315191/315191 [==============================] - 471s 1ms/step - loss: 20.8345 - acc: 0.0521 - val_loss: 20.6856 - val_acc: 0.0702\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 20.68386\n",
      "Epoch 36/100\n",
      "315191/315191 [==============================] - 487s 2ms/step - loss: 20.8513 - acc: 0.0557 - val_loss: 20.7084 - val_acc: 0.0724\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 20.68386\n"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10)\n",
    "checkpointer = ModelCheckpoint(filepath='drive/gru_NN_model2.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "history_gru_NN = gru_NN.fit([X_train_numeric, X_train_text], y_train, epochs=100, batch_size=2048, validation_split=0.1, callbacks=[early_stopping_monitor, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2643,
     "status": "ok",
     "timestamp": 1534753619927,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "Aqfq_Q9VDf5B",
    "outputId": "d5d77487-55f3-4297-8bd6-439d5df749f5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFnCAYAAAChL+DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSfv32LXMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe011afef0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_gru_NN.history['loss'])\n",
    "plt.plot(history_gru_NN.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model\n",
    "Run cell below if model has already been trained, and json and h5 files are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzyY-6uQNQCT"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "with open('gru_NN_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "gru_NN = model_from_json(loaded_model_json)\n",
    "\n",
    "gru_NN.load_weights('gru_NN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions on test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlXYzPrd5eP4"
   },
   "outputs": [],
   "source": [
    "label_class_counts = {\n",
    "    'Function': [0, 37], \n",
    "    'Object_Type': [37, 48], \n",
    "    'Operating_Status': [48, 51], \n",
    "    'Position_Type': [51, 76], \n",
    "    'Pre_K': [76, 79], \n",
    "    'Reporting': [79, 82], \n",
    "    'Sharing': [82, 87], \n",
    "    'Student_Type': [87, 96], \n",
    "    'Use': [96, 104]\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "val_predictions = gru_NN.predict([X_val_numeric, X_val_text])\n",
    "\n",
    "# Calculate validation logloss for each label\n",
    "for label, indices in label_class_counts.items():\n",
    "    # Get values for specific label\n",
    "    start_idx = indices[0]\n",
    "    end_idx = indices[1]\n",
    "    y_val_label = y_val[:, start_idx:end_idx]\n",
    "    val_predictions_label = val_predictions[:, start_idx:end_idx]\n",
    "    \n",
    "    \n",
    "    # Get logloss score of mode\n",
    "    scores[label] = log_loss(y_val_label, val_predictions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6d9EwoxGX3z"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for test set\n",
    "predictions = gru_NN.predict([X_test_numeric, X_test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-pJMVIr5eP7"
   },
   "source": [
    "# Save score and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngyDlM8A5eP7"
   },
   "outputs": [],
   "source": [
    "# Save predictions for test set\n",
    "label = ['Function',\n",
    "         'Object_Type',\n",
    "         'Operating_Status',\n",
    "         'Position_Type',\n",
    "         'Pre_K',\n",
    "         'Reporting',\n",
    "         'Sharing',\n",
    "         'Student_Type',\n",
    "         'Use']\n",
    "y = pd.get_dummies(data_train[label]).astype('float64')\n",
    "\n",
    "submission = pd.DataFrame(predictions, index=data_test.index, columns=y.columns)\n",
    "submission.to_csv('gru_NN_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1534756144193,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "uRHjIso15eP8",
    "outputId": "d2d10c61-9775-4300-c17b-c9342d0370f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Function': 0.20893736624555154,\n",
       " 'Object_Type': 0.0559802555353085,\n",
       " 'Operating_Status': 0.060882893733789065,\n",
       " 'Position_Type': 0.07964425126465846,\n",
       " 'Pre_K': 0.03725828551658394,\n",
       " 'Reporting': 0.07329710876069019,\n",
       " 'Sharing': 0.1294886757837233,\n",
       " 'Student_Type': 0.10264402130957304,\n",
       " 'Use': 0.14898147769912726}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1534756144593,
     "user": {
      "displayName": "Albert Lee",
      "photoUrl": "//lh3.googleusercontent.com/-f0u8obCCk_w/AAAAAAAAAAI/AAAAAAAAAxs/83E22s4mtyM/s50-c-k-no/photo.jpg",
      "userId": "109969660738913262150"
     },
     "user_tz": 240
    },
    "id": "yQd8s_q85eP_",
    "outputId": "d7d512b7-d307-4b6f-99e2-94b5674f5856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09967937064988948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([score for score in scores.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQxW3L5o5eQC"
   },
   "outputs": [],
   "source": [
    "# Save scores\n",
    "with open('gru_NN_score.json', 'w') as file:\n",
    "     file.write(json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GRU_NN_model.ipynb",
   "provenance": [
    {
     "file_id": "113YK-k0PrWBbtiUjQp7qB4-fLr_nyaMR",
     "timestamp": 1534630643463
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
